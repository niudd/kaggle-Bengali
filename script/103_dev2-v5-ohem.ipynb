{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define environment\n",
    "ON_KAGGLE = False\n",
    "TRAIN_PREDICT = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.3.1+cu100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if ON_KAGGLE:\n",
    "    sys.path.append('../input/bengali-util/script/')\n",
    "    sys.path.append('../input/bengali-util/')\n",
    "    from script.utils import seed_everything, set_n_get_device\n",
    "else:\n",
    "    from utils import seed_everything, set_n_get_device\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "print('torch', torch.__version__)\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    #load utility scripts\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "debug = False\n",
    "SEED = 42\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 256\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    NUM_WORKERS = 2\n",
    "else:\n",
    "    NUM_WORKERS = 16\n",
    "\n",
    "device = set_n_get_device(\"0,1\", data_device_id=\"cuda:0\")#IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0,1]\n",
    "\n",
    "if debug:\n",
    "    LOG_PATH = '../logging/v5-debug.log'\n",
    "else:\n",
    "    LOG_PATH = '../logging/v5.log'\n",
    "\n",
    "checkpoint_path = '../checkpoint/v5'\n",
    "warm_start, last_checkpoint_path = False, '../checkpoint/v3/best.pth.tar'\n",
    "\n",
    "NUM_EPOCHS = 60\n",
    "early_stopping_round = 9999\n",
    "#LearningRate = 5e-3\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "n_grapheme=168\n",
    "n_vowel=11\n",
    "n_consonant=7\n",
    "#n_combo = 1295\n",
    "\n",
    "#num_classes = n_grapheme+n_vowel+n_consonant+n_combo\n",
    "num_classes = n_grapheme+n_vowel+n_consonant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "1. pytorch Dataset, data augmentation, DataLoader, train-test-split/KFold, \n",
    "2. network\n",
    "3. training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200840, 137, 236), (200840, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ON_KAGGLE:\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    train_df_list = [pd.read_feather('../data/processed/train_image_data_%d.feather'%i) for i in range(4)]\n",
    "    train_images_arr = np.concatenate([df.iloc[:, 1:].values.reshape(-1, IMG_HEIGHT, IMG_WIDTH) \n",
    "                                       for df in train_df_list], axis=0)\n",
    "    train_label_df = pd.read_csv('../data/raw/train.csv')\n",
    "    train_label_arr = train_label_df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "\n",
    "train_images_arr.shape, train_label_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import augmentation\n",
    "# importlib.reload(augmentation)\n",
    "# from augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##experiment a lot of augmentations\n",
    "# imgs = train_images_arr[np.random.choice(200840, 4), :]\n",
    "# imgs = np.clip((255-imgs)/255, 0, 1)\n",
    "\n",
    "# fig,axes = plt.subplots(4,2, figsize=(10,8))\n",
    "# for i in range(4):\n",
    "#     image = imgs[i]\n",
    "#     img_aug = do_random_shift_scale_crop_pad2(image, limit=0.2)\n",
    "#     axes[i, 0].imshow(image, cmap='binary')\n",
    "#     axes[i, 1].imshow(img_aug, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 1. encode grapheme characters to index 2. use it as sampler\n",
    "# unique_char = train_label_df['grapheme'].unique()\n",
    "# char2ind = dict([(char,i) for i,char in enumerate(unique_char)])\n",
    "# grapheme_ind = [char2ind[char] for char in train_label_df['grapheme']]\n",
    "# cls_w_dict = pd.value_counts(grapheme_ind)\n",
    "# cls_w_dict /= 100\n",
    "# cls_w_dict = cls_w_dict.to_dict()\n",
    "# cls_w = [cls_w_dict[i] for i in grapheme_ind]\n",
    "\n",
    "\n",
    "##check onehot correct?\n",
    "#train_label_df.loc[train_label_arr[:,3]==1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation --cutmix, mixup\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    #cut_rat = np.sqrt(1. - lam)\n",
    "    cut_rat = lam\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform, ignore edge area\n",
    "    cx = np.random.randint(W//4, W*3//4)\n",
    "    cy = np.random.randint(H//4, H*3//4)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    #print(bbx1, bby1, bbx2, bby2)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(data, target, alpha=1.0):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    #lam = np.random.beta(alpha, alpha)\n",
    "    lam = np.sqrt(np.random.rand()/4)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    #data[:, :, bbx1:bbx2, bby1:bby2] += data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    #data = torch.clamp(data, 0, 1)\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, \n",
    "               targets3, shuffled_targets3, lam]\n",
    "    return data, targets\n",
    "\n",
    "def mixup(data, target, alpha=0.4):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, \n",
    "               targets3, shuffled_targets3, lam]\n",
    "\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "#     if fold in [0]:#train 1 fold for testing ideas\n",
    "#         print('========training fold %d========'%fold)\n",
    "#         print(train_idx)\n",
    "#         print(valid_idx)\n",
    "        \n",
    "#         #1.1 data\n",
    "#         train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "#         train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "#         #1.2 Dataset, DataLoader\n",
    "#         train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "#         val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "\n",
    "# ####\n",
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if np.random.rand()<-10:\n",
    "#         inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "#     else:\n",
    "#         inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "#     if batch_id==1:\n",
    "#         break\n",
    "\n",
    "# #print(inputs.shape, truth.shape)\n",
    "\n",
    "# show_inputs = inputs.cpu().numpy()[np.random.choice(BATCH_SIZE, 20, replace=False), :, :, :]\n",
    "# fig,axes = plt.subplots(5,4, figsize=(10,8))\n",
    "# for i in range(20):\n",
    "#     axes[i//4, i%4].imshow(show_inputs[i, 0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##crop to 128x128\n",
    "# def bbox(img):\n",
    "#     rows = np.any(img, axis=1)\n",
    "#     cols = np.any(img, axis=0)\n",
    "#     rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#     cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#     return rmin, rmax, cmin, cmax\n",
    "\n",
    "# def crop_resize(img0, size=128, pad=16):\n",
    "#     #crop a box around pixels large than the threshold \n",
    "#     #some images contain line at the sides\n",
    "#     ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "#     #cropping may cut too much, so we need to add it back\n",
    "#     xmin = xmin - 13 if (xmin > 13) else 0\n",
    "#     ymin = ymin - 10 if (ymin > 10) else 0\n",
    "#     xmax = xmax + 13 if (xmax < IMG_WIDTH - 13) else IMG_WIDTH\n",
    "#     ymax = ymax + 10 if (ymax < IMG_HEIGHT - 10) else IMG_HEIGHT\n",
    "#     img = img0[ymin:ymax,xmin:xmax]\n",
    "#     #remove lo intensity pixels as noise\n",
    "#     img[img < 28] = 0\n",
    "#     lx, ly = xmax-xmin,ymax-ymin\n",
    "#     l = max(lx,ly) + pad\n",
    "#     #make sure that the aspect ratio is kept in rescaling\n",
    "#     img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "#     return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img0 = train_images_arr[0]\n",
    "#img0 = 255 - img0\n",
    "#img0 = (img0*(255.0/img0.max())).astype(np.uint8)\n",
    "#plt.imshow(crop_resize(rotate(img0, angle=20, reshape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### make up a weighted/balanced data sampler --for mixup/cutmix ####\n",
    "# #weights for 168 classes--graphene_root\n",
    "# import torch.utils.data\n",
    "# _weights = [6.8,6.9,3,3.1,3,5.7,3.2,6.5,6.4,2.3,6.6,6.6,6.8,0.2,1.3,0.9,1.1,1.3,0.6,3.6,3,1.1,0.3,0.2,3,0.9,5.8,3.3,1.3,0.4,2.3,1.3,0.9,7.4,3.6,2.1,1,3.5,0.3,1.6,1.3,3.3,0.5,0.3,0.9,6.9,1.7,2.2,0.7,3.1,1.4,3.1,1.1,0.3,1.7,0.6,0.4,1.6,0.8,0.4,2.3,1.7,1.2,6.7,0.2,0.7,1.3,2.1,1.6,1.3,1,0.3,0.2,7.7,0.7,0.9,0.5,1,3.4,0.3,2.2,0.3,3.4,0.7,2.2,0.7,0.5,6,1.3,0.4,1.6,0.6,0.9,1.6,1,1.4,0.2,2.1,1.6,2.2,2.2,0.9,7.1,0.3,6.2,6.6,1.3,0.2,6.3,1.1,2.9,1.3,1.1,0.2,6.7,0.2,2.3,0.7,0.9,0.7,0.8,2.2,0.4,0.5,0.5,1.2,6.3,1.1,1.1,1,6.9,2.3,1,0.2,1.6,1.6,1,1.8,1.1,0.4,1.1,0.6,0.9,1.6,1.6,3.2,3.3,0.2,0.6,0.4,0.4,0.8,1.6,0.6,1.4,1.1,1.3,3.1,7,0.3,2.1,3.2,2.2,6.1,6.1,0.9,3.3,0.6]\n",
    "# weights_dict = dict(zip(range(len(_weights)), _weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import set_logger, save_checkpoint, load_checkpoint\n",
    "import logging\n",
    "#import gc\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import cv2\n",
    "from augmentation import *\n",
    "\n",
    "\n",
    "def prepare_dataset(img_arr, label_arr, mode='train', debug=False):\n",
    "    \"\"\"\n",
    "    mode: 'train', 'valid', 'test'\n",
    "    \"\"\"\n",
    "    if debug:#for debug, sample 1/10 data\n",
    "        n = img_arr.shape[0]\n",
    "        sid = np.random.choice(n, size=n//5, replace=False)\n",
    "        img_arr = img_arr[sid]\n",
    "        label_arr = label_arr[sid]\n",
    "\n",
    "    if mode=='train':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "\n",
    "#     if mode=='train':\n",
    "#         ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "#         weights = [weights_dict[c] for c in label_arr[:,0]]\n",
    "#         sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=len(ds), replacement=True)\n",
    "#         dl = DataLoader(ds,\n",
    "#                         batch_size=BATCH_SIZE,\n",
    "#                         shuffle=False,\n",
    "#                         sampler=sampler,\n",
    "#                         num_workers=NUM_WORKERS,\n",
    "#                         drop_last=True\n",
    "#                        )\n",
    "#         return dl\n",
    "\n",
    "    elif mode=='valid':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "    elif mode=='test':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='test', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=False\n",
    "                       ) \n",
    "    return dl\n",
    "\n",
    "class DatasetV1(Dataset):\n",
    "    \"\"\"plain\"\"\"\n",
    "    def __init__(self, inputs, outputs, mode='train', augmentation=False):\n",
    "        \"\"\"\n",
    "        inputs: images, (N, H, W)\n",
    "        outputs: label, (N, 3)\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.mode = mode \n",
    "        self.augmentation = augmentation\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: augmentation, preprocessing\n",
    "        inputs, outputs = self.inputs[idx], self.outputs[idx]\n",
    "        inputs = np.clip((255-inputs)/255.0, 0, 1)\n",
    "\n",
    "#         inputs = cv2.resize(inputs, (224,224))\n",
    "#         inputs = np.clip(inputs, 0, 1)\n",
    "\n",
    "        #crop\n",
    "#         inputs = 255-inputs\n",
    "#         inputs = crop_resize(inputs)\n",
    "#         inputs = np.clip(inputs/255.0, 0, 1)\n",
    "\n",
    "        if self.augmentation:\n",
    "            inputs = self.do_augmentation(inputs)\n",
    "        \n",
    "        inputs = np.expand_dims(inputs, 0)#(224,224)-->(1,224,224)\n",
    "        inputs = inputs.astype(np.float32)\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "    \n",
    "    def do_augmentation(self, image):\n",
    "        #rotate\n",
    "        #if np.random.rand() < 0.5:\n",
    "        #angle = np.random.randint(0, 40) - 20\n",
    "        #inputs = rotate(inputs, angle, reshape=False)\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_projective(image, 0.4),#0.4\n",
    "            lambda image : do_random_perspective(image, 0.4),#0.4\n",
    "            lambda image : do_random_scale(image, 0.4),#0.4\n",
    "            lambda image : do_random_rotate(image, 0.4),#0.4\n",
    "            lambda image : do_random_shear_x(image, 0.5),#0.5\n",
    "            lambda image : do_random_shear_y(image, 0.4),#0.4\n",
    "            lambda image : do_random_stretch_x(image, 0.5),#0.5\n",
    "            lambda image : do_random_stretch_y(image, 0.5),#0.5\n",
    "            lambda image : do_random_grid_distortion(image, 0.4),#0.4\n",
    "            lambda image : do_random_custom_distortion1(image, 0.5),#0.5\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_erode(image, 0.4),#0.4\n",
    "            lambda image : do_random_dilate(image, 0.4),#0.4\n",
    "            lambda image : do_random_sprinkle(image, 0.5),#0.5\n",
    "            #lambda image : do_random_line(image, 0.2),\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_contast(image, 0.5),#0.5\n",
    "            lambda image : do_random_block_fade(image, 0.5),#0.5\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "        \n",
    "#         if np.random.rand()<1.1:\n",
    "#             image = do_random_shift_scale_crop_pad2(image, limit=0.1)\n",
    "#         else:\n",
    "#             image = do_shift_scale_rotate2(image, angle=np.random.uniform(0, 10))\n",
    "        return image\n",
    "\n",
    "def train_and_valid(net, train_dl, val_dl):\n",
    "    \"\"\"train one fold\n",
    "    \n",
    "    [settings]...\n",
    "    \n",
    "    [Epoch i]\n",
    "        [Trainset]\n",
    "            [Batch j]\n",
    "        [Validset]\n",
    "            [Batch k]\n",
    "        [Logging/Checkpoint]\n",
    "    \"\"\"\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #1. optim\n",
    "    train_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "#     optimizer = torch.optim.Adam(train_params, lr=LearningRate)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "#                                                           factor=0.5, patience=5, \n",
    "#                                                           verbose=False, threshold=0.0001, \n",
    "#                                                           threshold_mode='rel', cooldown=0, \n",
    "#                                                           min_lr=0, eps=1e-08)\n",
    "\n",
    "#     optimizer = torch.optim.Adam(train_params, lr=5e-2)\n",
    "#     scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,10,15,20], gamma=0.1)\n",
    "\n",
    "    optimizer = torch.optim.Adam(train_params)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-3, \n",
    "                                                    steps_per_epoch=len(train_dl),#1255 \n",
    "                                                    epochs=NUM_EPOCHS)\n",
    "\n",
    "    #1.1 warm-start\n",
    "    if warm_start:\n",
    "        logging.info('warm_start: '+last_checkpoint_path)\n",
    "        net, _ = load_checkpoint(last_checkpoint_path, net)\n",
    "    \n",
    "    #2. using multi GPU\n",
    "    if multi_gpu is not None:\n",
    "        net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "    #3. train\n",
    "    diff = 0\n",
    "    best_val_metric = -1.0#np.inf\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i_epoch in range(NUM_EPOCHS):\n",
    "        t0 = time.time()\n",
    "        print('lr: ', scheduler.get_lr())\n",
    "        ## trainset -------------------------------------------------------------\n",
    "        net.train()\n",
    "        loss_logger = LossLogger()\n",
    "        for batch_id, (images, labels) in enumerate(train_dl):\n",
    "            inputs = images.to(device=device, dtype=torch.float)\n",
    "            truth = labels.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            #do cutmix/mixup\n",
    "            if np.random.rand()<0.5:\n",
    "                inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "            else:\n",
    "                inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "\n",
    "            #if use ohem loss\n",
    "            if i_epoch<-1:#80\n",
    "                mode = 'normal'\n",
    "                rate = None\n",
    "            else:\n",
    "                mode = 'ohem'\n",
    "                if i_epoch<10:\n",
    "                    rate = 1.0 #keep all loss, no ohem\n",
    "                elif i_epoch<50:\n",
    "                    rate = 0.7\n",
    "                else:\n",
    "                    rate = 0.2\n",
    "\n",
    "            logit = net(inputs)\n",
    "            logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "            train_loss = loss_logger.update(logits, truth, mode=mode, rate=rate)\n",
    "            #grandient accumulation step=2\n",
    "            acc_step = 1\n",
    "            if acc_step>1:\n",
    "                train_loss = train_loss / acc_step\n",
    "            train_loss.backward()\n",
    "            if (batch_id+1)%acc_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            ##lr scheduler\n",
    "            scheduler.step()\n",
    "        ##aggregate loss\n",
    "        train_loss_total, _, _, _ = loss_logger.aggregate()\n",
    "        \n",
    "#         ##check for memory leakage\n",
    "#         for obj in gc.get_objects():\n",
    "#             try:\n",
    "#                 if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#                     print(type(obj), obj.size())\n",
    "#             except:\n",
    "#                 pass\n",
    "        ## validset -------------------------------------------------------------\n",
    "        net.eval()\n",
    "        loss_logger = LossLogger()\n",
    "        metric_logger = MetricLogger()\n",
    "        with torch.no_grad():\n",
    "            for batch_id, (images, labels) in enumerate(val_dl):\n",
    "                inputs = images.to(device=device, dtype=torch.float)\n",
    "                truth = labels.to(device=device, dtype=torch.float)\n",
    "                logit = net(inputs)\n",
    "                logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "                _ = loss_logger.update(logits, truth, mode='normal', rate=None)\n",
    "                metric_logger.update(logits, truth)\n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "        loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "        \n",
    "        ## callbacks -------------------------------------------------------------\n",
    "        val_metric = rec#loss_total\n",
    "        #scheduler.step(val_metric)\n",
    "        ##lr scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        #sometimes too early stop, force to at least train N epochs\n",
    "        if i_epoch>=-1:\n",
    "            if val_metric > best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                is_best = True\n",
    "                diff = 0\n",
    "            else:\n",
    "                is_best = False\n",
    "                diff += 1\n",
    "                if diff > early_stopping_round:\n",
    "                    logging.info('Early Stopping: val_metric does not increase %d rounds'%early_stopping_round)\n",
    "                    break\n",
    "        else:\n",
    "            is_best = False\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i_epoch,\n",
    "            'state_dict': net.module.state_dict() if multi_gpu is not None else net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            'metrics': {'train_loss': train_loss_total, 'val_loss': loss_total, \n",
    "                        'val_metric': val_metric}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=is_best, checkpoint=checkpoint_path)\n",
    "        \n",
    "        #logging loss/metric\n",
    "        logging.info('[EPOCH %05d]train_loss: %0.4f; val_loss: %0.4f; time elapsed: %0.1f min'%(i_epoch, \n",
    "                    train_loss_total, loss_total, (time.time()-t0)/60))\n",
    "        logging.info('[valid loss]grapheme: %0.4f, vowel: %0.4f, consonant: %0.4f'%(loss_grapheme, \n",
    "                                                                        loss_vowel, loss_consonant))\n",
    "        logging.info('[valid recall]total: %0.4f, grapheme: %0.4f, vowel: %0.4f, consonant: %0.4f'%(rec, \n",
    "                    rec_grapheme, rec_vowel, rec_consonant))\n",
    "        logging.info('='*80)\n",
    "\n",
    "def predict(test_dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# print(torch.__version__)\n",
    "\n",
    "# NUM_EPOCHS = 60\n",
    "\n",
    "# model = torchvision.models.resnet18(pretrained=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-3, \n",
    "#                                                 steps_per_epoch=1255, epochs=NUM_EPOCHS)#steps_per_epoch=len(dl)\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "# # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,50], gamma=0.1)\n",
    "\n",
    "# l = []\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     for i,batch in enumerate(range(1255)):\n",
    "#         #pass\n",
    "#         l.append(scheduler.get_lr())\n",
    "#         #train_batch(...)\n",
    "#     #l.append(scheduler.get_lr()[0])\n",
    "#         scheduler.step()\n",
    "\n",
    "# l[0::1255]\n",
    "# #l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class LossLogger(object):\n",
    "    \"\"\"loss for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        loss_logger = LossLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            loss = loss_logger.update(logits, truth)\n",
    "            loss.backward()\n",
    "        \n",
    "        loss, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss_grapheme = []\n",
    "        self.loss_vowel = []\n",
    "        self.loss_consonant = []\n",
    "\n",
    "    def update(self, logits, truth, mode='normal', rate=None):\n",
    "        \"\"\"\n",
    "        logits: logit splitted to [logit_grapheme, logit_vowel, logit_consonant]\n",
    "        truth: shape (N, 3)\n",
    "        \"\"\"\n",
    "        truth1, truth2, truth3, truth4, truth5, truth6, lam = \\\n",
    "                truth[0], truth[1], truth[2], truth[3], truth[4], truth[5], truth[6]\n",
    "        if mode=='normal':\n",
    "            criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "            #loss\n",
    "            loss_grapheme = F.cross_entropy(logits[0], truth[:,0].long())\n",
    "            loss_vowel = F.cross_entropy(logits[1], truth[:,1].long())\n",
    "            loss_consonant = F.cross_entropy(logits[2], truth[:,2].long())\n",
    "        elif mode=='ohem':\n",
    "            criterion = ohem_loss\n",
    "            loss_grapheme = lam * criterion(logits[0], truth1.long(), rate) + \\\n",
    "                (1 - lam) * criterion(logits[0], truth2.long(), rate)\n",
    "            loss_vowel = lam * criterion(logits[1], truth3.long(), rate) + \\\n",
    "                (1 - lam) * criterion(logits[1], truth4.long(), rate)\n",
    "            loss_consonant = lam * criterion(logits[2], truth5.long(), rate) + \\\n",
    "                (1 - lam) * criterion(logits[2], truth6.long(), rate)\n",
    "        loss = 0.5*loss_grapheme + 0.25*loss_vowel + 0.25*loss_consonant\n",
    "        #\n",
    "        self.loss_grapheme.append(loss_grapheme.item())\n",
    "        self.loss_vowel.append(loss_vowel.item())\n",
    "        self.loss_consonant.append(loss_consonant.item())\n",
    "        return loss\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\"\n",
    "        for print logging\n",
    "        \"\"\"\n",
    "        loss_grapheme = np.mean(self.loss_grapheme)\n",
    "        loss_vowel = np.mean(self.loss_vowel)\n",
    "        loss_consonant = np.mean(self.loss_consonant)\n",
    "        loss_total = np.mean(\n",
    "            0.5*np.array(self.loss_grapheme) + \\\n",
    "            0.25*np.array(self.loss_vowel) + \\\n",
    "            0.25*np.array(self.loss_consonant)\n",
    "        )\n",
    "        return loss_total, loss_grapheme, loss_vowel, loss_consonant\n",
    "\n",
    "def ohem_loss(cls_pred, cls_target, rate=0.7):\n",
    "    \"\"\"TODO: rate may change per EPOCH\"\"\"\n",
    "    batch_size = cls_pred.size(0) \n",
    "    ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
    "\n",
    "#     sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
    "#     keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*rate) )\n",
    "#     if keep_num < sorted_ohem_loss.size()[0]:\n",
    "#         keep_idx_cuda = idx[:keep_num]\n",
    "#         ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
    "#     cls_loss = ohem_cls_loss.sum() / keep_num\n",
    "    ohem_cls_loss_sorted, idx = torch.topk(ohem_cls_loss, k=int(rate * batch_size), \n",
    "                                           largest=True, sorted=True, out=None)\n",
    "    cls_loss = ohem_cls_loss_sorted.mean()\n",
    "    return cls_loss\n",
    "\n",
    "class MetricLogger(object):\n",
    "    \"\"\"recall, precision for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        metric_logger = MetricLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            metric_logger.update(logits, truth)\n",
    "        \n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pred_grapheme = torch.tensor([], dtype=torch.long).cuda(device)\n",
    "        self.pred_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.pred_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        \n",
    "        self.truth_grapheme = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "\n",
    "    def update(self, logits, truth):\n",
    "        pred = torch.argmax(logits[0], dim=1)\n",
    "        self.pred_grapheme = torch.cat([self.pred_grapheme, pred])\n",
    "        self.truth_grapheme = torch.cat([self.truth_grapheme, truth[:, 0].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[1], dim=1)\n",
    "        self.pred_vowel = torch.cat([self.pred_vowel, pred])\n",
    "        self.truth_vowel = torch.cat([self.truth_vowel, truth[:, 1].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[2], dim=1)\n",
    "        self.pred_consonant = torch.cat([self.pred_consonant, pred])\n",
    "        self.truth_consonant = torch.cat([self.truth_consonant, truth[:, 2].long()])\n",
    "\n",
    "    def aggregate(self):\n",
    "        rec_grapheme = recall_score(self.truth_grapheme.cpu().numpy(), \n",
    "                                    self.pred_grapheme.cpu().numpy(), \n",
    "                                    average='macro')\n",
    "        rec_vowel = recall_score(self.truth_vowel.cpu().numpy(), \n",
    "                                 self.pred_vowel.cpu().numpy(), \n",
    "                                 average='macro')\n",
    "        rec_consonant = recall_score(self.truth_consonant.cpu().numpy(), \n",
    "                                     self.pred_consonant.cpu().numpy(), \n",
    "                                     average='macro')\n",
    "        #rec = (2*rec_grapheme + 1*rec_vowel + 1*rec_consonant) / 4\n",
    "        rec = np.average([rec_grapheme, rec_vowel, rec_consonant], weights=[2,1,1])\n",
    "        return rec, rec_grapheme, rec_vowel, rec_consonant\n",
    "\n",
    "# #debug MetricLogger\n",
    "# #Epoch 0\n",
    "# loss_logger = LossLogger()\n",
    "# metric_logger = MetricLogger()\n",
    "# for batch_id, (images, labels) in enumerate(val_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if batch_id==10:\n",
    "#         break\n",
    "#     logit = net(inputs)\n",
    "#     logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "#     loss = loss_logger.update(logits, truth)\n",
    "#     metric_logger.update(logits, truth)\n",
    "# rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "# loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "# print(rec, rec_grapheme, rec_vowel, rec_consonant)\n",
    "# print(loss_total, loss_grapheme, loss_vowel, loss_consonant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from senet import se_resnext50_32x4d\n",
    "# from senet_v2 import se_resnext50_32x4d\n",
    "from efficientnet import EffiNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 0========\n",
      "[     0      1      2 ... 200835 200837 200839]\n",
      "[     4      6     12 ... 200832 200836 200838]\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00019999999999999966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00000]train_loss: 2.7047; val_loss: 0.8431; time elapsed: 7.7 min\n",
      "[valid loss]grapheme: 1.0416, vowel: 0.6096, consonant: 0.6796\n",
      "[valid recall]total: 0.7330, grapheme: 0.6436, vowel: 0.8879, consonant: 0.7570\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00023652259907873396]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00001]train_loss: 1.8154; val_loss: 0.4404; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.5120, vowel: 0.3318, consonant: 0.4057\n",
      "[valid recall]total: 0.8477, grapheme: 0.8433, vowel: 0.9396, consonant: 0.7645\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0003449788127787151]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00002]train_loss: 1.5375; val_loss: 0.3814; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.5104, vowel: 0.2314, consonant: 0.2734\n",
      "[valid recall]total: 0.8739, grapheme: 0.8528, vowel: 0.9448, consonant: 0.8453\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0005220677220911405]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00003]train_loss: 1.3944; val_loss: 0.3121; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.3967, vowel: 0.2345, consonant: 0.2205\n",
      "[valid recall]total: 0.9060, grapheme: 0.8958, vowel: 0.9603, consonant: 0.8721\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0007623995376525878]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00004]train_loss: 1.3127; val_loss: 0.3388; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.4679, vowel: 0.2332, consonant: 0.1861\n",
      "[valid recall]total: 0.9064, grapheme: 0.8718, vowel: 0.9614, consonant: 0.9207\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0010586596406750451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00005]train_loss: 1.2585; val_loss: 0.3073; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.4290, vowel: 0.2157, consonant: 0.1558\n",
      "[valid recall]total: 0.9222, grapheme: 0.8788, vowel: 0.9724, consonant: 0.9587\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001401831207020416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00006]train_loss: 1.2229; val_loss: 0.2954; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.3792, vowel: 0.2409, consonant: 0.1824\n",
      "[valid recall]total: 0.9194, grapheme: 0.9056, vowel: 0.9586, consonant: 0.9077\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0017814696387446574]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00007]train_loss: 1.2047; val_loss: 0.2488; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.3454, vowel: 0.1649, consonant: 0.1397\n",
      "[valid recall]total: 0.9315, grapheme: 0.9086, vowel: 0.9704, consonant: 0.9386\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002186020450650482]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00008]train_loss: 1.1873; val_loss: 0.5396; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.7570, vowel: 0.3948, consonant: 0.2496\n",
      "[valid recall]total: 0.8330, grapheme: 0.7918, vowel: 0.8643, consonant: 0.8839\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0026031709368127135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00009]train_loss: 1.1756; val_loss: 0.2418; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.3462, vowel: 0.1379, consonant: 0.1367\n",
      "[valid recall]total: 0.9326, grapheme: 0.9016, vowel: 0.9667, consonant: 0.9604\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0030202249139300156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00010]train_loss: 1.5542; val_loss: 0.4341; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.5945, vowel: 0.3471, consonant: 0.2003\n",
      "[valid recall]total: 0.8927, grapheme: 0.8654, vowel: 0.9020, consonant: 0.9379\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0034244891360020163]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00011]train_loss: 1.4959; val_loss: 0.3425; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.4466, vowel: 0.2689, consonant: 0.2080\n",
      "[valid recall]total: 0.9292, grapheme: 0.9066, vowel: 0.9671, consonant: 0.9364\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0038036596196082064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00012]train_loss: 1.4486; val_loss: 0.3226; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.4102, vowel: 0.2596, consonant: 0.2101\n",
      "[valid recall]total: 0.9321, grapheme: 0.9056, vowel: 0.9591, consonant: 0.9583\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004146196121785886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00013]train_loss: 1.4374; val_loss: 0.4298; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.5876, vowel: 0.3228, consonant: 0.2211\n",
      "[valid recall]total: 0.9191, grapheme: 0.8848, vowel: 0.9531, consonant: 0.9536\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004441673373085999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00014]train_loss: 1.4220; val_loss: 0.5024; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.7238, vowel: 0.3380, consonant: 0.2239\n",
      "[valid recall]total: 0.8876, grapheme: 0.8393, vowel: 0.9644, consonant: 0.9076\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0046810983758534454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00015]train_loss: 1.3530; val_loss: 0.2793; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.3808, vowel: 0.1974, consonant: 0.1580\n",
      "[valid recall]total: 0.9384, grapheme: 0.9085, vowel: 0.9728, consonant: 0.9637\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004857184110600309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00016]train_loss: 1.4052; val_loss: 0.3096; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.4035, vowel: 0.2373, consonant: 0.1940\n",
      "[valid recall]total: 0.9427, grapheme: 0.9242, vowel: 0.9703, consonant: 0.9519\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0049645713200818856]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00017]train_loss: 1.3767; val_loss: 0.2488; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.3227, vowel: 0.1985, consonant: 0.1513\n",
      "[valid recall]total: 0.9484, grapheme: 0.9291, vowel: 0.9705, consonant: 0.9649\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004999998397016159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00018]train_loss: 1.3508; val_loss: 0.2883; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.3721, vowel: 0.2274, consonant: 0.1817\n",
      "[valid recall]total: 0.9464, grapheme: 0.9352, vowel: 0.9727, consonant: 0.9426\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004992785049552961]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00019]train_loss: 1.3278; val_loss: 0.2584; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.3352, vowel: 0.2082, consonant: 0.1551\n",
      "[valid recall]total: 0.9497, grapheme: 0.9309, vowel: 0.9762, consonant: 0.9607\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004971608878267791]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00020]train_loss: 1.3161; val_loss: 0.2173; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2859, vowel: 0.1567, consonant: 0.1406\n",
      "[valid recall]total: 0.9506, grapheme: 0.9341, vowel: 0.9734, consonant: 0.9608\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004936588497613618]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00021]train_loss: 1.3088; val_loss: 0.4414; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.6429, vowel: 0.2646, consonant: 0.2151\n",
      "[valid recall]total: 0.8728, grapheme: 0.8250, vowel: 0.9587, consonant: 0.8823\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0048879200678518114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00022]train_loss: 1.2768; val_loss: 0.2507; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.3231, vowel: 0.2093, consonant: 0.1472\n",
      "[valid recall]total: 0.9475, grapheme: 0.9295, vowel: 0.9789, consonant: 0.9522\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004825876196296287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00023]train_loss: 1.2724; val_loss: 0.2112; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.2819, vowel: 0.1525, consonant: 0.1283\n",
      "[valid recall]total: 0.9505, grapheme: 0.9347, vowel: 0.9705, consonant: 0.9619\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0047508044103534664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00024]train_loss: 1.2732; val_loss: 0.2078; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2885, vowel: 0.1332, consonant: 0.1208\n",
      "[valid recall]total: 0.9521, grapheme: 0.9318, vowel: 0.9756, consonant: 0.9692\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004663125210911027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00025]train_loss: 1.2396; val_loss: 0.4008; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.6193, vowel: 0.2164, consonant: 0.1483\n",
      "[valid recall]total: 0.8942, grapheme: 0.8338, vowel: 0.9688, consonant: 0.9403\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004563329716979042]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00026]train_loss: 1.2409; val_loss: 0.3875; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.5164, vowel: 0.3149, consonant: 0.2023\n",
      "[valid recall]total: 0.9321, grapheme: 0.9078, vowel: 0.9673, consonant: 0.9456\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004451976914776603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00027]train_loss: 1.2290; val_loss: 0.2129; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2917, vowel: 0.1436, consonant: 0.1244\n",
      "[valid recall]total: 0.9512, grapheme: 0.9279, vowel: 0.9818, consonant: 0.9675\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004329690526672687]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00028]train_loss: 1.2023; val_loss: 0.2949; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.3703, vowel: 0.2752, consonant: 0.1637\n",
      "[valid recall]total: 0.9502, grapheme: 0.9356, vowel: 0.9708, consonant: 0.9589\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00419715551751931]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00029]train_loss: 1.2285; val_loss: 0.2246; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.2885, vowel: 0.1907, consonant: 0.1309\n",
      "[valid recall]total: 0.9602, grapheme: 0.9431, vowel: 0.9791, consonant: 0.9756\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004055114257946095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00030]train_loss: 1.1897; val_loss: 0.2322; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.3143, vowel: 0.1644, consonant: 0.1360\n",
      "[valid recall]total: 0.9472, grapheme: 0.9229, vowel: 0.9788, consonant: 0.9642\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0039043623661068868]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00031]train_loss: 1.1956; val_loss: 0.2130; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2719, vowel: 0.1703, consonant: 0.1379\n",
      "[valid recall]total: 0.9640, grapheme: 0.9500, vowel: 0.9785, consonant: 0.9774\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003745744251170077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00032]train_loss: 1.1385; val_loss: 0.1484; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.1894, vowel: 0.1141, consonant: 0.1006\n",
      "[valid recall]total: 0.9703, grapheme: 0.9582, vowel: 0.9848, consonant: 0.9799\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003580148383514985]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00033]train_loss: 1.1370; val_loss: 0.2445; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.3113, vowel: 0.2161, consonant: 0.1393\n",
      "[valid recall]total: 0.9640, grapheme: 0.9477, vowel: 0.9840, consonant: 0.9766\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0034085023181274206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00034]train_loss: 1.1090; val_loss: 0.2192; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.2811, vowel: 0.1821, consonant: 0.1323\n",
      "[valid recall]total: 0.9685, grapheme: 0.9539, vowel: 0.9854, consonant: 0.9808\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003231767499069964]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00035]train_loss: 1.1342; val_loss: 0.1463; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.1894, vowel: 0.1117, consonant: 0.0949\n",
      "[valid recall]total: 0.9693, grapheme: 0.9549, vowel: 0.9854, consonant: 0.9820\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003050933874128778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00036]train_loss: 1.1365; val_loss: 0.1883; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2458, vowel: 0.1451, consonant: 0.1166\n",
      "[valid recall]total: 0.9598, grapheme: 0.9442, vowel: 0.9771, consonant: 0.9737\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002867014349802023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00037]train_loss: 1.0960; val_loss: 0.1455; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.1888, vowel: 0.1094, consonant: 0.0951\n",
      "[valid recall]total: 0.9677, grapheme: 0.9531, vowel: 0.9862, consonant: 0.9785\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00268103911768924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00038]train_loss: 1.0967; val_loss: 0.1793; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2263, vowel: 0.1541, consonant: 0.1105\n",
      "[valid recall]total: 0.9718, grapheme: 0.9586, vowel: 0.9860, consonant: 0.9841\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0024940498840614004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00039]train_loss: 1.0847; val_loss: 0.1820; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.2318, vowel: 0.1452, consonant: 0.1193\n",
      "[valid recall]total: 0.9676, grapheme: 0.9557, vowel: 0.9840, consonant: 0.9752\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002307094034933627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00040]train_loss: 1.0884; val_loss: 0.1991; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.2399, vowel: 0.1595, consonant: 0.1573\n",
      "[valid recall]total: 0.9598, grapheme: 0.9417, vowel: 0.9801, consonant: 0.9756\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0021212187693238705]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00041]train_loss: 1.0380; val_loss: 0.1602; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.2011, vowel: 0.1373, consonant: 0.1010\n",
      "[valid recall]total: 0.9739, grapheme: 0.9621, vowel: 0.9862, consonant: 0.9852\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001937465233559005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00042]train_loss: 1.0406; val_loss: 0.1327; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.1683, vowel: 0.1066, consonant: 0.0874\n",
      "[valid recall]total: 0.9742, grapheme: 0.9619, vowel: 0.9867, consonant: 0.9865\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0017568626894839828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00043]train_loss: 1.0379; val_loss: 0.1918; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2518, vowel: 0.1526, consonant: 0.1109\n",
      "[valid recall]total: 0.9593, grapheme: 0.9386, vowel: 0.9818, consonant: 0.9783\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0015804227492397258]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00044]train_loss: 1.0217; val_loss: 0.1324; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.1637, vowel: 0.1103, consonant: 0.0918\n",
      "[valid recall]total: 0.9753, grapheme: 0.9648, vowel: 0.9866, consonant: 0.9850\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001409133708902623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00045]train_loss: 1.0258; val_loss: 0.2102; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.2604, vowel: 0.1910, consonant: 0.1287\n",
      "[valid recall]total: 0.9703, grapheme: 0.9576, vowel: 0.9857, consonant: 0.9803\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0012439550127246893]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00046]train_loss: 1.0446; val_loss: 0.1031; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.1243, vowel: 0.0874, consonant: 0.0763\n",
      "[valid recall]total: 0.9784, grapheme: 0.9694, vowel: 0.9880, consonant: 0.9866\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001085811878981954]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00047]train_loss: 1.0429; val_loss: 0.1773; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.2191, vowel: 0.1509, consonant: 0.1200\n",
      "[valid recall]total: 0.9698, grapheme: 0.9561, vowel: 0.9843, consonant: 0.9826\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0009355901175333936]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00048]train_loss: 1.0299; val_loss: 0.1578; time elapsed: 8.2 min\n",
      "[valid loss]grapheme: 0.1991, vowel: 0.1319, consonant: 0.1012\n",
      "[valid recall]total: 0.9730, grapheme: 0.9600, vowel: 0.9872, consonant: 0.9849\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0007941311681189094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00049]train_loss: 0.9988; val_loss: 0.1505; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.1812, vowel: 0.1387, consonant: 0.1010\n",
      "[valid recall]total: 0.9766, grapheme: 0.9679, vowel: 0.9872, consonant: 0.9833\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0006622273871884255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00050]train_loss: 1.6882; val_loss: 0.3013; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.3789, vowel: 0.2656, consonant: 0.1817\n",
      "[valid recall]total: 0.9776, grapheme: 0.9670, vowel: 0.9887, consonant: 0.9879\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0005406176096620473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00051]train_loss: 1.6759; val_loss: 0.2369; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2797, vowel: 0.2012, consonant: 0.1869\n",
      "[valid recall]total: 0.9793, grapheme: 0.9706, vowel: 0.9890, consonant: 0.9872\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0004299830104813085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00052]train_loss: 1.6094; val_loss: 0.2129; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.2543, vowel: 0.1687, consonant: 0.1743\n",
      "[valid recall]total: 0.9780, grapheme: 0.9682, vowel: 0.9886, consonant: 0.9870\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00033094328913222813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00053]train_loss: 1.6551; val_loss: 0.4936; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.6502, vowel: 0.3868, consonant: 0.2872\n",
      "[valid recall]total: 0.9792, grapheme: 0.9701, vowel: 0.9893, consonant: 0.9873\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0002440531985119155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00054]train_loss: 1.5661; val_loss: 0.2845; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.3386, vowel: 0.2428, consonant: 0.2180\n",
      "[valid recall]total: 0.9802, grapheme: 0.9718, vowel: 0.9900, consonant: 0.9873\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0001697994375816017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00055]train_loss: 1.6198; val_loss: 0.5078; time elapsed: 8.0 min\n",
      "[valid loss]grapheme: 0.6655, vowel: 0.4021, consonant: 0.2981\n",
      "[valid recall]total: 0.9800, grapheme: 0.9721, vowel: 0.9901, consonant: 0.9856\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0001085979252113749]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00056]train_loss: 1.5648; val_loss: 0.3110; time elapsed: 8.1 min\n",
      "[valid loss]grapheme: 0.3657, vowel: 0.2719, consonant: 0.2405\n",
      "[valid recall]total: 0.9805, grapheme: 0.9719, vowel: 0.9896, consonant: 0.9888\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [6.079147048664102e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00057]train_loss: 1.6319; val_loss: 0.1894; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.2113, vowel: 0.1666, consonant: 0.1682\n",
      "[valid recall]total: 0.9810, grapheme: 0.9725, vowel: 0.9899, consonant: 0.9889\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [2.664785252569453e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00058]train_loss: 1.6272; val_loss: 0.3597; time elapsed: 7.9 min\n",
      "[valid loss]grapheme: 0.4372, vowel: 0.3170, consonant: 0.2472\n",
      "[valid recall]total: 0.9806, grapheme: 0.9722, vowel: 0.9900, consonant: 0.9880\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [6.358320563928247e-06]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to step 75302 times. The specified number of total steps is 75300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e75ed5a5c2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#3. train session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_and_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-78f002206ca8>\u001b[0m in \u001b[0;36mtrain_and_valid\u001b[0;34m(net, train_dl, val_dl)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m##lr scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;31m##aggregate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mtrain_loss_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mget_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_num\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             raise ValueError(\"Tried to step {} times. The specified number of total steps is {}\"\n\u001b[0;32m--> 978\u001b[0;31m                              .format(step_num + 1, self.total_steps))\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to step 75302 times. The specified number of total steps is 75300"
     ]
    }
   ],
   "source": [
    "#### training for 5 folds here ####\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "    if fold in [0]:#train 1 fold for testing ideas\n",
    "        print('========training fold %d========'%fold)\n",
    "        print(train_idx)\n",
    "        print(valid_idx)\n",
    "        \n",
    "        #checkpoint_path = '../checkpoint/v3-fold'+str(fold)\n",
    "        #print('checkpoint_path: ', checkpoint_path)\n",
    "        \n",
    "        #1.1 data\n",
    "        train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "        train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "        #1.2 Dataset, DataLoader\n",
    "        train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "        val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "        \n",
    "        #2. model\n",
    "        #net = se_resnext50_32x4d(num_classes=num_classes, pretrained=None).cuda(device=device)\n",
    "        #net = se_resnext50_32x4d(num_classes=num_classes, pretrained='imagenet').cuda(device=device)\n",
    "        net = EffiNet(model='b3').cuda(device=device)\n",
    "\n",
    "        #3. train session\n",
    "        train_and_valid(net, train_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold0 - val_loss: 0.0621; CV: 0.9874, LB=0.9801\n",
    "#fold1 - val_loss: 0.0627; CV: 0.9861, LB=0.9796\n",
    "#fold2 - val_loss: 0.0674; CV: 0.9875, LB=0.9789\n",
    "#fold3 - val_loss: 0.0664; CV: 0.9853, LB=0.9787\n",
    "#fold4 - val_loss: 0.0670; CV: 0.9854, LB="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 0\n",
    "# [     0      1      2 ... 200835 200837 200839]\n",
    "# [     4      6     12 ... 200832 200836 200838]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check dataset/network/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "#     if fold in [0]:#train 1 fold for testing ideas\n",
    "#         print('========training fold %d========'%fold)\n",
    "#         print(train_idx)\n",
    "#         print(valid_idx)\n",
    "        \n",
    "#         #1.1 data\n",
    "#         train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "#         train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "#         #1.2 Dataset, DataLoader\n",
    "#         train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "#         val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "\n",
    "# ####\n",
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if np.random.rand()<1.0:\n",
    "#         print('cutmix')\n",
    "#         inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "#     else:\n",
    "#         print('mixup')\n",
    "#         inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "#     if batch_id==1:\n",
    "#         break\n",
    "\n",
    "# #print(inputs.shape, truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_inputs = inputs.cpu().numpy()[np.random.choice(BATCH_SIZE, 20), :, :, :]\n",
    "# fig,axes = plt.subplots(5,4, figsize=(10,8))\n",
    "# for i in range(20):\n",
    "#     axes[i//4, i%4].imshow(show_inputs[i, 0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import efficientnet\n",
    "# importlib.reload(efficientnet)\n",
    "\n",
    "# import torch\n",
    "\n",
    "# #from senet_v2 import se_resnext50_32x4d\n",
    "# from efficientnet import EffiNet\n",
    "\n",
    "# #net = se_resnext50_32x4d(num_classes=186, pretrained='imagenet', debug=True).cuda(device='cuda:2')\n",
    "# net = EffiNet(model='b3', debug=True).cuda(device='cuda:3')\n",
    "\n",
    "# inputs = torch.rand((128, 1, 137, 236), dtype=torch.float).cuda(device='cuda:3')\n",
    "# print(inputs.size())\n",
    "\n",
    "# logit = net(inputs)\n",
    "# print(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
