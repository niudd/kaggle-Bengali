{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define environment\n",
    "ON_KAGGLE = False\n",
    "TRAIN_PREDICT = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if ON_KAGGLE:\n",
    "    sys.path.append('../input/bengali-util/script/')\n",
    "    sys.path.append('../input/bengali-util/')\n",
    "    from script.utils import seed_everything, set_n_get_device\n",
    "else:\n",
    "    from utils import seed_everything, set_n_get_device\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "print('torch', torch.__version__)\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    #load utility scripts\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "debug = False\n",
    "SEED = 42\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 256\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    NUM_WORKERS = 2\n",
    "else:\n",
    "    NUM_WORKERS = 16\n",
    "\n",
    "device = set_n_get_device(\"2,3\", data_device_id=\"cuda:0\")#IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0,1]\n",
    "\n",
    "if debug:\n",
    "    LOG_PATH = '../logging/v3-debug.log'\n",
    "else:\n",
    "    LOG_PATH = '../logging/v2-5folds.log'\n",
    "\n",
    "#checkpoint_path = '../checkpoint/v3'\n",
    "warm_start, last_checkpoint_path = False, '../checkpoint/v2/last.pth.tar'\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "early_stopping_round = 20\n",
    "LearningRate = 5e-3\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "n_grapheme=168\n",
    "n_vowel=11\n",
    "n_consonant=7\n",
    "#n_combo = 1295\n",
    "\n",
    "#num_classes = n_grapheme+n_vowel+n_consonant+n_combo\n",
    "num_classes = n_grapheme+n_vowel+n_consonant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "1. pytorch Dataset, data augmentation, DataLoader, train-test-split/KFold, \n",
    "2. network\n",
    "3. training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200840, 137, 236), (200840, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ON_KAGGLE:\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    train_df_list = [pd.read_feather('../data/processed/train_image_data_%d.feather'%i) for i in range(4)]\n",
    "    train_images_arr = np.concatenate([df.iloc[:, 1:].values.reshape(-1, IMG_HEIGHT, IMG_WIDTH) \n",
    "                                       for df in train_df_list], axis=0)\n",
    "    train_label_df = pd.read_csv('../data/raw/train.csv')\n",
    "    train_label_arr = train_label_df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "\n",
    "train_images_arr.shape, train_label_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import augmentation\n",
    "# importlib.reload(augmentation)\n",
    "# from augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##experiment a lot of augmentations\n",
    "# imgs = train_images_arr[np.random.choice(200840, 4), :]\n",
    "# imgs = np.clip((255-imgs)/255, 0, 1)\n",
    "\n",
    "# fig,axes = plt.subplots(4,2, figsize=(10,8))\n",
    "# for i in range(4):\n",
    "#     image = imgs[i]\n",
    "#     img_aug = do_random_shift_scale_crop_pad2(image, limit=0.2)\n",
    "#     axes[i, 0].imshow(image, cmap='binary')\n",
    "#     axes[i, 1].imshow(img_aug, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 1. encode grapheme characters to index 2. use it as sampler\n",
    "# unique_char = train_label_df['grapheme'].unique()\n",
    "# char2ind = dict([(char,i) for i,char in enumerate(unique_char)])\n",
    "# grapheme_ind = [char2ind[char] for char in train_label_df['grapheme']]\n",
    "# cls_w_dict = pd.value_counts(grapheme_ind)\n",
    "# cls_w_dict /= 100\n",
    "# cls_w_dict = cls_w_dict.to_dict()\n",
    "# cls_w = [cls_w_dict[i] for i in grapheme_ind]\n",
    "\n",
    "\n",
    "##check onehot correct?\n",
    "#train_label_df.loc[train_label_arr[:,3]==1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation --cutmix, mixup\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    #cut_rat = np.sqrt(1. - lam)\n",
    "    cut_rat = lam\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform, ignore edge area\n",
    "    cx = np.random.randint(W//4, W*3//4)\n",
    "    cy = np.random.randint(H//4, H*3//4)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    #print(bbx1, bby1, bbx2, bby2)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(data, target, alpha=1.0):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    #lam = np.random.beta(alpha, alpha)\n",
    "    lam = np.sqrt(np.random.rand()/4)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    #data[:, :, bbx1:bbx2, bby1:bby2] += data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    #data = torch.clamp(data, 0, 1)\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, \n",
    "               targets3, shuffled_targets3, lam]\n",
    "    return data, targets\n",
    "\n",
    "def mixup(data, target, alpha=0.4):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, \n",
    "               targets3, shuffled_targets3, lam]\n",
    "\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "#     if fold in [0]:#train 1 fold for testing ideas\n",
    "#         print('========training fold %d========'%fold)\n",
    "#         print(train_idx)\n",
    "#         print(valid_idx)\n",
    "        \n",
    "#         #1.1 data\n",
    "#         train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "#         train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "#         #1.2 Dataset, DataLoader\n",
    "#         train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "#         val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "\n",
    "# ####\n",
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if np.random.rand()<-10:\n",
    "#         inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "#     else:\n",
    "#         inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "#     if batch_id==1:\n",
    "#         break\n",
    "\n",
    "# #print(inputs.shape, truth.shape)\n",
    "\n",
    "# show_inputs = inputs.cpu().numpy()[np.random.choice(BATCH_SIZE, 20, replace=False), :, :, :]\n",
    "# fig,axes = plt.subplots(5,4, figsize=(10,8))\n",
    "# for i in range(20):\n",
    "#     axes[i//4, i%4].imshow(show_inputs[i, 0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##crop to 128x128\n",
    "# def bbox(img):\n",
    "#     rows = np.any(img, axis=1)\n",
    "#     cols = np.any(img, axis=0)\n",
    "#     rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#     cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#     return rmin, rmax, cmin, cmax\n",
    "\n",
    "# def crop_resize(img0, size=128, pad=16):\n",
    "#     #crop a box around pixels large than the threshold \n",
    "#     #some images contain line at the sides\n",
    "#     ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "#     #cropping may cut too much, so we need to add it back\n",
    "#     xmin = xmin - 13 if (xmin > 13) else 0\n",
    "#     ymin = ymin - 10 if (ymin > 10) else 0\n",
    "#     xmax = xmax + 13 if (xmax < IMG_WIDTH - 13) else IMG_WIDTH\n",
    "#     ymax = ymax + 10 if (ymax < IMG_HEIGHT - 10) else IMG_HEIGHT\n",
    "#     img = img0[ymin:ymax,xmin:xmax]\n",
    "#     #remove lo intensity pixels as noise\n",
    "#     img[img < 28] = 0\n",
    "#     lx, ly = xmax-xmin,ymax-ymin\n",
    "#     l = max(lx,ly) + pad\n",
    "#     #make sure that the aspect ratio is kept in rescaling\n",
    "#     img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "#     return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img0 = train_images_arr[0]\n",
    "#img0 = 255 - img0\n",
    "#img0 = (img0*(255.0/img0.max())).astype(np.uint8)\n",
    "#plt.imshow(crop_resize(rotate(img0, angle=20, reshape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### make up a weighted/balanced data sampler --for mixup/cutmix ####\n",
    "# #weights for 168 classes--graphene_root\n",
    "# import torch.utils.data\n",
    "# _weights = [6.8,6.9,3,3.1,3,5.7,3.2,6.5,6.4,2.3,6.6,6.6,6.8,0.2,1.3,0.9,1.1,1.3,0.6,3.6,3,1.1,0.3,0.2,3,0.9,5.8,3.3,1.3,0.4,2.3,1.3,0.9,7.4,3.6,2.1,1,3.5,0.3,1.6,1.3,3.3,0.5,0.3,0.9,6.9,1.7,2.2,0.7,3.1,1.4,3.1,1.1,0.3,1.7,0.6,0.4,1.6,0.8,0.4,2.3,1.7,1.2,6.7,0.2,0.7,1.3,2.1,1.6,1.3,1,0.3,0.2,7.7,0.7,0.9,0.5,1,3.4,0.3,2.2,0.3,3.4,0.7,2.2,0.7,0.5,6,1.3,0.4,1.6,0.6,0.9,1.6,1,1.4,0.2,2.1,1.6,2.2,2.2,0.9,7.1,0.3,6.2,6.6,1.3,0.2,6.3,1.1,2.9,1.3,1.1,0.2,6.7,0.2,2.3,0.7,0.9,0.7,0.8,2.2,0.4,0.5,0.5,1.2,6.3,1.1,1.1,1,6.9,2.3,1,0.2,1.6,1.6,1,1.8,1.1,0.4,1.1,0.6,0.9,1.6,1.6,3.2,3.3,0.2,0.6,0.4,0.4,0.8,1.6,0.6,1.4,1.1,1.3,3.1,7,0.3,2.1,3.2,2.2,6.1,6.1,0.9,3.3,0.6]\n",
    "# weights_dict = dict(zip(range(len(_weights)), _weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import set_logger, save_checkpoint, load_checkpoint\n",
    "import logging\n",
    "#import gc\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import cv2\n",
    "from augmentation import *\n",
    "\n",
    "\n",
    "def prepare_dataset(img_arr, label_arr, mode='train', debug=False):\n",
    "    \"\"\"\n",
    "    mode: 'train', 'valid', 'test'\n",
    "    \"\"\"\n",
    "    if debug:#for debug, sample 1/10 data\n",
    "        n = img_arr.shape[0]\n",
    "        sid = np.random.choice(n, size=n//5, replace=False)\n",
    "        img_arr = img_arr[sid]\n",
    "        label_arr = label_arr[sid]\n",
    "\n",
    "    if mode=='train':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "\n",
    "#     if mode=='train':\n",
    "#         ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "#         weights = [weights_dict[c] for c in label_arr[:,0]]\n",
    "#         sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=len(ds), replacement=True)\n",
    "#         dl = DataLoader(ds,\n",
    "#                         batch_size=BATCH_SIZE,\n",
    "#                         shuffle=False,\n",
    "#                         sampler=sampler,\n",
    "#                         num_workers=NUM_WORKERS,\n",
    "#                         drop_last=True\n",
    "#                        )\n",
    "#         return dl\n",
    "\n",
    "    elif mode=='valid':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "    elif mode=='test':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='test', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=False\n",
    "                       ) \n",
    "    return dl\n",
    "\n",
    "class DatasetV1(Dataset):\n",
    "    \"\"\"plain\"\"\"\n",
    "    def __init__(self, inputs, outputs, mode='train', augmentation=False):\n",
    "        \"\"\"\n",
    "        inputs: images, (N, H, W)\n",
    "        outputs: label, (N, 3)\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.mode = mode \n",
    "        self.augmentation = augmentation\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: augmentation, preprocessing\n",
    "        inputs, outputs = self.inputs[idx], self.outputs[idx]\n",
    "        inputs = np.clip((255-inputs)/255.0, 0, 1)\n",
    "\n",
    "#         inputs = cv2.resize(inputs, (224,224))\n",
    "#         inputs = np.clip(inputs, 0, 1)\n",
    "\n",
    "        #crop\n",
    "#         inputs = 255-inputs\n",
    "#         inputs = crop_resize(inputs)\n",
    "#         inputs = np.clip(inputs/255.0, 0, 1)\n",
    "\n",
    "        if self.augmentation:\n",
    "            inputs = self.do_augmentation(inputs)\n",
    "        \n",
    "        inputs = np.expand_dims(inputs, 0)#(224,224)-->(1,224,224)\n",
    "        inputs = inputs.astype(np.float32)\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "    \n",
    "    def do_augmentation(self, image):\n",
    "        #rotate\n",
    "        #if np.random.rand() < 0.5:\n",
    "        #angle = np.random.randint(0, 40) - 20\n",
    "        #inputs = rotate(inputs, angle, reshape=False)\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_projective(image, 0.4),#0.4\n",
    "            lambda image : do_random_perspective(image, 0.4),#0.4\n",
    "            lambda image : do_random_scale(image, 0.4),#0.4\n",
    "            lambda image : do_random_rotate(image, 0.4),#0.4\n",
    "            lambda image : do_random_shear_x(image, 0.5),#0.5\n",
    "            lambda image : do_random_shear_y(image, 0.4),#0.4\n",
    "            lambda image : do_random_stretch_x(image, 0.5),#0.5\n",
    "            lambda image : do_random_stretch_y(image, 0.5),#0.5\n",
    "            lambda image : do_random_grid_distortion(image, 0.4),#0.4\n",
    "            lambda image : do_random_custom_distortion1(image, 0.5),#0.5\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_erode(image, 0.4),#0.4\n",
    "            lambda image : do_random_dilate(image, 0.4),#0.4\n",
    "            lambda image : do_random_sprinkle(image, 0.5),#0.5\n",
    "            #lambda image : do_random_line(image, 0.2),\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_contast(image, 0.5),#0.5\n",
    "            lambda image : do_random_block_fade(image, 0.5),#0.5\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "        \n",
    "#         if np.random.rand()<1.1:\n",
    "#             image = do_random_shift_scale_crop_pad2(image, limit=0.1)\n",
    "#         else:\n",
    "#             image = do_shift_scale_rotate2(image, angle=np.random.uniform(0, 10))\n",
    "        return image\n",
    "\n",
    "def train_and_valid(net, train_dl, val_dl):\n",
    "    \"\"\"train one fold\n",
    "    \n",
    "    [settings]...\n",
    "    \n",
    "    [Epoch i]\n",
    "        [Trainset]\n",
    "            [Batch j]\n",
    "        [Validset]\n",
    "            [Batch k]\n",
    "        [Logging/Checkpoint]\n",
    "    \"\"\"\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #1. optim\n",
    "    train_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    optimizer = torch.optim.Adam(train_params, lr=LearningRate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                          factor=0.5, patience=5, \n",
    "                                                          verbose=False, threshold=0.0001, \n",
    "                                                          threshold_mode='rel', cooldown=0, \n",
    "                                                          min_lr=0, eps=1e-08)\n",
    "    #1.1 warm-start\n",
    "    if warm_start:\n",
    "        logging.info('warm_start: '+last_checkpoint_path)\n",
    "        net, _ = load_checkpoint(last_checkpoint_path, net)\n",
    "    \n",
    "    #2. using multi GPU\n",
    "    if multi_gpu is not None:\n",
    "        net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "    #3. train\n",
    "    diff = 0\n",
    "    best_val_metric = np.inf\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i_epoch in range(NUM_EPOCHS):\n",
    "        t0 = time.time()\n",
    "        ## trainset -------------------------------------------------------------\n",
    "        net.train()\n",
    "        loss_logger = LossLogger()\n",
    "        for batch_id, (images, labels) in enumerate(train_dl):\n",
    "            inputs = images.to(device=device, dtype=torch.float)\n",
    "            truth = labels.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            #do cutmix/mixup\n",
    "            if i_epoch<-1:#5\n",
    "                mode = 0\n",
    "                do_nothing = True\n",
    "            else:\n",
    "                mode = 1\n",
    "                if np.random.rand()<0.5:\n",
    "                    inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "                else:\n",
    "                    inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "            \n",
    "            logit = net(inputs)\n",
    "            logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "            train_loss = loss_logger.update(logits, truth, mode=mode)\n",
    "            #grandient accumulation step=2\n",
    "            acc_step = 1\n",
    "            if acc_step>1:\n",
    "                train_loss = train_loss / acc_step\n",
    "            train_loss.backward()\n",
    "            if (batch_id+1)%acc_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        train_loss_total, _, _, _ = loss_logger.aggregate()\n",
    "        \n",
    "#         ##check for memory leakage\n",
    "#         for obj in gc.get_objects():\n",
    "#             try:\n",
    "#                 if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#                     print(type(obj), obj.size())\n",
    "#             except:\n",
    "#                 pass\n",
    "        ## validset -------------------------------------------------------------\n",
    "        net.eval()\n",
    "        loss_logger = LossLogger()\n",
    "        metric_logger = MetricLogger()\n",
    "        with torch.no_grad():\n",
    "            for batch_id, (images, labels) in enumerate(val_dl):\n",
    "                inputs = images.to(device=device, dtype=torch.float)\n",
    "                truth = labels.to(device=device, dtype=torch.float)\n",
    "                logit = net(inputs)\n",
    "                logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "                _ = loss_logger.update(logits, truth, mode=0)\n",
    "                metric_logger.update(logits, truth)\n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "        loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "        \n",
    "        ## callbacks -------------------------------------------------------------\n",
    "        val_metric = loss_total#rec\n",
    "        scheduler.step(val_metric)\n",
    "        \n",
    "        #sometimes too early stop, force to at least train N epochs\n",
    "        if i_epoch>=40:#-1\n",
    "            if val_metric < best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                is_best = True\n",
    "                diff = 0\n",
    "            else:\n",
    "                is_best = False\n",
    "                diff += 1\n",
    "                if diff > early_stopping_round:\n",
    "                    logging.info('Early Stopping: val_metric does not increase %d rounds'%early_stopping_round)\n",
    "                    break\n",
    "        else:\n",
    "            is_best = False\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i_epoch,\n",
    "            'state_dict': net.module.state_dict() if multi_gpu is not None else net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            'metrics': {'train_loss': train_loss_total, 'val_loss': loss_total, \n",
    "                        'val_metric': val_metric}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=is_best, checkpoint=checkpoint_path)\n",
    "        \n",
    "        #logging loss/metric\n",
    "        logging.info('[EPOCH %05d]train_loss: %0.4f; val_loss: %0.4f; time elapsed: %0.1f min'%(i_epoch, \n",
    "                    train_loss_total, loss_total, (time.time()-t0)/60))\n",
    "        logging.info('[valid loss]grapheme: %0.4f, vowel: %0.4f, consonant: %0.4f'%(loss_grapheme, \n",
    "                                                                        loss_vowel, loss_consonant))\n",
    "        logging.info('[valid recall]total: %0.4f, grapheme: %0.4f, vowel: %0.4f, consonant: %0.4f'%(rec, \n",
    "                    rec_grapheme, rec_vowel, rec_consonant))\n",
    "        logging.info('='*80)\n",
    "\n",
    "def predict(test_dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# #print(torch.__version__)\n",
    "# from one_cycle_lr import OneCycleLR\n",
    "\n",
    "# NUM_EPOCHS=100\n",
    "\n",
    "# model = torchvision.models.resnet18(pretrained=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "# scheduler = OneCycleLR(optimizer, max_lr=5e-3, steps_per_epoch=1255, epochs=NUM_EPOCHS)#steps_per_epoch=len(dl)\n",
    "\n",
    "# l = []\n",
    "# for epoch in range(100):\n",
    "#     for i,batch in enumerate(range(1255)):\n",
    "#         #l.append(scheduler.get_lr())\n",
    "#         #train_batch(...)\n",
    "#         scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class LossLogger(object):\n",
    "    \"\"\"loss for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        loss_logger = LossLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            loss = loss_logger.update(logits, truth)\n",
    "            loss.backward()\n",
    "        \n",
    "        loss, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss_grapheme = []\n",
    "        self.loss_vowel = []\n",
    "        self.loss_consonant = []\n",
    "\n",
    "    def update(self, logits, truth, mode=0):\n",
    "        \"\"\"\n",
    "        logits: logit splitted to [logit_grapheme, logit_vowel, logit_consonant]\n",
    "        truth: shape (N, 3)\n",
    "        \"\"\"\n",
    "        if mode==0:\n",
    "            #loss\n",
    "            loss_grapheme = F.cross_entropy(logits[0], truth[:,0].long())\n",
    "            loss_vowel = F.cross_entropy(logits[1], truth[:,1].long())\n",
    "            loss_consonant = F.cross_entropy(logits[2], truth[:,2].long())\n",
    "            loss = 0.5*loss_grapheme + 0.25*loss_vowel + 0.25*loss_consonant\n",
    "            #\n",
    "            self.loss_grapheme.append(loss_grapheme.item())\n",
    "            self.loss_vowel.append(loss_vowel.item())\n",
    "            self.loss_consonant.append(loss_consonant.item())\n",
    "            return loss\n",
    "        elif mode==1:#cutmix/mixup loss\n",
    "            truth1, truth2, truth3, truth4, truth5, truth6, lam = \\\n",
    "                    truth[0], truth[1], truth[2], truth[3], truth[4], truth[5], truth[6]\n",
    "            criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "            loss_grapheme = lam * criterion(logits[0], truth1.long()) + \\\n",
    "                (1 - lam) * criterion(logits[0], truth2.long())\n",
    "            loss_vowel = lam * criterion(logits[1], truth3.long()) + \\\n",
    "                (1 - lam) * criterion(logits[1], truth4.long())\n",
    "            loss_consonant = lam * criterion(logits[2], truth5.long()) + \\\n",
    "                (1 - lam) * criterion(logits[2], truth6.long())\n",
    "            loss = 0.5*loss_grapheme + 0.25*loss_vowel + 0.25*loss_consonant\n",
    "            #\n",
    "            self.loss_grapheme.append(loss_grapheme.item())\n",
    "            self.loss_vowel.append(loss_vowel.item())\n",
    "            self.loss_consonant.append(loss_consonant.item())\n",
    "            return loss\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\"\n",
    "        for print logging\n",
    "        \"\"\"\n",
    "        loss_grapheme = np.mean(self.loss_grapheme)\n",
    "        loss_vowel = np.mean(self.loss_vowel)\n",
    "        loss_consonant = np.mean(self.loss_consonant)\n",
    "        loss_total = np.mean(\n",
    "            0.5*np.array(self.loss_grapheme) + \\\n",
    "            0.25*np.array(self.loss_vowel) + \\\n",
    "            0.25*np.array(self.loss_consonant)\n",
    "        )\n",
    "        return loss_total, loss_grapheme, loss_vowel, loss_consonant\n",
    "\n",
    "class MetricLogger(object):\n",
    "    \"\"\"recall, precision for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        metric_logger = MetricLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            metric_logger.update(logits, truth)\n",
    "        \n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pred_grapheme = torch.tensor([], dtype=torch.long).cuda(device)\n",
    "        self.pred_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.pred_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        \n",
    "        self.truth_grapheme = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "\n",
    "    def update(self, logits, truth):\n",
    "        pred = torch.argmax(logits[0], dim=1)\n",
    "        self.pred_grapheme = torch.cat([self.pred_grapheme, pred])\n",
    "        self.truth_grapheme = torch.cat([self.truth_grapheme, truth[:, 0].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[1], dim=1)\n",
    "        self.pred_vowel = torch.cat([self.pred_vowel, pred])\n",
    "        self.truth_vowel = torch.cat([self.truth_vowel, truth[:, 1].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[2], dim=1)\n",
    "        self.pred_consonant = torch.cat([self.pred_consonant, pred])\n",
    "        self.truth_consonant = torch.cat([self.truth_consonant, truth[:, 2].long()])\n",
    "\n",
    "    def aggregate(self):\n",
    "        rec_grapheme = recall_score(self.truth_grapheme.cpu().numpy(), \n",
    "                                    self.pred_grapheme.cpu().numpy(), \n",
    "                                    average='macro')\n",
    "        rec_vowel = recall_score(self.truth_vowel.cpu().numpy(), \n",
    "                                 self.pred_vowel.cpu().numpy(), \n",
    "                                 average='macro')\n",
    "        rec_consonant = recall_score(self.truth_consonant.cpu().numpy(), \n",
    "                                     self.pred_consonant.cpu().numpy(), \n",
    "                                     average='macro')\n",
    "        #rec = (2*rec_grapheme + 1*rec_vowel + 1*rec_consonant) / 4\n",
    "        rec = np.average([rec_grapheme, rec_vowel, rec_consonant], weights=[2,1,1])\n",
    "        return rec, rec_grapheme, rec_vowel, rec_consonant\n",
    "\n",
    "# #debug MetricLogger\n",
    "# #Epoch 0\n",
    "# loss_logger = LossLogger()\n",
    "# metric_logger = MetricLogger()\n",
    "# for batch_id, (images, labels) in enumerate(val_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if batch_id==10:\n",
    "#         break\n",
    "#     logit = net(inputs)\n",
    "#     logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "#     loss = loss_logger.update(logits, truth)\n",
    "#     metric_logger.update(logits, truth)\n",
    "# rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "# loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "# print(rec, rec_grapheme, rec_vowel, rec_consonant)\n",
    "# print(loss_total, loss_grapheme, loss_vowel, loss_consonant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from senet import se_resnext50_32x4d\n",
    "from senet_v2 import se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 1========\n",
      "[     1      2      3 ... 200836 200838 200839]\n",
      "[     0     11     20 ... 200829 200834 200837]\n",
      "checkpoint_path:  ../checkpoint/v2-fold1\n",
      "model state_dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[EPOCH 00000]train_loss: 2.3035; val_loss: 0.7920; time elapsed: 8.6 min\n",
      "[valid loss]grapheme: 1.1740, vowel: 0.4806, consonant: 0.3395\n",
      "[valid recall]total: 0.6892, grapheme: 0.6146, vowel: 0.8412, consonant: 0.6867\n",
      "================================================================================\n",
      "[EPOCH 00001]train_loss: 1.5463; val_loss: 0.3476; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.4724, vowel: 0.2472, consonant: 0.1982\n",
      "[valid recall]total: 0.9045, grapheme: 0.8857, vowel: 0.9379, consonant: 0.9089\n",
      "================================================================================\n",
      "[EPOCH 00002]train_loss: 1.3804; val_loss: 0.2829; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.3834, vowel: 0.2012, consonant: 0.1636\n",
      "[valid recall]total: 0.9249, grapheme: 0.9073, vowel: 0.9528, consonant: 0.9324\n",
      "================================================================================\n",
      "[EPOCH 00003]train_loss: 1.2642; val_loss: 0.2789; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.3617, vowel: 0.2206, consonant: 0.1718\n",
      "[valid recall]total: 0.9301, grapheme: 0.9065, vowel: 0.9603, consonant: 0.9469\n",
      "================================================================================\n",
      "[EPOCH 00004]train_loss: 1.2032; val_loss: 0.2080; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2697, vowel: 0.1639, consonant: 0.1286\n",
      "[valid recall]total: 0.9438, grapheme: 0.9286, vowel: 0.9671, consonant: 0.9511\n",
      "================================================================================\n",
      "[EPOCH 00005]train_loss: 1.1562; val_loss: 0.1993; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2568, vowel: 0.1596, consonant: 0.1241\n",
      "[valid recall]total: 0.9508, grapheme: 0.9346, vowel: 0.9743, consonant: 0.9595\n",
      "================================================================================\n",
      "[EPOCH 00006]train_loss: 1.1233; val_loss: 0.1829; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.2395, vowel: 0.1374, consonant: 0.1152\n",
      "[valid recall]total: 0.9509, grapheme: 0.9410, vowel: 0.9707, consonant: 0.9508\n",
      "================================================================================\n",
      "[EPOCH 00007]train_loss: 1.0926; val_loss: 0.1929; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2535, vowel: 0.1424, consonant: 0.1221\n",
      "[valid recall]total: 0.9550, grapheme: 0.9398, vowel: 0.9707, consonant: 0.9697\n",
      "================================================================================\n",
      "[EPOCH 00008]train_loss: 1.0753; val_loss: 0.1511; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1931, vowel: 0.1198, consonant: 0.0983\n",
      "[valid recall]total: 0.9628, grapheme: 0.9505, vowel: 0.9751, consonant: 0.9751\n",
      "================================================================================\n",
      "[EPOCH 00009]train_loss: 1.0573; val_loss: 0.1557; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1994, vowel: 0.1205, consonant: 0.1036\n",
      "[valid recall]total: 0.9622, grapheme: 0.9506, vowel: 0.9765, consonant: 0.9712\n",
      "================================================================================\n",
      "[EPOCH 00010]train_loss: 1.0409; val_loss: 0.1690; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2179, vowel: 0.1312, consonant: 0.1088\n",
      "[valid recall]total: 0.9619, grapheme: 0.9526, vowel: 0.9778, consonant: 0.9645\n",
      "================================================================================\n",
      "[EPOCH 00011]train_loss: 1.0242; val_loss: 0.1509; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1984, vowel: 0.1122, consonant: 0.0947\n",
      "[valid recall]total: 0.9631, grapheme: 0.9533, vowel: 0.9800, consonant: 0.9659\n",
      "================================================================================\n",
      "[EPOCH 00012]train_loss: 0.9928; val_loss: 0.1517; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1932, vowel: 0.1230, consonant: 0.0974\n",
      "[valid recall]total: 0.9649, grapheme: 0.9537, vowel: 0.9794, consonant: 0.9730\n",
      "================================================================================\n",
      "[EPOCH 00013]train_loss: 0.9894; val_loss: 0.1755; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.2179, vowel: 0.1479, consonant: 0.1184\n",
      "[valid recall]total: 0.9658, grapheme: 0.9554, vowel: 0.9820, consonant: 0.9703\n",
      "================================================================================\n",
      "[EPOCH 00014]train_loss: 0.9770; val_loss: 0.1668; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2044, vowel: 0.1460, consonant: 0.1125\n",
      "[valid recall]total: 0.9663, grapheme: 0.9561, vowel: 0.9809, consonant: 0.9721\n",
      "================================================================================\n",
      "[EPOCH 00015]train_loss: 0.9268; val_loss: 0.1386; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1763, vowel: 0.1100, consonant: 0.0919\n",
      "[valid recall]total: 0.9690, grapheme: 0.9596, vowel: 0.9812, consonant: 0.9755\n",
      "================================================================================\n",
      "[EPOCH 00016]train_loss: 0.9663; val_loss: 0.1678; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.2120, vowel: 0.1377, consonant: 0.1094\n",
      "[valid recall]total: 0.9653, grapheme: 0.9547, vowel: 0.9799, consonant: 0.9718\n",
      "================================================================================\n",
      "[EPOCH 00017]train_loss: 0.9536; val_loss: 0.1472; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1874, vowel: 0.1208, consonant: 0.0933\n",
      "[valid recall]total: 0.9654, grapheme: 0.9535, vowel: 0.9820, consonant: 0.9723\n",
      "================================================================================\n",
      "[EPOCH 00018]train_loss: 0.9378; val_loss: 0.1602; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1923, vowel: 0.1445, consonant: 0.1116\n",
      "[valid recall]total: 0.9656, grapheme: 0.9521, vowel: 0.9813, consonant: 0.9771\n",
      "================================================================================\n",
      "[EPOCH 00019]train_loss: 0.9248; val_loss: 0.1383; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1774, vowel: 0.1089, consonant: 0.0897\n",
      "[valid recall]total: 0.9673, grapheme: 0.9563, vowel: 0.9793, consonant: 0.9774\n",
      "================================================================================\n",
      "[EPOCH 00020]train_loss: 0.9238; val_loss: 0.1206; time elapsed: 9.8 min\n",
      "[valid loss]grapheme: 0.1594, vowel: 0.0853, consonant: 0.0782\n",
      "[valid recall]total: 0.9684, grapheme: 0.9563, vowel: 0.9806, consonant: 0.9802\n",
      "================================================================================\n",
      "[EPOCH 00021]train_loss: 0.9101; val_loss: 0.1303; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1724, vowel: 0.0925, consonant: 0.0838\n",
      "[valid recall]total: 0.9649, grapheme: 0.9515, vowel: 0.9813, consonant: 0.9751\n",
      "================================================================================\n",
      "[EPOCH 00022]train_loss: 0.8977; val_loss: 0.1288; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1625, vowel: 0.1072, consonant: 0.0831\n",
      "[valid recall]total: 0.9717, grapheme: 0.9621, vowel: 0.9841, consonant: 0.9785\n",
      "================================================================================\n",
      "[EPOCH 00023]train_loss: 0.8953; val_loss: 0.1238; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1603, vowel: 0.0958, consonant: 0.0787\n",
      "[valid recall]total: 0.9696, grapheme: 0.9590, vowel: 0.9836, consonant: 0.9769\n",
      "================================================================================\n",
      "[EPOCH 00024]train_loss: 0.9016; val_loss: 0.1133; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1496, vowel: 0.0831, consonant: 0.0709\n",
      "[valid recall]total: 0.9720, grapheme: 0.9625, vowel: 0.9832, consonant: 0.9798\n",
      "================================================================================\n",
      "[EPOCH 00025]train_loss: 0.8779; val_loss: 0.1163; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1462, vowel: 0.0920, consonant: 0.0809\n",
      "[valid recall]total: 0.9712, grapheme: 0.9637, vowel: 0.9821, consonant: 0.9752\n",
      "================================================================================\n",
      "[EPOCH 00026]train_loss: 0.8856; val_loss: 0.1466; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1800, vowel: 0.1268, consonant: 0.0995\n",
      "[valid recall]total: 0.9701, grapheme: 0.9586, vowel: 0.9856, consonant: 0.9778\n",
      "================================================================================\n",
      "[EPOCH 00027]train_loss: 0.8781; val_loss: 0.1174; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1513, vowel: 0.0919, consonant: 0.0754\n",
      "[valid recall]total: 0.9715, grapheme: 0.9621, vowel: 0.9847, consonant: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[EPOCH 00028]train_loss: 0.8654; val_loss: 0.1359; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1669, vowel: 0.1205, consonant: 0.0894\n",
      "[valid recall]total: 0.9725, grapheme: 0.9639, vowel: 0.9840, consonant: 0.9782\n",
      "================================================================================\n",
      "[EPOCH 00029]train_loss: 0.8843; val_loss: 0.1358; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1739, vowel: 0.1075, consonant: 0.0880\n",
      "[valid recall]total: 0.9694, grapheme: 0.9568, vowel: 0.9830, consonant: 0.9809\n",
      "================================================================================\n",
      "[EPOCH 00030]train_loss: 0.8592; val_loss: 0.1188; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1519, vowel: 0.0964, consonant: 0.0751\n",
      "[valid recall]total: 0.9732, grapheme: 0.9637, vowel: 0.9853, consonant: 0.9799\n",
      "================================================================================\n",
      "[EPOCH 00031]train_loss: 0.8380; val_loss: 0.1191; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1419, vowel: 0.1096, consonant: 0.0830\n",
      "[valid recall]total: 0.9761, grapheme: 0.9670, vowel: 0.9857, consonant: 0.9846\n",
      "================================================================================\n",
      "[EPOCH 00032]train_loss: 0.7960; val_loss: 0.0928; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1176, vowel: 0.0725, consonant: 0.0633\n",
      "[valid recall]total: 0.9747, grapheme: 0.9685, vowel: 0.9838, consonant: 0.9779\n",
      "================================================================================\n",
      "[EPOCH 00033]train_loss: 0.7947; val_loss: 0.1234; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1493, vowel: 0.1095, consonant: 0.0858\n",
      "[valid recall]total: 0.9772, grapheme: 0.9697, vowel: 0.9863, consonant: 0.9831\n",
      "================================================================================\n",
      "[EPOCH 00034]train_loss: 0.7781; val_loss: 0.1199; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1407, vowel: 0.1131, consonant: 0.0849\n",
      "[valid recall]total: 0.9770, grapheme: 0.9698, vowel: 0.9861, consonant: 0.9823\n",
      "================================================================================\n",
      "[EPOCH 00035]train_loss: 0.7950; val_loss: 0.0969; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1211, vowel: 0.0782, consonant: 0.0673\n",
      "[valid recall]total: 0.9763, grapheme: 0.9685, vowel: 0.9867, consonant: 0.9816\n",
      "================================================================================\n",
      "[EPOCH 00036]train_loss: 0.8045; val_loss: 0.1002; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1235, vowel: 0.0851, consonant: 0.0687\n",
      "[valid recall]total: 0.9766, grapheme: 0.9680, vowel: 0.9865, consonant: 0.9840\n",
      "================================================================================\n",
      "[EPOCH 00037]train_loss: 0.7783; val_loss: 0.0984; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1243, vowel: 0.0789, consonant: 0.0662\n",
      "[valid recall]total: 0.9763, grapheme: 0.9682, vowel: 0.9869, consonant: 0.9820\n",
      "================================================================================\n",
      "[EPOCH 00038]train_loss: 0.7836; val_loss: 0.1027; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1247, vowel: 0.0908, consonant: 0.0707\n",
      "[valid recall]total: 0.9771, grapheme: 0.9692, vowel: 0.9858, consonant: 0.9841\n",
      "================================================================================\n",
      "[EPOCH 00039]train_loss: 0.7706; val_loss: 0.1028; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1242, vowel: 0.0938, consonant: 0.0692\n",
      "[valid recall]total: 0.9770, grapheme: 0.9688, vowel: 0.9858, consonant: 0.9844\n",
      "================================================================================\n",
      "[EPOCH 00040]train_loss: 0.7732; val_loss: 0.1010; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1215, vowel: 0.0907, consonant: 0.0704\n",
      "[valid recall]total: 0.9772, grapheme: 0.9700, vowel: 0.9858, consonant: 0.9831\n",
      "================================================================================\n",
      "[EPOCH 00041]train_loss: 0.7396; val_loss: 0.0963; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1165, vowel: 0.0853, consonant: 0.0668\n",
      "[valid recall]total: 0.9786, grapheme: 0.9715, vowel: 0.9866, consonant: 0.9846\n",
      "================================================================================\n",
      "[EPOCH 00042]train_loss: 0.7478; val_loss: 0.0902; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1120, vowel: 0.0725, consonant: 0.0644\n",
      "[valid recall]total: 0.9786, grapheme: 0.9716, vowel: 0.9868, consonant: 0.9845\n",
      "================================================================================\n",
      "[EPOCH 00043]train_loss: 0.7486; val_loss: 0.1044; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1253, vowel: 0.0917, consonant: 0.0752\n",
      "[valid recall]total: 0.9773, grapheme: 0.9697, vowel: 0.9867, consonant: 0.9832\n",
      "================================================================================\n",
      "[EPOCH 00044]train_loss: 0.7398; val_loss: 0.0894; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1089, vowel: 0.0768, consonant: 0.0630\n",
      "[valid recall]total: 0.9783, grapheme: 0.9697, vowel: 0.9876, consonant: 0.9860\n",
      "================================================================================\n",
      "[EPOCH 00045]train_loss: 0.7509; val_loss: 0.1130; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1315, vowel: 0.1083, consonant: 0.0807\n",
      "[valid recall]total: 0.9766, grapheme: 0.9691, vowel: 0.9870, consonant: 0.9811\n",
      "================================================================================\n",
      "[EPOCH 00046]train_loss: 0.7681; val_loss: 0.0788; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0981, vowel: 0.0658, consonant: 0.0533\n",
      "[valid recall]total: 0.9789, grapheme: 0.9712, vowel: 0.9878, consonant: 0.9855\n",
      "================================================================================\n",
      "[EPOCH 00047]train_loss: 0.7686; val_loss: 0.0979; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1170, vowel: 0.0878, consonant: 0.0696\n",
      "[valid recall]total: 0.9778, grapheme: 0.9692, vowel: 0.9868, consonant: 0.9859\n",
      "================================================================================\n",
      "[EPOCH 00048]train_loss: 0.7633; val_loss: 0.0989; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1177, vowel: 0.0886, consonant: 0.0717\n",
      "[valid recall]total: 0.9776, grapheme: 0.9702, vowel: 0.9871, consonant: 0.9828\n",
      "================================================================================\n",
      "[EPOCH 00049]train_loss: 0.7419; val_loss: 0.0992; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1178, vowel: 0.0893, consonant: 0.0720\n",
      "[valid recall]total: 0.9764, grapheme: 0.9708, vowel: 0.9864, consonant: 0.9778\n",
      "================================================================================\n",
      "[EPOCH 00050]train_loss: 0.7404; val_loss: 0.0845; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1022, vowel: 0.0746, consonant: 0.0591\n",
      "[valid recall]total: 0.9801, grapheme: 0.9733, vowel: 0.9875, consonant: 0.9864\n",
      "================================================================================\n",
      "[EPOCH 00051]train_loss: 0.7512; val_loss: 0.0959; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1169, vowel: 0.0785, consonant: 0.0714\n",
      "[valid recall]total: 0.9774, grapheme: 0.9702, vowel: 0.9876, consonant: 0.9816\n",
      "================================================================================\n",
      "[EPOCH 00052]train_loss: 0.7233; val_loss: 0.0789; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1007, vowel: 0.0598, consonant: 0.0543\n",
      "[valid recall]total: 0.9795, grapheme: 0.9725, vowel: 0.9875, consonant: 0.9855\n",
      "================================================================================\n",
      "[EPOCH 00053]train_loss: 0.7422; val_loss: 0.1049; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1214, vowel: 0.1019, consonant: 0.0749\n",
      "[valid recall]total: 0.9776, grapheme: 0.9716, vowel: 0.9867, consonant: 0.9806\n",
      "================================================================================\n",
      "[EPOCH 00054]train_loss: 0.7033; val_loss: 0.0832; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1021, vowel: 0.0699, consonant: 0.0588\n",
      "[valid recall]total: 0.9794, grapheme: 0.9731, vowel: 0.9875, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00055]train_loss: 0.7258; val_loss: 0.1057; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1237, vowel: 0.1018, consonant: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid recall]total: 0.9787, grapheme: 0.9721, vowel: 0.9873, consonant: 0.9832\n",
      "================================================================================\n",
      "[EPOCH 00056]train_loss: 0.6988; val_loss: 0.0908; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1078, vowel: 0.0827, consonant: 0.0650\n",
      "[valid recall]total: 0.9787, grapheme: 0.9725, vowel: 0.9868, consonant: 0.9830\n",
      "================================================================================\n",
      "[EPOCH 00057]train_loss: 0.7360; val_loss: 0.0798; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0989, vowel: 0.0656, consonant: 0.0556\n",
      "[valid recall]total: 0.9789, grapheme: 0.9731, vowel: 0.9878, consonant: 0.9818\n",
      "================================================================================\n",
      "[EPOCH 00058]train_loss: 0.7312; val_loss: 0.0983; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1146, vowel: 0.0916, consonant: 0.0724\n",
      "[valid recall]total: 0.9791, grapheme: 0.9716, vowel: 0.9878, consonant: 0.9854\n",
      "================================================================================\n",
      "[EPOCH 00059]train_loss: 0.7407; val_loss: 0.1052; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1192, vowel: 0.1030, consonant: 0.0793\n",
      "[valid recall]total: 0.9792, grapheme: 0.9723, vowel: 0.9877, consonant: 0.9845\n",
      "================================================================================\n",
      "[EPOCH 00060]train_loss: 0.7235; val_loss: 0.0891; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1063, vowel: 0.0797, consonant: 0.0640\n",
      "[valid recall]total: 0.9792, grapheme: 0.9732, vowel: 0.9875, consonant: 0.9829\n",
      "================================================================================\n",
      "[EPOCH 00061]train_loss: 0.7163; val_loss: 0.0904; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1070, vowel: 0.0828, consonant: 0.0646\n",
      "[valid recall]total: 0.9789, grapheme: 0.9723, vowel: 0.9869, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00062]train_loss: 0.7218; val_loss: 0.0936; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1093, vowel: 0.0857, consonant: 0.0700\n",
      "[valid recall]total: 0.9792, grapheme: 0.9728, vowel: 0.9874, consonant: 0.9838\n",
      "================================================================================\n",
      "[EPOCH 00063]train_loss: 0.7052; val_loss: 0.0920; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1077, vowel: 0.0870, consonant: 0.0656\n",
      "[valid recall]total: 0.9794, grapheme: 0.9731, vowel: 0.9876, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00064]train_loss: 0.7244; val_loss: 0.1039; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1166, vowel: 0.1052, consonant: 0.0773\n",
      "[valid recall]total: 0.9795, grapheme: 0.9725, vowel: 0.9875, consonant: 0.9855\n",
      "================================================================================\n",
      "[EPOCH 00065]train_loss: 0.7087; val_loss: 0.0969; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1131, vowel: 0.0895, consonant: 0.0718\n",
      "[valid recall]total: 0.9790, grapheme: 0.9727, vowel: 0.9876, consonant: 0.9830\n",
      "================================================================================\n",
      "[EPOCH 00066]train_loss: 0.7001; val_loss: 0.0773; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.0956, vowel: 0.0634, consonant: 0.0546\n",
      "[valid recall]total: 0.9811, grapheme: 0.9751, vowel: 0.9881, consonant: 0.9862\n",
      "================================================================================\n",
      "[EPOCH 00067]train_loss: 0.7070; val_loss: 0.0885; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1037, vowel: 0.0820, consonant: 0.0645\n",
      "[valid recall]total: 0.9800, grapheme: 0.9739, vowel: 0.9878, consonant: 0.9844\n",
      "================================================================================\n",
      "[EPOCH 00068]train_loss: 0.7084; val_loss: 0.0914; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1064, vowel: 0.0877, consonant: 0.0652\n",
      "[valid recall]total: 0.9799, grapheme: 0.9730, vowel: 0.9874, consonant: 0.9862\n",
      "================================================================================\n",
      "[EPOCH 00069]train_loss: 0.7201; val_loss: 0.0889; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1063, vowel: 0.0787, consonant: 0.0643\n",
      "[valid recall]total: 0.9795, grapheme: 0.9725, vowel: 0.9877, consonant: 0.9851\n",
      "================================================================================\n",
      "[EPOCH 00070]train_loss: 0.7162; val_loss: 0.1141; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1295, vowel: 0.1110, consonant: 0.0865\n",
      "[valid recall]total: 0.9780, grapheme: 0.9705, vowel: 0.9875, consonant: 0.9833\n",
      "================================================================================\n",
      "[EPOCH 00071]train_loss: 0.7074; val_loss: 0.0840; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1013, vowel: 0.0724, consonant: 0.0611\n",
      "[valid recall]total: 0.9798, grapheme: 0.9729, vowel: 0.9873, consonant: 0.9863\n",
      "================================================================================\n",
      "[EPOCH 00072]train_loss: 0.7169; val_loss: 0.0855; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1016, vowel: 0.0782, consonant: 0.0605\n",
      "[valid recall]total: 0.9810, grapheme: 0.9751, vowel: 0.9876, consonant: 0.9861\n",
      "================================================================================\n",
      "[EPOCH 00073]train_loss: 0.7077; val_loss: 0.1043; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1194, vowel: 0.0994, consonant: 0.0791\n",
      "[valid recall]total: 0.9784, grapheme: 0.9717, vowel: 0.9869, consonant: 0.9833\n",
      "================================================================================\n",
      "[EPOCH 00074]train_loss: 0.7309; val_loss: 0.0902; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1051, vowel: 0.0841, consonant: 0.0664\n",
      "[valid recall]total: 0.9797, grapheme: 0.9729, vowel: 0.9876, consonant: 0.9852\n",
      "================================================================================\n",
      "[EPOCH 00075]train_loss: 0.7140; val_loss: 0.0778; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0957, vowel: 0.0668, consonant: 0.0528\n",
      "[valid recall]total: 0.9804, grapheme: 0.9743, vowel: 0.9875, consonant: 0.9854\n",
      "================================================================================\n",
      "[EPOCH 00076]train_loss: 0.6947; val_loss: 0.0880; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1034, vowel: 0.0829, consonant: 0.0622\n",
      "[valid recall]total: 0.9808, grapheme: 0.9741, vowel: 0.9877, consonant: 0.9874\n",
      "================================================================================\n",
      "[EPOCH 00077]train_loss: 0.7002; val_loss: 0.0923; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1087, vowel: 0.0858, consonant: 0.0661\n",
      "[valid recall]total: 0.9792, grapheme: 0.9728, vowel: 0.9874, consonant: 0.9838\n",
      "================================================================================\n",
      "[EPOCH 00078]train_loss: 0.7120; val_loss: 0.0945; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1121, vowel: 0.0857, consonant: 0.0680\n",
      "[valid recall]total: 0.9790, grapheme: 0.9721, vowel: 0.9874, consonant: 0.9843\n",
      "================================================================================\n",
      "[EPOCH 00079]train_loss: 0.7086; val_loss: 0.1107; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1256, vowel: 0.1084, consonant: 0.0831\n",
      "[valid recall]total: 0.9778, grapheme: 0.9710, vowel: 0.9875, consonant: 0.9818\n",
      "================================================================================\n",
      "[EPOCH 00080]train_loss: 0.7253; val_loss: 0.0820; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.0977, vowel: 0.0744, consonant: 0.0584\n",
      "[valid recall]total: 0.9802, grapheme: 0.9734, vowel: 0.9877, consonant: 0.9861\n",
      "================================================================================\n",
      "[EPOCH 00081]train_loss: 0.6947; val_loss: 0.0933; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1095, vowel: 0.0864, consonant: 0.0677\n",
      "[valid recall]total: 0.9790, grapheme: 0.9724, vowel: 0.9872, consonant: 0.9840\n",
      "================================================================================\n",
      "[EPOCH 00082]train_loss: 0.7069; val_loss: 0.1094; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1224, vowel: 0.1077, consonant: 0.0853\n",
      "[valid recall]total: 0.9785, grapheme: 0.9722, vowel: 0.9877, consonant: 0.9820\n",
      "================================================================================\n",
      "[EPOCH 00083]train_loss: 0.7044; val_loss: 0.0999; time elapsed: 9.6 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid loss]grapheme: 0.1130, vowel: 0.1006, consonant: 0.0733\n",
      "[valid recall]total: 0.9795, grapheme: 0.9723, vowel: 0.9874, consonant: 0.9860\n",
      "================================================================================\n",
      "[EPOCH 00084]train_loss: 0.7170; val_loss: 0.0981; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1137, vowel: 0.0942, consonant: 0.0708\n",
      "[valid recall]total: 0.9786, grapheme: 0.9722, vowel: 0.9872, consonant: 0.9827\n",
      "================================================================================\n",
      "[EPOCH 00085]train_loss: 0.7150; val_loss: 0.0992; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1114, vowel: 0.0986, consonant: 0.0754\n",
      "[valid recall]total: 0.9795, grapheme: 0.9732, vowel: 0.9873, consonant: 0.9842\n",
      "================================================================================\n",
      "[EPOCH 00086]train_loss: 0.7011; val_loss: 0.0839; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0982, vowel: 0.0773, consonant: 0.0618\n",
      "[valid recall]total: 0.9805, grapheme: 0.9740, vowel: 0.9878, consonant: 0.9861\n",
      "================================================================================\n",
      "[EPOCH 00087]train_loss: 0.6770; val_loss: 0.0766; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0958, vowel: 0.0626, consonant: 0.0524\n",
      "[valid recall]total: 0.9808, grapheme: 0.9739, vowel: 0.9879, consonant: 0.9874\n",
      "================================================================================\n",
      "[EPOCH 00088]train_loss: 0.6943; val_loss: 0.0869; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1028, vowel: 0.0802, consonant: 0.0616\n",
      "[valid recall]total: 0.9804, grapheme: 0.9736, vowel: 0.9873, consonant: 0.9870\n",
      "================================================================================\n",
      "[EPOCH 00089]train_loss: 0.7067; val_loss: 0.0891; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1048, vowel: 0.0821, consonant: 0.0649\n",
      "[valid recall]total: 0.9795, grapheme: 0.9734, vowel: 0.9875, consonant: 0.9836\n",
      "================================================================================\n",
      "[EPOCH 00090]train_loss: 0.7288; val_loss: 0.1064; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1206, vowel: 0.1090, consonant: 0.0755\n",
      "[valid recall]total: 0.9786, grapheme: 0.9718, vowel: 0.9872, consonant: 0.9834\n",
      "================================================================================\n",
      "[EPOCH 00091]train_loss: 0.7015; val_loss: 0.1025; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1157, vowel: 0.1013, consonant: 0.0775\n",
      "[valid recall]total: 0.9785, grapheme: 0.9716, vowel: 0.9876, consonant: 0.9829\n",
      "================================================================================\n",
      "[EPOCH 00092]train_loss: 0.7010; val_loss: 0.0756; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0937, vowel: 0.0609, consonant: 0.0540\n",
      "[valid recall]total: 0.9807, grapheme: 0.9744, vowel: 0.9881, consonant: 0.9861\n",
      "================================================================================\n",
      "[EPOCH 00093]train_loss: 0.7191; val_loss: 0.1010; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1155, vowel: 0.0994, consonant: 0.0735\n",
      "[valid recall]total: 0.9796, grapheme: 0.9734, vowel: 0.9872, consonant: 0.9846\n",
      "================================================================================\n",
      "[EPOCH 00094]train_loss: 0.7089; val_loss: 0.0896; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1047, vowel: 0.0845, consonant: 0.0643\n",
      "[valid recall]total: 0.9796, grapheme: 0.9731, vowel: 0.9878, consonant: 0.9843\n",
      "================================================================================\n",
      "[EPOCH 00095]train_loss: 0.7029; val_loss: 0.0974; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1129, vowel: 0.0939, consonant: 0.0697\n",
      "[valid recall]total: 0.9805, grapheme: 0.9742, vowel: 0.9874, consonant: 0.9861\n",
      "================================================================================\n",
      "[EPOCH 00096]train_loss: 0.6931; val_loss: 0.0826; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0987, vowel: 0.0756, consonant: 0.0575\n",
      "[valid recall]total: 0.9803, grapheme: 0.9738, vowel: 0.9876, consonant: 0.9863\n",
      "================================================================================\n",
      "[EPOCH 00097]train_loss: 0.7139; val_loss: 0.0970; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1130, vowel: 0.0946, consonant: 0.0672\n",
      "[valid recall]total: 0.9802, grapheme: 0.9728, vowel: 0.9877, consonant: 0.9874\n",
      "================================================================================\n",
      "[EPOCH 00098]train_loss: 0.7133; val_loss: 0.0761; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0937, vowel: 0.0642, consonant: 0.0527\n",
      "[valid recall]total: 0.9801, grapheme: 0.9738, vowel: 0.9875, consonant: 0.9853\n",
      "================================================================================\n",
      "[EPOCH 00099]train_loss: 0.6844; val_loss: 0.0821; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0958, vowel: 0.0810, consonant: 0.0559\n",
      "[valid recall]total: 0.9815, grapheme: 0.9753, vowel: 0.9878, consonant: 0.9876\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 2========\n",
      "[     0      2      4 ... 200836 200837 200838]\n",
      "[     1      3      8 ... 200821 200833 200839]\n",
      "checkpoint_path:  ../checkpoint/v2-fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model state_dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00000]train_loss: 2.3693; val_loss: 0.5745; time elapsed: 9.1 min\n",
      "[valid loss]grapheme: 0.8413, vowel: 0.3495, consonant: 0.2659\n",
      "[valid recall]total: 0.7762, grapheme: 0.7154, vowel: 0.8952, consonant: 0.7788\n",
      "================================================================================\n",
      "[EPOCH 00001]train_loss: 1.5703; val_loss: 0.3821; time elapsed: 9.2 min\n",
      "[valid loss]grapheme: 0.5313, vowel: 0.2519, consonant: 0.2138\n",
      "[valid recall]total: 0.8974, grapheme: 0.8603, vowel: 0.9403, consonant: 0.9287\n",
      "================================================================================\n",
      "[EPOCH 00002]train_loss: 1.3950; val_loss: 0.2642; time elapsed: 9.0 min\n",
      "[valid loss]grapheme: 0.3508, vowel: 0.1974, consonant: 0.1578\n",
      "[valid recall]total: 0.9307, grapheme: 0.9057, vowel: 0.9524, consonant: 0.9591\n",
      "================================================================================\n",
      "[EPOCH 00003]train_loss: 1.2928; val_loss: 0.2473; time elapsed: 9.1 min\n",
      "[valid loss]grapheme: 0.3277, vowel: 0.1933, consonant: 0.1405\n",
      "[valid recall]total: 0.9403, grapheme: 0.9149, vowel: 0.9631, consonant: 0.9682\n",
      "================================================================================\n",
      "[EPOCH 00004]train_loss: 1.1954; val_loss: 0.2206; time elapsed: 9.2 min\n",
      "[valid loss]grapheme: 0.2970, vowel: 0.1610, consonant: 0.1274\n",
      "[valid recall]total: 0.9468, grapheme: 0.9281, vowel: 0.9642, consonant: 0.9668\n",
      "================================================================================\n",
      "[EPOCH 00005]train_loss: 1.1614; val_loss: 0.1943; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.2535, vowel: 0.1460, consonant: 0.1240\n",
      "[valid recall]total: 0.9531, grapheme: 0.9357, vowel: 0.9712, consonant: 0.9699\n",
      "================================================================================\n",
      "[EPOCH 00006]train_loss: 1.1236; val_loss: 0.2089; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2651, vowel: 0.1756, consonant: 0.1300\n",
      "[valid recall]total: 0.9510, grapheme: 0.9301, vowel: 0.9726, consonant: 0.9710\n",
      "================================================================================\n",
      "[EPOCH 00007]train_loss: 1.1068; val_loss: 0.1865; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2430, vowel: 0.1430, consonant: 0.1168\n",
      "[valid recall]total: 0.9553, grapheme: 0.9433, vowel: 0.9776, consonant: 0.9568\n",
      "================================================================================\n",
      "[EPOCH 00008]train_loss: 1.0553; val_loss: 0.1871; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2405, vowel: 0.1572, consonant: 0.1102\n",
      "[valid recall]total: 0.9567, grapheme: 0.9397, vowel: 0.9758, consonant: 0.9717\n",
      "================================================================================\n",
      "[EPOCH 00009]train_loss: 1.0663; val_loss: 0.1600; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.2051, vowel: 0.1250, consonant: 0.1045\n",
      "[valid recall]total: 0.9612, grapheme: 0.9469, vowel: 0.9797, consonant: 0.9714\n",
      "================================================================================\n",
      "[EPOCH 00010]train_loss: 1.0339; val_loss: 0.1715; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2164, vowel: 0.1477, consonant: 0.1054\n",
      "[valid recall]total: 0.9610, grapheme: 0.9483, vowel: 0.9771, consonant: 0.9702\n",
      "================================================================================\n",
      "[EPOCH 00011]train_loss: 1.0174; val_loss: 0.1433; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1872, vowel: 0.1119, consonant: 0.0869\n",
      "[valid recall]total: 0.9648, grapheme: 0.9511, vowel: 0.9789, consonant: 0.9780\n",
      "================================================================================\n",
      "[EPOCH 00012]train_loss: 1.0034; val_loss: 0.1449; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1879, vowel: 0.1129, consonant: 0.0908\n",
      "[valid recall]total: 0.9669, grapheme: 0.9538, vowel: 0.9799, consonant: 0.9799\n",
      "================================================================================\n",
      "[EPOCH 00013]train_loss: 1.0073; val_loss: 0.1602; time elapsed: 9.1 min\n",
      "[valid loss]grapheme: 0.1998, vowel: 0.1347, consonant: 0.1067\n",
      "[valid recall]total: 0.9631, grapheme: 0.9521, vowel: 0.9793, consonant: 0.9689\n",
      "================================================================================\n",
      "[EPOCH 00014]train_loss: 0.9586; val_loss: 0.1429; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1878, vowel: 0.1085, consonant: 0.0874\n",
      "[valid recall]total: 0.9689, grapheme: 0.9563, vowel: 0.9830, consonant: 0.9798\n",
      "================================================================================\n",
      "[EPOCH 00015]train_loss: 0.9522; val_loss: 0.1517; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1914, vowel: 0.1268, consonant: 0.0970\n",
      "[valid recall]total: 0.9691, grapheme: 0.9569, vowel: 0.9846, consonant: 0.9781\n",
      "================================================================================\n",
      "[EPOCH 00016]train_loss: 0.9673; val_loss: 0.1410; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1842, vowel: 0.1066, consonant: 0.0891\n",
      "[valid recall]total: 0.9651, grapheme: 0.9508, vowel: 0.9834, consonant: 0.9754\n",
      "================================================================================\n",
      "[EPOCH 00017]train_loss: 0.9476; val_loss: 0.1353; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1722, vowel: 0.1097, consonant: 0.0872\n",
      "[valid recall]total: 0.9693, grapheme: 0.9563, vowel: 0.9857, consonant: 0.9790\n",
      "================================================================================\n",
      "[EPOCH 00018]train_loss: 0.9353; val_loss: 0.1746; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.2133, vowel: 0.1676, consonant: 0.1042\n",
      "[valid recall]total: 0.9689, grapheme: 0.9565, vowel: 0.9842, consonant: 0.9783\n",
      "================================================================================\n",
      "[EPOCH 00019]train_loss: 0.9486; val_loss: 0.1477; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1882, vowel: 0.1213, consonant: 0.0931\n",
      "[valid recall]total: 0.9655, grapheme: 0.9502, vowel: 0.9842, consonant: 0.9776\n",
      "================================================================================\n",
      "[EPOCH 00020]train_loss: 0.9154; val_loss: 0.1281; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1614, vowel: 0.1058, consonant: 0.0837\n",
      "[valid recall]total: 0.9720, grapheme: 0.9612, vowel: 0.9849, consonant: 0.9809\n",
      "================================================================================\n",
      "[EPOCH 00021]train_loss: 0.9099; val_loss: 0.1245; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1626, vowel: 0.0994, consonant: 0.0734\n",
      "[valid recall]total: 0.9719, grapheme: 0.9612, vowel: 0.9852, consonant: 0.9800\n",
      "================================================================================\n",
      "[EPOCH 00022]train_loss: 0.9222; val_loss: 0.1222; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1594, vowel: 0.0988, consonant: 0.0712\n",
      "[valid recall]total: 0.9736, grapheme: 0.9606, vowel: 0.9852, consonant: 0.9878\n",
      "================================================================================\n",
      "[EPOCH 00023]train_loss: 0.8834; val_loss: 0.1207; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1561, vowel: 0.0985, consonant: 0.0722\n",
      "[valid recall]total: 0.9730, grapheme: 0.9614, vowel: 0.9845, consonant: 0.9847\n",
      "================================================================================\n",
      "[EPOCH 00024]train_loss: 0.8719; val_loss: 0.1385; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1734, vowel: 0.1213, consonant: 0.0857\n",
      "[valid recall]total: 0.9741, grapheme: 0.9627, vowel: 0.9850, consonant: 0.9859\n",
      "================================================================================\n",
      "[EPOCH 00025]train_loss: 0.9099; val_loss: 0.1297; time elapsed: 9.2 min\n",
      "[valid loss]grapheme: 0.1657, vowel: 0.1075, consonant: 0.0801\n",
      "[valid recall]total: 0.9729, grapheme: 0.9616, vowel: 0.9862, consonant: 0.9821\n",
      "================================================================================\n",
      "[EPOCH 00026]train_loss: 0.8851; val_loss: 0.1225; time elapsed: 9.1 min\n",
      "[valid loss]grapheme: 0.1556, vowel: 0.1017, consonant: 0.0769\n",
      "[valid recall]total: 0.9732, grapheme: 0.9621, vowel: 0.9855, consonant: 0.9830\n",
      "================================================================================\n",
      "[EPOCH 00027]train_loss: 0.8787; val_loss: 0.1264; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1584, vowel: 0.1063, consonant: 0.0827\n",
      "[valid recall]total: 0.9753, grapheme: 0.9640, vowel: 0.9873, consonant: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[EPOCH 00028]train_loss: 0.8847; val_loss: 0.1097; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1412, vowel: 0.0846, consonant: 0.0718\n",
      "[valid recall]total: 0.9728, grapheme: 0.9627, vowel: 0.9853, consonant: 0.9803\n",
      "================================================================================\n",
      "[EPOCH 00029]train_loss: 0.8619; val_loss: 0.1186; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1525, vowel: 0.0930, consonant: 0.0764\n",
      "[valid recall]total: 0.9739, grapheme: 0.9632, vowel: 0.9858, consonant: 0.9835\n",
      "================================================================================\n",
      "[EPOCH 00030]train_loss: 0.8561; val_loss: 0.1160; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1524, vowel: 0.0847, consonant: 0.0748\n",
      "[valid recall]total: 0.9709, grapheme: 0.9582, vowel: 0.9846, consonant: 0.9825\n",
      "================================================================================\n",
      "[EPOCH 00031]train_loss: 0.8535; val_loss: 0.1164; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1444, vowel: 0.1016, consonant: 0.0752\n",
      "[valid recall]total: 0.9743, grapheme: 0.9630, vowel: 0.9853, consonant: 0.9861\n",
      "================================================================================\n",
      "[EPOCH 00032]train_loss: 0.8417; val_loss: 0.1296; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1595, vowel: 0.1145, consonant: 0.0851\n",
      "[valid recall]total: 0.9710, grapheme: 0.9609, vowel: 0.9828, consonant: 0.9793\n",
      "================================================================================\n",
      "[EPOCH 00033]train_loss: 0.8396; val_loss: 0.1128; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1399, vowel: 0.0978, consonant: 0.0737\n",
      "[valid recall]total: 0.9742, grapheme: 0.9649, vowel: 0.9839, consonant: 0.9831\n",
      "================================================================================\n",
      "[EPOCH 00034]train_loss: 0.8505; val_loss: 0.1205; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1502, vowel: 0.1061, consonant: 0.0755\n",
      "[valid recall]total: 0.9755, grapheme: 0.9650, vowel: 0.9874, consonant: 0.9849\n",
      "================================================================================\n",
      "[EPOCH 00035]train_loss: 0.7800; val_loss: 0.1155; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1368, vowel: 0.1094, consonant: 0.0789\n",
      "[valid recall]total: 0.9775, grapheme: 0.9679, vowel: 0.9883, consonant: 0.9860\n",
      "================================================================================\n",
      "[EPOCH 00036]train_loss: 0.7827; val_loss: 0.0954; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1223, vowel: 0.0751, consonant: 0.0619\n",
      "[valid recall]total: 0.9790, grapheme: 0.9691, vowel: 0.9889, consonant: 0.9891\n",
      "================================================================================\n",
      "[EPOCH 00037]train_loss: 0.7833; val_loss: 0.1048; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1260, vowel: 0.0940, consonant: 0.0730\n",
      "[valid recall]total: 0.9791, grapheme: 0.9705, vowel: 0.9888, consonant: 0.9866\n",
      "================================================================================\n",
      "[EPOCH 00038]train_loss: 0.8127; val_loss: 0.1035; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1257, vowel: 0.0930, consonant: 0.0696\n",
      "[valid recall]total: 0.9789, grapheme: 0.9707, vowel: 0.9883, consonant: 0.9859\n",
      "================================================================================\n",
      "[EPOCH 00039]train_loss: 0.7964; val_loss: 0.1065; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1289, vowel: 0.0967, consonant: 0.0717\n",
      "[valid recall]total: 0.9789, grapheme: 0.9702, vowel: 0.9882, consonant: 0.9872\n",
      "================================================================================\n",
      "[EPOCH 00040]train_loss: 0.7727; val_loss: 0.1006; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1252, vowel: 0.0850, consonant: 0.0671\n",
      "[valid recall]total: 0.9790, grapheme: 0.9696, vowel: 0.9881, consonant: 0.9887\n",
      "================================================================================\n",
      "[EPOCH 00041]train_loss: 0.7710; val_loss: 0.0920; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1140, vowel: 0.0764, consonant: 0.0638\n",
      "[valid recall]total: 0.9786, grapheme: 0.9707, vowel: 0.9883, consonant: 0.9848\n",
      "================================================================================\n",
      "[EPOCH 00042]train_loss: 0.7650; val_loss: 0.1130; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1338, vowel: 0.1021, consonant: 0.0822\n",
      "[valid recall]total: 0.9789, grapheme: 0.9699, vowel: 0.9890, consonant: 0.9869\n",
      "================================================================================\n",
      "[EPOCH 00043]train_loss: 0.7702; val_loss: 0.0860; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1088, vowel: 0.0698, consonant: 0.0566\n",
      "[valid recall]total: 0.9791, grapheme: 0.9711, vowel: 0.9882, consonant: 0.9857\n",
      "================================================================================\n",
      "[EPOCH 00044]train_loss: 0.7575; val_loss: 0.1273; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1515, vowel: 0.1245, consonant: 0.0815\n",
      "[valid recall]total: 0.9753, grapheme: 0.9652, vowel: 0.9841, consonant: 0.9866\n",
      "================================================================================\n",
      "[EPOCH 00045]train_loss: 0.7875; val_loss: 0.1046; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1272, vowel: 0.0961, consonant: 0.0681\n",
      "[valid recall]total: 0.9784, grapheme: 0.9683, vowel: 0.9887, consonant: 0.9881\n",
      "================================================================================\n",
      "[EPOCH 00046]train_loss: 0.7640; val_loss: 0.1022; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1246, vowel: 0.0867, consonant: 0.0730\n",
      "[valid recall]total: 0.9779, grapheme: 0.9679, vowel: 0.9885, consonant: 0.9875\n",
      "================================================================================\n",
      "[EPOCH 00047]train_loss: 0.7419; val_loss: 0.1018; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1223, vowel: 0.0939, consonant: 0.0688\n",
      "[valid recall]total: 0.9793, grapheme: 0.9706, vowel: 0.9894, consonant: 0.9865\n",
      "================================================================================\n",
      "[EPOCH 00048]train_loss: 0.7678; val_loss: 0.1055; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1258, vowel: 0.0972, consonant: 0.0731\n",
      "[valid recall]total: 0.9795, grapheme: 0.9703, vowel: 0.9889, consonant: 0.9888\n",
      "================================================================================\n",
      "[EPOCH 00049]train_loss: 0.7548; val_loss: 0.1005; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1241, vowel: 0.0850, consonant: 0.0688\n",
      "[valid recall]total: 0.9780, grapheme: 0.9693, vowel: 0.9893, consonant: 0.9842\n",
      "================================================================================\n",
      "[EPOCH 00050]train_loss: 0.7598; val_loss: 0.0951; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1145, vowel: 0.0851, consonant: 0.0663\n",
      "[valid recall]total: 0.9805, grapheme: 0.9717, vowel: 0.9896, consonant: 0.9891\n",
      "================================================================================\n",
      "[EPOCH 00051]train_loss: 0.7381; val_loss: 0.0974; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1127, vowel: 0.0932, consonant: 0.0711\n",
      "[valid recall]total: 0.9811, grapheme: 0.9723, vowel: 0.9905, consonant: 0.9892\n",
      "================================================================================\n",
      "[EPOCH 00052]train_loss: 0.7245; val_loss: 0.0935; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1146, vowel: 0.0789, consonant: 0.0660\n",
      "[valid recall]total: 0.9817, grapheme: 0.9741, vowel: 0.9903, consonant: 0.9884\n",
      "================================================================================\n",
      "[EPOCH 00053]train_loss: 0.7123; val_loss: 0.0808; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1006, vowel: 0.0655, consonant: 0.0566\n",
      "[valid recall]total: 0.9818, grapheme: 0.9746, vowel: 0.9904, consonant: 0.9874\n",
      "================================================================================\n",
      "[EPOCH 00054]train_loss: 0.7571; val_loss: 0.0907; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1121, vowel: 0.0757, consonant: 0.0629\n",
      "[valid recall]total: 0.9814, grapheme: 0.9730, vowel: 0.9900, consonant: 0.9894\n",
      "================================================================================\n",
      "[EPOCH 00055]train_loss: 0.7296; val_loss: 0.0856; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1062, vowel: 0.0696, consonant: 0.0606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid recall]total: 0.9811, grapheme: 0.9740, vowel: 0.9901, consonant: 0.9865\n",
      "================================================================================\n",
      "[EPOCH 00056]train_loss: 0.7263; val_loss: 0.0911; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1097, vowel: 0.0808, consonant: 0.0642\n",
      "[valid recall]total: 0.9815, grapheme: 0.9734, vowel: 0.9899, consonant: 0.9895\n",
      "================================================================================\n",
      "[EPOCH 00057]train_loss: 0.7215; val_loss: 0.1028; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1156, vowel: 0.1029, consonant: 0.0770\n",
      "[valid recall]total: 0.9806, grapheme: 0.9724, vowel: 0.9904, consonant: 0.9872\n",
      "================================================================================\n",
      "[EPOCH 00058]train_loss: 0.7244; val_loss: 0.0851; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1059, vowel: 0.0677, consonant: 0.0608\n",
      "[valid recall]total: 0.9821, grapheme: 0.9740, vowel: 0.9904, consonant: 0.9903\n",
      "================================================================================\n",
      "[EPOCH 00059]train_loss: 0.7081; val_loss: 0.0872; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1050, vowel: 0.0757, consonant: 0.0633\n",
      "[valid recall]total: 0.9815, grapheme: 0.9738, vowel: 0.9894, consonant: 0.9891\n",
      "================================================================================\n",
      "[EPOCH 00060]train_loss: 0.7225; val_loss: 0.0990; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1112, vowel: 0.0993, consonant: 0.0743\n",
      "[valid recall]total: 0.9816, grapheme: 0.9737, vowel: 0.9899, consonant: 0.9889\n",
      "================================================================================\n",
      "[EPOCH 00061]train_loss: 0.7021; val_loss: 0.0869; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1024, vowel: 0.0812, consonant: 0.0619\n",
      "[valid recall]total: 0.9829, grapheme: 0.9755, vowel: 0.9904, consonant: 0.9904\n",
      "================================================================================\n",
      "[EPOCH 00062]train_loss: 0.7262; val_loss: 0.0919; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1082, vowel: 0.0847, consonant: 0.0665\n",
      "[valid recall]total: 0.9817, grapheme: 0.9742, vowel: 0.9902, consonant: 0.9883\n",
      "================================================================================\n",
      "[EPOCH 00063]train_loss: 0.7110; val_loss: 0.0858; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1027, vowel: 0.0767, consonant: 0.0612\n",
      "[valid recall]total: 0.9817, grapheme: 0.9737, vowel: 0.9907, consonant: 0.9888\n",
      "================================================================================\n",
      "[EPOCH 00064]train_loss: 0.7254; val_loss: 0.0854; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1011, vowel: 0.0777, consonant: 0.0618\n",
      "[valid recall]total: 0.9832, grapheme: 0.9760, vowel: 0.9904, consonant: 0.9901\n",
      "================================================================================\n",
      "[EPOCH 00065]train_loss: 0.6959; val_loss: 0.0972; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1128, vowel: 0.0930, consonant: 0.0700\n",
      "[valid recall]total: 0.9819, grapheme: 0.9737, vowel: 0.9900, consonant: 0.9903\n",
      "================================================================================\n",
      "[EPOCH 00066]train_loss: 0.6960; val_loss: 0.1076; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1204, vowel: 0.1095, consonant: 0.0799\n",
      "[valid recall]total: 0.9824, grapheme: 0.9747, vowel: 0.9904, consonant: 0.9896\n",
      "================================================================================\n",
      "[EPOCH 00067]train_loss: 0.7142; val_loss: 0.1012; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1088, vowel: 0.1092, consonant: 0.0781\n",
      "[valid recall]total: 0.9817, grapheme: 0.9738, vowel: 0.9901, consonant: 0.9893\n",
      "================================================================================\n",
      "[EPOCH 00068]train_loss: 0.6791; val_loss: 0.0894; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1049, vowel: 0.0813, consonant: 0.0667\n",
      "[valid recall]total: 0.9828, grapheme: 0.9753, vowel: 0.9903, consonant: 0.9900\n",
      "================================================================================\n",
      "[EPOCH 00069]train_loss: 0.6915; val_loss: 0.0734; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.0923, vowel: 0.0576, consonant: 0.0511\n",
      "[valid recall]total: 0.9828, grapheme: 0.9748, vowel: 0.9909, consonant: 0.9907\n",
      "================================================================================\n",
      "[EPOCH 00070]train_loss: 0.6859; val_loss: 0.0871; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1031, vowel: 0.0800, consonant: 0.0622\n",
      "[valid recall]total: 0.9826, grapheme: 0.9748, vowel: 0.9907, consonant: 0.9901\n",
      "================================================================================\n",
      "[EPOCH 00071]train_loss: 0.7187; val_loss: 0.0844; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1015, vowel: 0.0727, consonant: 0.0619\n",
      "[valid recall]total: 0.9832, grapheme: 0.9760, vowel: 0.9908, consonant: 0.9903\n",
      "================================================================================\n",
      "[EPOCH 00072]train_loss: 0.7170; val_loss: 0.0861; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1019, vowel: 0.0785, consonant: 0.0621\n",
      "[valid recall]total: 0.9833, grapheme: 0.9760, vowel: 0.9907, consonant: 0.9905\n",
      "================================================================================\n",
      "[EPOCH 00073]train_loss: 0.7077; val_loss: 0.0774; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0952, vowel: 0.0652, consonant: 0.0541\n",
      "[valid recall]total: 0.9829, grapheme: 0.9751, vowel: 0.9905, consonant: 0.9910\n",
      "================================================================================\n",
      "[EPOCH 00074]train_loss: 0.7011; val_loss: 0.0762; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0943, vowel: 0.0634, consonant: 0.0529\n",
      "[valid recall]total: 0.9832, grapheme: 0.9757, vowel: 0.9908, consonant: 0.9906\n",
      "================================================================================\n",
      "[EPOCH 00075]train_loss: 0.6959; val_loss: 0.0782; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0958, vowel: 0.0658, consonant: 0.0554\n",
      "[valid recall]total: 0.9832, grapheme: 0.9758, vowel: 0.9907, consonant: 0.9904\n",
      "================================================================================\n",
      "[EPOCH 00076]train_loss: 0.7048; val_loss: 0.0799; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.0967, vowel: 0.0686, consonant: 0.0576\n",
      "[valid recall]total: 0.9831, grapheme: 0.9758, vowel: 0.9907, consonant: 0.9902\n",
      "================================================================================\n",
      "[EPOCH 00077]train_loss: 0.6933; val_loss: 0.0794; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0953, vowel: 0.0729, consonant: 0.0542\n",
      "[valid recall]total: 0.9835, grapheme: 0.9764, vowel: 0.9908, consonant: 0.9904\n",
      "================================================================================\n",
      "[EPOCH 00078]train_loss: 0.7021; val_loss: 0.0838; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0999, vowel: 0.0747, consonant: 0.0606\n",
      "[valid recall]total: 0.9827, grapheme: 0.9753, vowel: 0.9908, consonant: 0.9893\n",
      "================================================================================\n",
      "[EPOCH 00079]train_loss: 0.6670; val_loss: 0.0708; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0892, vowel: 0.0563, consonant: 0.0484\n",
      "[valid recall]total: 0.9836, grapheme: 0.9763, vowel: 0.9914, consonant: 0.9906\n",
      "================================================================================\n",
      "[EPOCH 00080]train_loss: 0.6916; val_loss: 0.0846; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1011, vowel: 0.0742, consonant: 0.0618\n",
      "[valid recall]total: 0.9829, grapheme: 0.9751, vowel: 0.9907, consonant: 0.9907\n",
      "================================================================================\n",
      "[EPOCH 00081]train_loss: 0.6811; val_loss: 0.0711; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0881, vowel: 0.0579, consonant: 0.0503\n",
      "[valid recall]total: 0.9835, grapheme: 0.9763, vowel: 0.9907, consonant: 0.9907\n",
      "================================================================================\n",
      "[EPOCH 00082]train_loss: 0.6772; val_loss: 0.0773; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0930, vowel: 0.0681, consonant: 0.0548\n",
      "[valid recall]total: 0.9832, grapheme: 0.9756, vowel: 0.9908, consonant: 0.9907\n",
      "================================================================================\n",
      "[EPOCH 00083]train_loss: 0.6867; val_loss: 0.0902; time elapsed: 9.6 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid loss]grapheme: 0.1041, vowel: 0.0851, consonant: 0.0677\n",
      "[valid recall]total: 0.9828, grapheme: 0.9749, vowel: 0.9908, consonant: 0.9904\n",
      "================================================================================\n",
      "[EPOCH 00084]train_loss: 0.6944; val_loss: 0.0843; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1005, vowel: 0.0759, consonant: 0.0601\n",
      "[valid recall]total: 0.9828, grapheme: 0.9748, vowel: 0.9908, consonant: 0.9905\n",
      "================================================================================\n",
      "[EPOCH 00085]train_loss: 0.6923; val_loss: 0.0818; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0972, vowel: 0.0744, consonant: 0.0582\n",
      "[valid recall]total: 0.9833, grapheme: 0.9758, vowel: 0.9909, consonant: 0.9905\n",
      "================================================================================\n",
      "[EPOCH 00086]train_loss: 0.6979; val_loss: 0.0842; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1009, vowel: 0.0750, consonant: 0.0598\n",
      "[valid recall]total: 0.9835, grapheme: 0.9763, vowel: 0.9909, consonant: 0.9905\n",
      "================================================================================\n",
      "[EPOCH 00087]train_loss: 0.6764; val_loss: 0.0853; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0997, vowel: 0.0790, consonant: 0.0626\n",
      "[valid recall]total: 0.9830, grapheme: 0.9752, vowel: 0.9912, consonant: 0.9903\n",
      "================================================================================\n",
      "[EPOCH 00088]train_loss: 0.6722; val_loss: 0.0904; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1033, vowel: 0.0849, consonant: 0.0702\n",
      "[valid recall]total: 0.9829, grapheme: 0.9753, vowel: 0.9907, consonant: 0.9903\n",
      "================================================================================\n",
      "[EPOCH 00089]train_loss: 0.6996; val_loss: 0.0877; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0999, vowel: 0.0869, consonant: 0.0640\n",
      "[valid recall]total: 0.9830, grapheme: 0.9754, vowel: 0.9909, consonant: 0.9903\n",
      "================================================================================\n",
      "[EPOCH 00090]train_loss: 0.7058; val_loss: 0.0869; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1004, vowel: 0.0826, consonant: 0.0640\n",
      "[valid recall]total: 0.9831, grapheme: 0.9754, vowel: 0.9907, consonant: 0.9907\n",
      "================================================================================\n",
      "[EPOCH 00091]train_loss: 0.6853; val_loss: 0.0740; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0924, vowel: 0.0601, consonant: 0.0511\n",
      "[valid recall]total: 0.9835, grapheme: 0.9763, vowel: 0.9910, consonant: 0.9905\n",
      "================================================================================\n",
      "[EPOCH 00092]train_loss: 0.6860; val_loss: 0.0813; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0970, vowel: 0.0685, consonant: 0.0624\n",
      "[valid recall]total: 0.9831, grapheme: 0.9752, vowel: 0.9910, consonant: 0.9909\n",
      "================================================================================\n",
      "[EPOCH 00093]train_loss: 0.6995; val_loss: 0.0777; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0941, vowel: 0.0657, consonant: 0.0568\n",
      "[valid recall]total: 0.9832, grapheme: 0.9758, vowel: 0.9908, consonant: 0.9905\n",
      "================================================================================\n",
      "[EPOCH 00094]train_loss: 0.6864; val_loss: 0.1062; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1172, vowel: 0.1087, consonant: 0.0818\n",
      "[valid recall]total: 0.9816, grapheme: 0.9733, vowel: 0.9904, consonant: 0.9895\n",
      "================================================================================\n",
      "[EPOCH 00095]train_loss: 0.6998; val_loss: 0.0815; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0977, vowel: 0.0743, consonant: 0.0563\n",
      "[valid recall]total: 0.9836, grapheme: 0.9765, vowel: 0.9908, consonant: 0.9904\n",
      "================================================================================\n",
      "[EPOCH 00096]train_loss: 0.6731; val_loss: 0.0678; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.0878, vowel: 0.0496, consonant: 0.0460\n",
      "[valid recall]total: 0.9840, grapheme: 0.9770, vowel: 0.9911, consonant: 0.9907\n",
      "================================================================================\n",
      "[EPOCH 00097]train_loss: 0.6931; val_loss: 0.0873; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1019, vowel: 0.0804, consonant: 0.0650\n",
      "[valid recall]total: 0.9831, grapheme: 0.9758, vowel: 0.9907, consonant: 0.9902\n",
      "================================================================================\n",
      "[EPOCH 00098]train_loss: 0.6764; val_loss: 0.0909; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1026, vowel: 0.0889, consonant: 0.0694\n",
      "[valid recall]total: 0.9825, grapheme: 0.9746, vowel: 0.9906, consonant: 0.9901\n",
      "================================================================================\n",
      "[EPOCH 00099]train_loss: 0.6934; val_loss: 0.0991; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1110, vowel: 0.0992, consonant: 0.0754\n",
      "[valid recall]total: 0.9827, grapheme: 0.9748, vowel: 0.9910, consonant: 0.9902\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 3========\n",
      "[     0      1      3 ... 200837 200838 200839]\n",
      "[     2      7      9 ... 200814 200822 200828]\n",
      "checkpoint_path:  ../checkpoint/v2-fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model state_dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00000]train_loss: 2.2895; val_loss: 0.5173; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.7388, vowel: 0.3199, consonant: 0.2718\n",
      "[valid recall]total: 0.8245, grapheme: 0.7564, vowel: 0.9103, consonant: 0.8750\n",
      "================================================================================\n",
      "[EPOCH 00001]train_loss: 1.5626; val_loss: 0.3131; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.4288, vowel: 0.2138, consonant: 0.1810\n",
      "[valid recall]total: 0.9120, grapheme: 0.8804, vowel: 0.9533, consonant: 0.9337\n",
      "================================================================================\n",
      "[EPOCH 00002]train_loss: 1.3567; val_loss: 0.3116; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.4116, vowel: 0.2286, consonant: 0.1946\n",
      "[valid recall]total: 0.9207, grapheme: 0.9054, vowel: 0.9603, consonant: 0.9116\n",
      "================================================================================\n",
      "[EPOCH 00003]train_loss: 1.2725; val_loss: 0.2228; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.2945, vowel: 0.1591, consonant: 0.1429\n",
      "[valid recall]total: 0.9402, grapheme: 0.9202, vowel: 0.9712, consonant: 0.9493\n",
      "================================================================================\n",
      "[EPOCH 00004]train_loss: 1.1942; val_loss: 0.1991; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2581, vowel: 0.1497, consonant: 0.1306\n",
      "[valid recall]total: 0.9516, grapheme: 0.9319, vowel: 0.9777, consonant: 0.9650\n",
      "================================================================================\n",
      "[EPOCH 00005]train_loss: 1.1832; val_loss: 0.1974; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2534, vowel: 0.1536, consonant: 0.1293\n",
      "[valid recall]total: 0.9502, grapheme: 0.9332, vowel: 0.9723, consonant: 0.9621\n",
      "================================================================================\n",
      "[EPOCH 00006]train_loss: 1.1325; val_loss: 0.1853; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.2436, vowel: 0.1367, consonant: 0.1174\n",
      "[valid recall]total: 0.9510, grapheme: 0.9317, vowel: 0.9751, consonant: 0.9655\n",
      "================================================================================\n",
      "[EPOCH 00007]train_loss: 1.0874; val_loss: 0.1928; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2550, vowel: 0.1412, consonant: 0.1200\n",
      "[valid recall]total: 0.9542, grapheme: 0.9362, vowel: 0.9764, consonant: 0.9681\n",
      "================================================================================\n",
      "[EPOCH 00008]train_loss: 1.0647; val_loss: 0.1803; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2355, vowel: 0.1333, consonant: 0.1170\n",
      "[valid recall]total: 0.9577, grapheme: 0.9457, vowel: 0.9762, consonant: 0.9634\n",
      "================================================================================\n",
      "[EPOCH 00009]train_loss: 1.0351; val_loss: 0.1661; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.2139, vowel: 0.1328, consonant: 0.1036\n",
      "[valid recall]total: 0.9604, grapheme: 0.9492, vowel: 0.9789, consonant: 0.9644\n",
      "================================================================================\n",
      "[EPOCH 00010]train_loss: 1.0095; val_loss: 0.1832; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.2514, vowel: 0.1296, consonant: 0.1006\n",
      "[valid recall]total: 0.9487, grapheme: 0.9262, vowel: 0.9699, consonant: 0.9726\n",
      "================================================================================\n",
      "[EPOCH 00011]train_loss: 1.0201; val_loss: 0.1893; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2381, vowel: 0.1588, consonant: 0.1222\n",
      "[valid recall]total: 0.9633, grapheme: 0.9514, vowel: 0.9828, consonant: 0.9675\n",
      "================================================================================\n",
      "[EPOCH 00012]train_loss: 1.0148; val_loss: 0.1364; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1717, vowel: 0.1157, consonant: 0.0866\n",
      "[valid recall]total: 0.9662, grapheme: 0.9552, vowel: 0.9828, consonant: 0.9717\n",
      "================================================================================\n",
      "[EPOCH 00013]train_loss: 0.9573; val_loss: 0.1538; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1969, vowel: 0.1273, consonant: 0.0941\n",
      "[valid recall]total: 0.9659, grapheme: 0.9558, vowel: 0.9834, consonant: 0.9686\n",
      "================================================================================\n",
      "[EPOCH 00014]train_loss: 0.9684; val_loss: 0.1640; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2149, vowel: 0.1245, consonant: 0.1018\n",
      "[valid recall]total: 0.9622, grapheme: 0.9493, vowel: 0.9818, consonant: 0.9686\n",
      "================================================================================\n",
      "[EPOCH 00015]train_loss: 0.9724; val_loss: 0.1191; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1563, vowel: 0.0881, consonant: 0.0755\n",
      "[valid recall]total: 0.9699, grapheme: 0.9596, vowel: 0.9860, consonant: 0.9743\n",
      "================================================================================\n",
      "[EPOCH 00016]train_loss: 0.9792; val_loss: 0.1325; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1755, vowel: 0.1006, consonant: 0.0783\n",
      "[valid recall]total: 0.9672, grapheme: 0.9549, vowel: 0.9835, consonant: 0.9754\n",
      "================================================================================\n",
      "[EPOCH 00017]train_loss: 0.9501; val_loss: 0.1277; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1625, vowel: 0.1050, consonant: 0.0808\n",
      "[valid recall]total: 0.9696, grapheme: 0.9589, vowel: 0.9866, consonant: 0.9741\n",
      "================================================================================\n",
      "[EPOCH 00018]train_loss: 0.9187; val_loss: 0.1627; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2025, vowel: 0.1328, consonant: 0.1128\n",
      "[valid recall]total: 0.9628, grapheme: 0.9494, vowel: 0.9808, consonant: 0.9716\n",
      "================================================================================\n",
      "[EPOCH 00019]train_loss: 0.9404; val_loss: 0.1544; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1879, vowel: 0.1403, consonant: 0.1016\n",
      "[valid recall]total: 0.9681, grapheme: 0.9589, vowel: 0.9844, consonant: 0.9701\n",
      "================================================================================\n",
      "[EPOCH 00020]train_loss: 0.9259; val_loss: 0.1140; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1481, vowel: 0.0845, consonant: 0.0752\n",
      "[valid recall]total: 0.9691, grapheme: 0.9596, vowel: 0.9845, consonant: 0.9730\n",
      "================================================================================\n",
      "[EPOCH 00021]train_loss: 0.9280; val_loss: 0.1326; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1727, vowel: 0.1013, consonant: 0.0838\n",
      "[valid recall]total: 0.9677, grapheme: 0.9567, vowel: 0.9847, consonant: 0.9727\n",
      "================================================================================\n",
      "[EPOCH 00022]train_loss: 0.8831; val_loss: 0.1172; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1506, vowel: 0.0906, consonant: 0.0773\n",
      "[valid recall]total: 0.9701, grapheme: 0.9595, vowel: 0.9848, consonant: 0.9764\n",
      "================================================================================\n",
      "[EPOCH 00023]train_loss: 0.8887; val_loss: 0.1097; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1465, vowel: 0.0789, consonant: 0.0669\n",
      "[valid recall]total: 0.9721, grapheme: 0.9621, vowel: 0.9867, consonant: 0.9774\n",
      "================================================================================\n",
      "[EPOCH 00024]train_loss: 0.9134; val_loss: 0.1013; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1296, vowel: 0.0765, consonant: 0.0693\n",
      "[valid recall]total: 0.9734, grapheme: 0.9654, vowel: 0.9865, consonant: 0.9763\n",
      "================================================================================\n",
      "[EPOCH 00025]train_loss: 0.8916; val_loss: 0.0972; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1266, vowel: 0.0708, consonant: 0.0646\n",
      "[valid recall]total: 0.9735, grapheme: 0.9638, vowel: 0.9867, consonant: 0.9799\n",
      "================================================================================\n",
      "[EPOCH 00026]train_loss: 0.8928; val_loss: 0.1105; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1381, vowel: 0.0901, consonant: 0.0758\n",
      "[valid recall]total: 0.9724, grapheme: 0.9617, vowel: 0.9880, consonant: 0.9782\n",
      "================================================================================\n",
      "[EPOCH 00027]train_loss: 0.8676; val_loss: 0.1496; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1829, vowel: 0.1371, consonant: 0.0954\n",
      "[valid recall]total: 0.9695, grapheme: 0.9582, vowel: 0.9863, consonant: 0.9751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[EPOCH 00028]train_loss: 0.8557; val_loss: 0.1149; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1475, vowel: 0.0896, consonant: 0.0749\n",
      "[valid recall]total: 0.9714, grapheme: 0.9599, vowel: 0.9889, consonant: 0.9768\n",
      "================================================================================\n",
      "[EPOCH 00029]train_loss: 0.9085; val_loss: 0.1447; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1694, vowel: 0.1391, consonant: 0.1008\n",
      "[valid recall]total: 0.9735, grapheme: 0.9645, vowel: 0.9865, consonant: 0.9786\n",
      "================================================================================\n",
      "[EPOCH 00030]train_loss: 0.8576; val_loss: 0.1223; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1529, vowel: 0.1028, consonant: 0.0807\n",
      "[valid recall]total: 0.9724, grapheme: 0.9650, vowel: 0.9850, consonant: 0.9746\n",
      "================================================================================\n",
      "[EPOCH 00031]train_loss: 0.8369; val_loss: 0.1151; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1468, vowel: 0.0919, consonant: 0.0750\n",
      "[valid recall]total: 0.9729, grapheme: 0.9628, vowel: 0.9882, consonant: 0.9780\n",
      "================================================================================\n",
      "[EPOCH 00032]train_loss: 0.8061; val_loss: 0.1145; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1419, vowel: 0.0985, consonant: 0.0757\n",
      "[valid recall]total: 0.9768, grapheme: 0.9699, vowel: 0.9883, consonant: 0.9791\n",
      "================================================================================\n",
      "[EPOCH 00033]train_loss: 0.7997; val_loss: 0.1095; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1340, vowel: 0.0977, consonant: 0.0725\n",
      "[valid recall]total: 0.9765, grapheme: 0.9682, vowel: 0.9892, consonant: 0.9806\n",
      "================================================================================\n",
      "[EPOCH 00034]train_loss: 0.8109; val_loss: 0.1148; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1412, vowel: 0.0987, consonant: 0.0781\n",
      "[valid recall]total: 0.9765, grapheme: 0.9687, vowel: 0.9882, consonant: 0.9805\n",
      "================================================================================\n",
      "[EPOCH 00035]train_loss: 0.8270; val_loss: 0.0984; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1204, vowel: 0.0847, consonant: 0.0680\n",
      "[valid recall]total: 0.9784, grapheme: 0.9722, vowel: 0.9900, consonant: 0.9793\n",
      "================================================================================\n",
      "[EPOCH 00036]train_loss: 0.7920; val_loss: 0.0957; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1170, vowel: 0.0851, consonant: 0.0635\n",
      "[valid recall]total: 0.9789, grapheme: 0.9722, vowel: 0.9901, consonant: 0.9813\n",
      "================================================================================\n",
      "[EPOCH 00037]train_loss: 0.7590; val_loss: 0.1078; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1271, vowel: 0.1013, consonant: 0.0756\n",
      "[valid recall]total: 0.9778, grapheme: 0.9707, vowel: 0.9885, consonant: 0.9814\n",
      "================================================================================\n",
      "[EPOCH 00038]train_loss: 0.7925; val_loss: 0.1039; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1245, vowel: 0.0948, consonant: 0.0717\n",
      "[valid recall]total: 0.9788, grapheme: 0.9705, vowel: 0.9900, consonant: 0.9842\n",
      "================================================================================\n",
      "[EPOCH 00039]train_loss: 0.7873; val_loss: 0.0893; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1107, vowel: 0.0751, consonant: 0.0610\n",
      "[valid recall]total: 0.9788, grapheme: 0.9713, vowel: 0.9890, consonant: 0.9836\n",
      "================================================================================\n",
      "[EPOCH 00040]train_loss: 0.7822; val_loss: 0.0999; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1169, vowel: 0.0978, consonant: 0.0678\n",
      "[valid recall]total: 0.9783, grapheme: 0.9704, vowel: 0.9886, consonant: 0.9837\n",
      "================================================================================\n",
      "[EPOCH 00041]train_loss: 0.7771; val_loss: 0.1163; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1339, vowel: 0.1110, consonant: 0.0867\n",
      "[valid recall]total: 0.9782, grapheme: 0.9712, vowel: 0.9899, consonant: 0.9804\n",
      "================================================================================\n",
      "[EPOCH 00042]train_loss: 0.7881; val_loss: 0.0916; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1115, vowel: 0.0803, consonant: 0.0629\n",
      "[valid recall]total: 0.9787, grapheme: 0.9728, vowel: 0.9891, consonant: 0.9802\n",
      "================================================================================\n",
      "[EPOCH 00043]train_loss: 0.7713; val_loss: 0.0881; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1116, vowel: 0.0710, consonant: 0.0581\n",
      "[valid recall]total: 0.9790, grapheme: 0.9732, vowel: 0.9892, consonant: 0.9804\n",
      "================================================================================\n",
      "[EPOCH 00044]train_loss: 0.7640; val_loss: 0.0952; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1197, vowel: 0.0769, consonant: 0.0645\n",
      "[valid recall]total: 0.9772, grapheme: 0.9703, vowel: 0.9877, consonant: 0.9807\n",
      "================================================================================\n",
      "[EPOCH 00045]train_loss: 0.7665; val_loss: 0.0978; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1174, vowel: 0.0868, consonant: 0.0698\n",
      "[valid recall]total: 0.9786, grapheme: 0.9715, vowel: 0.9897, consonant: 0.9815\n",
      "================================================================================\n",
      "[EPOCH 00046]train_loss: 0.7753; val_loss: 0.0927; time elapsed: 9.2 min\n",
      "[valid loss]grapheme: 0.1137, vowel: 0.0774, consonant: 0.0658\n",
      "[valid recall]total: 0.9785, grapheme: 0.9716, vowel: 0.9885, consonant: 0.9823\n",
      "================================================================================\n",
      "[EPOCH 00047]train_loss: 0.7494; val_loss: 0.0796; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1013, vowel: 0.0620, consonant: 0.0541\n",
      "[valid recall]total: 0.9793, grapheme: 0.9734, vowel: 0.9900, consonant: 0.9805\n",
      "================================================================================\n",
      "[EPOCH 00048]train_loss: 0.7525; val_loss: 0.1063; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1240, vowel: 0.0984, consonant: 0.0789\n",
      "[valid recall]total: 0.9780, grapheme: 0.9712, vowel: 0.9894, consonant: 0.9801\n",
      "================================================================================\n",
      "[EPOCH 00049]train_loss: 0.7871; val_loss: 0.1138; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1305, vowel: 0.1093, consonant: 0.0848\n",
      "[valid recall]total: 0.9769, grapheme: 0.9693, vowel: 0.9884, consonant: 0.9805\n",
      "================================================================================\n",
      "[EPOCH 00050]train_loss: 0.7581; val_loss: 0.0901; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1154, vowel: 0.0690, consonant: 0.0606\n",
      "[valid recall]total: 0.9782, grapheme: 0.9711, vowel: 0.9896, consonant: 0.9811\n",
      "================================================================================\n",
      "[EPOCH 00051]train_loss: 0.7613; val_loss: 0.0814; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1020, vowel: 0.0629, consonant: 0.0588\n",
      "[valid recall]total: 0.9796, grapheme: 0.9724, vowel: 0.9905, consonant: 0.9833\n",
      "================================================================================\n",
      "[EPOCH 00052]train_loss: 0.7566; val_loss: 0.0824; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1018, vowel: 0.0685, consonant: 0.0577\n",
      "[valid recall]total: 0.9802, grapheme: 0.9736, vowel: 0.9903, consonant: 0.9832\n",
      "================================================================================\n",
      "[EPOCH 00053]train_loss: 0.7554; val_loss: 0.0888; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1101, vowel: 0.0723, consonant: 0.0625\n",
      "[valid recall]total: 0.9787, grapheme: 0.9709, vowel: 0.9901, consonant: 0.9830\n",
      "================================================================================\n",
      "[EPOCH 00054]train_loss: 0.7399; val_loss: 0.0815; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1007, vowel: 0.0689, consonant: 0.0556\n",
      "[valid recall]total: 0.9813, grapheme: 0.9755, vowel: 0.9906, consonant: 0.9837\n",
      "================================================================================\n",
      "[EPOCH 00055]train_loss: 0.7477; val_loss: 0.0919; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1062, vowel: 0.0867, consonant: 0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid recall]total: 0.9801, grapheme: 0.9742, vowel: 0.9903, consonant: 0.9818\n",
      "================================================================================\n",
      "[EPOCH 00056]train_loss: 0.7291; val_loss: 0.0874; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1023, vowel: 0.0797, consonant: 0.0651\n",
      "[valid recall]total: 0.9810, grapheme: 0.9754, vowel: 0.9909, consonant: 0.9823\n",
      "================================================================================\n",
      "[EPOCH 00057]train_loss: 0.7397; val_loss: 0.0912; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1057, vowel: 0.0872, consonant: 0.0659\n",
      "[valid recall]total: 0.9814, grapheme: 0.9756, vowel: 0.9900, consonant: 0.9844\n",
      "================================================================================\n",
      "[EPOCH 00058]train_loss: 0.7267; val_loss: 0.0813; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1023, vowel: 0.0657, consonant: 0.0547\n",
      "[valid recall]total: 0.9816, grapheme: 0.9757, vowel: 0.9904, consonant: 0.9845\n",
      "================================================================================\n",
      "[EPOCH 00059]train_loss: 0.7239; val_loss: 0.0978; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1119, vowel: 0.0903, consonant: 0.0770\n",
      "[valid recall]total: 0.9806, grapheme: 0.9746, vowel: 0.9903, consonant: 0.9829\n",
      "================================================================================\n",
      "[EPOCH 00060]train_loss: 0.7207; val_loss: 0.0916; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1043, vowel: 0.0894, consonant: 0.0682\n",
      "[valid recall]total: 0.9813, grapheme: 0.9754, vowel: 0.9906, consonant: 0.9838\n",
      "================================================================================\n",
      "[EPOCH 00061]train_loss: 0.7086; val_loss: 0.0867; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1011, vowel: 0.0801, consonant: 0.0647\n",
      "[valid recall]total: 0.9808, grapheme: 0.9744, vowel: 0.9906, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00062]train_loss: 0.7175; val_loss: 0.0799; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0974, vowel: 0.0683, consonant: 0.0567\n",
      "[valid recall]total: 0.9814, grapheme: 0.9749, vowel: 0.9908, consonant: 0.9849\n",
      "================================================================================\n",
      "[EPOCH 00063]train_loss: 0.6987; val_loss: 0.0829; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0984, vowel: 0.0760, consonant: 0.0587\n",
      "[valid recall]total: 0.9819, grapheme: 0.9755, vowel: 0.9914, consonant: 0.9854\n",
      "================================================================================\n",
      "[EPOCH 00064]train_loss: 0.6931; val_loss: 0.0869; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0999, vowel: 0.0835, consonant: 0.0643\n",
      "[valid recall]total: 0.9815, grapheme: 0.9755, vowel: 0.9909, consonant: 0.9842\n",
      "================================================================================\n",
      "[EPOCH 00065]train_loss: 0.7002; val_loss: 0.0806; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0958, vowel: 0.0729, consonant: 0.0580\n",
      "[valid recall]total: 0.9817, grapheme: 0.9758, vowel: 0.9912, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00066]train_loss: 0.7231; val_loss: 0.0851; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0999, vowel: 0.0801, consonant: 0.0603\n",
      "[valid recall]total: 0.9822, grapheme: 0.9761, vowel: 0.9916, consonant: 0.9850\n",
      "================================================================================\n",
      "[EPOCH 00067]train_loss: 0.6934; val_loss: 0.0867; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1007, vowel: 0.0819, consonant: 0.0635\n",
      "[valid recall]total: 0.9821, grapheme: 0.9758, vowel: 0.9913, consonant: 0.9855\n",
      "================================================================================\n",
      "Early Stopping: val_metric does not increase 20 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 4========\n",
      "[     0      1      2 ... 200837 200838 200839]\n",
      "[     5     10     15 ... 200818 200830 200835]\n",
      "checkpoint_path:  ../checkpoint/v2-fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model state_dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00000]train_loss: 2.2547; val_loss: 0.5301; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.7649, vowel: 0.3446, consonant: 0.2460\n",
      "[valid recall]total: 0.8233, grapheme: 0.7767, vowel: 0.9172, consonant: 0.8225\n",
      "================================================================================\n",
      "[EPOCH 00001]train_loss: 1.5355; val_loss: 0.3168; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.4357, vowel: 0.2153, consonant: 0.1807\n",
      "[valid recall]total: 0.9063, grapheme: 0.8752, vowel: 0.9498, consonant: 0.9252\n",
      "================================================================================\n",
      "[EPOCH 00002]train_loss: 1.4048; val_loss: 0.3116; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.4215, vowel: 0.2258, consonant: 0.1774\n",
      "[valid recall]total: 0.9180, grapheme: 0.9025, vowel: 0.9503, consonant: 0.9168\n",
      "================================================================================\n",
      "[EPOCH 00003]train_loss: 1.2714; val_loss: 0.2130; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.2808, vowel: 0.1559, consonant: 0.1344\n",
      "[valid recall]total: 0.9439, grapheme: 0.9215, vowel: 0.9698, consonant: 0.9627\n",
      "================================================================================\n",
      "[EPOCH 00004]train_loss: 1.2231; val_loss: 0.2299; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.2918, vowel: 0.1819, consonant: 0.1542\n",
      "[valid recall]total: 0.9460, grapheme: 0.9297, vowel: 0.9683, consonant: 0.9560\n",
      "================================================================================\n",
      "[EPOCH 00005]train_loss: 1.1579; val_loss: 0.1857; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2434, vowel: 0.1391, consonant: 0.1169\n",
      "[valid recall]total: 0.9518, grapheme: 0.9358, vowel: 0.9725, consonant: 0.9633\n",
      "================================================================================\n",
      "[EPOCH 00006]train_loss: 1.1147; val_loss: 0.2013; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2653, vowel: 0.1497, consonant: 0.1248\n",
      "[valid recall]total: 0.9564, grapheme: 0.9419, vowel: 0.9756, consonant: 0.9662\n",
      "================================================================================\n",
      "[EPOCH 00007]train_loss: 1.0989; val_loss: 0.1599; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2211, vowel: 0.1015, consonant: 0.0959\n",
      "[valid recall]total: 0.9495, grapheme: 0.9361, vowel: 0.9722, consonant: 0.9537\n",
      "================================================================================\n",
      "[EPOCH 00008]train_loss: 1.0892; val_loss: 0.1884; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.2450, vowel: 0.1487, consonant: 0.1148\n",
      "[valid recall]total: 0.9570, grapheme: 0.9421, vowel: 0.9761, consonant: 0.9678\n",
      "================================================================================\n",
      "[EPOCH 00009]train_loss: 1.0730; val_loss: 0.1850; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.2386, vowel: 0.1486, consonant: 0.1142\n",
      "[valid recall]total: 0.9564, grapheme: 0.9433, vowel: 0.9773, consonant: 0.9615\n",
      "================================================================================\n",
      "[EPOCH 00010]train_loss: 1.0450; val_loss: 0.1507; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.2030, vowel: 0.1013, consonant: 0.0953\n",
      "[valid recall]total: 0.9578, grapheme: 0.9423, vowel: 0.9789, consonant: 0.9676\n",
      "================================================================================\n",
      "[EPOCH 00011]train_loss: 1.0041; val_loss: 0.1763; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.2278, vowel: 0.1472, consonant: 0.1025\n",
      "[valid recall]total: 0.9624, grapheme: 0.9507, vowel: 0.9779, consonant: 0.9702\n",
      "================================================================================\n",
      "[EPOCH 00012]train_loss: 0.9997; val_loss: 0.1414; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1860, vowel: 0.1051, consonant: 0.0886\n",
      "[valid recall]total: 0.9639, grapheme: 0.9491, vowel: 0.9807, consonant: 0.9766\n",
      "================================================================================\n",
      "[EPOCH 00013]train_loss: 0.9835; val_loss: 0.1407; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1835, vowel: 0.1088, consonant: 0.0871\n",
      "[valid recall]total: 0.9636, grapheme: 0.9508, vowel: 0.9824, consonant: 0.9703\n",
      "================================================================================\n",
      "[EPOCH 00014]train_loss: 0.9547; val_loss: 0.1493; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1896, vowel: 0.1205, consonant: 0.0977\n",
      "[valid recall]total: 0.9645, grapheme: 0.9533, vowel: 0.9828, consonant: 0.9685\n",
      "================================================================================\n",
      "[EPOCH 00015]train_loss: 0.9461; val_loss: 0.1372; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1760, vowel: 0.1081, consonant: 0.0888\n",
      "[valid recall]total: 0.9654, grapheme: 0.9553, vowel: 0.9819, consonant: 0.9690\n",
      "================================================================================\n",
      "[EPOCH 00016]train_loss: 0.9348; val_loss: 0.1442; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1863, vowel: 0.1122, consonant: 0.0919\n",
      "[valid recall]total: 0.9646, grapheme: 0.9527, vowel: 0.9814, consonant: 0.9716\n",
      "================================================================================\n",
      "[EPOCH 00017]train_loss: 0.9543; val_loss: 0.1435; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1829, vowel: 0.1171, consonant: 0.0911\n",
      "[valid recall]total: 0.9666, grapheme: 0.9525, vowel: 0.9828, consonant: 0.9784\n",
      "================================================================================\n",
      "[EPOCH 00018]train_loss: 0.9474; val_loss: 0.1442; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1786, vowel: 0.1229, consonant: 0.0968\n",
      "[valid recall]total: 0.9658, grapheme: 0.9543, vowel: 0.9857, consonant: 0.9688\n",
      "================================================================================\n",
      "[EPOCH 00019]train_loss: 0.9155; val_loss: 0.1543; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1898, vowel: 0.1388, consonant: 0.0986\n",
      "[valid recall]total: 0.9670, grapheme: 0.9536, vowel: 0.9829, consonant: 0.9778\n",
      "================================================================================\n",
      "[EPOCH 00020]train_loss: 0.9381; val_loss: 0.1266; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1656, vowel: 0.0925, consonant: 0.0828\n",
      "[valid recall]total: 0.9683, grapheme: 0.9556, vowel: 0.9827, consonant: 0.9793\n",
      "================================================================================\n",
      "[EPOCH 00021]train_loss: 0.9233; val_loss: 0.1472; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1821, vowel: 0.1272, consonant: 0.0972\n",
      "[valid recall]total: 0.9668, grapheme: 0.9538, vowel: 0.9846, consonant: 0.9748\n",
      "================================================================================\n",
      "[EPOCH 00022]train_loss: 0.8950; val_loss: 0.1271; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1678, vowel: 0.0937, consonant: 0.0794\n",
      "[valid recall]total: 0.9675, grapheme: 0.9562, vowel: 0.9850, consonant: 0.9723\n",
      "================================================================================\n",
      "[EPOCH 00023]train_loss: 0.8991; val_loss: 0.1320; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1609, vowel: 0.1169, consonant: 0.0892\n",
      "[valid recall]total: 0.9701, grapheme: 0.9567, vowel: 0.9869, consonant: 0.9801\n",
      "================================================================================\n",
      "[EPOCH 00024]train_loss: 0.8585; val_loss: 0.1070; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1376, vowel: 0.0823, consonant: 0.0704\n",
      "[valid recall]total: 0.9715, grapheme: 0.9593, vowel: 0.9865, consonant: 0.9807\n",
      "================================================================================\n",
      "[EPOCH 00025]train_loss: 0.8836; val_loss: 0.1225; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1546, vowel: 0.0991, consonant: 0.0818\n",
      "[valid recall]total: 0.9699, grapheme: 0.9598, vowel: 0.9846, consonant: 0.9756\n",
      "================================================================================\n",
      "[EPOCH 00026]train_loss: 0.8804; val_loss: 0.1217; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1521, vowel: 0.0991, consonant: 0.0835\n",
      "[valid recall]total: 0.9708, grapheme: 0.9608, vowel: 0.9842, consonant: 0.9776\n",
      "================================================================================\n",
      "[EPOCH 00027]train_loss: 0.8660; val_loss: 0.1176; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1466, vowel: 0.0988, consonant: 0.0786\n",
      "[valid recall]total: 0.9727, grapheme: 0.9630, vowel: 0.9843, consonant: 0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[EPOCH 00028]train_loss: 0.8676; val_loss: 0.1148; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1473, vowel: 0.0885, consonant: 0.0761\n",
      "[valid recall]total: 0.9718, grapheme: 0.9612, vowel: 0.9853, consonant: 0.9793\n",
      "================================================================================\n",
      "[EPOCH 00029]train_loss: 0.8585; val_loss: 0.1075; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1387, vowel: 0.0786, consonant: 0.0742\n",
      "[valid recall]total: 0.9724, grapheme: 0.9623, vowel: 0.9864, consonant: 0.9788\n",
      "================================================================================\n",
      "[EPOCH 00030]train_loss: 0.8190; val_loss: 0.1178; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1485, vowel: 0.0934, consonant: 0.0806\n",
      "[valid recall]total: 0.9715, grapheme: 0.9624, vowel: 0.9863, consonant: 0.9751\n",
      "================================================================================\n",
      "[EPOCH 00031]train_loss: 0.8422; val_loss: 0.1209; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1439, vowel: 0.1103, consonant: 0.0855\n",
      "[valid recall]total: 0.9744, grapheme: 0.9655, vowel: 0.9868, consonant: 0.9800\n",
      "================================================================================\n",
      "[EPOCH 00032]train_loss: 0.8004; val_loss: 0.0934; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1167, vowel: 0.0737, consonant: 0.0667\n",
      "[valid recall]total: 0.9759, grapheme: 0.9684, vowel: 0.9872, consonant: 0.9797\n",
      "================================================================================\n",
      "[EPOCH 00033]train_loss: 0.8014; val_loss: 0.1058; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1287, vowel: 0.0930, consonant: 0.0727\n",
      "[valid recall]total: 0.9764, grapheme: 0.9677, vowel: 0.9877, consonant: 0.9824\n",
      "================================================================================\n",
      "[EPOCH 00034]train_loss: 0.7854; val_loss: 0.1227; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1431, vowel: 0.1174, consonant: 0.0871\n",
      "[valid recall]total: 0.9742, grapheme: 0.9637, vowel: 0.9876, consonant: 0.9819\n",
      "================================================================================\n",
      "[EPOCH 00035]train_loss: 0.7735; val_loss: 0.0956; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1196, vowel: 0.0774, consonant: 0.0658\n",
      "[valid recall]total: 0.9752, grapheme: 0.9652, vowel: 0.9877, consonant: 0.9827\n",
      "================================================================================\n",
      "[EPOCH 00036]train_loss: 0.7977; val_loss: 0.1195; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1415, vowel: 0.1132, consonant: 0.0820\n",
      "[valid recall]total: 0.9755, grapheme: 0.9667, vowel: 0.9874, consonant: 0.9811\n",
      "================================================================================\n",
      "[EPOCH 00037]train_loss: 0.7745; val_loss: 0.1042; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1277, vowel: 0.0888, consonant: 0.0726\n",
      "[valid recall]total: 0.9751, grapheme: 0.9648, vowel: 0.9876, consonant: 0.9830\n",
      "================================================================================\n",
      "[EPOCH 00038]train_loss: 0.7747; val_loss: 0.1109; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1350, vowel: 0.0956, consonant: 0.0779\n",
      "[valid recall]total: 0.9750, grapheme: 0.9666, vowel: 0.9858, consonant: 0.9809\n",
      "================================================================================\n",
      "[EPOCH 00039]train_loss: 0.7306; val_loss: 0.0831; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1055, vowel: 0.0633, consonant: 0.0582\n",
      "[valid recall]total: 0.9778, grapheme: 0.9692, vowel: 0.9884, consonant: 0.9844\n",
      "================================================================================\n",
      "[EPOCH 00040]train_loss: 0.7725; val_loss: 0.1061; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1240, vowel: 0.0998, consonant: 0.0768\n",
      "[valid recall]total: 0.9769, grapheme: 0.9702, vowel: 0.9878, consonant: 0.9796\n",
      "================================================================================\n",
      "[EPOCH 00041]train_loss: 0.7517; val_loss: 0.0975; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1175, vowel: 0.0860, consonant: 0.0688\n",
      "[valid recall]total: 0.9779, grapheme: 0.9702, vowel: 0.9877, consonant: 0.9835\n",
      "================================================================================\n",
      "[EPOCH 00042]train_loss: 0.7412; val_loss: 0.1003; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1198, vowel: 0.0897, consonant: 0.0719\n",
      "[valid recall]total: 0.9775, grapheme: 0.9701, vowel: 0.9875, consonant: 0.9824\n",
      "================================================================================\n",
      "[EPOCH 00043]train_loss: 0.7383; val_loss: 0.0950; time elapsed: 9.2 min\n",
      "[valid loss]grapheme: 0.1157, vowel: 0.0810, consonant: 0.0677\n",
      "[valid recall]total: 0.9774, grapheme: 0.9703, vowel: 0.9873, consonant: 0.9815\n",
      "================================================================================\n",
      "[EPOCH 00044]train_loss: 0.7585; val_loss: 0.1001; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1190, vowel: 0.0901, consonant: 0.0723\n",
      "[valid recall]total: 0.9778, grapheme: 0.9705, vowel: 0.9883, consonant: 0.9817\n",
      "================================================================================\n",
      "[EPOCH 00045]train_loss: 0.7521; val_loss: 0.0986; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1202, vowel: 0.0847, consonant: 0.0692\n",
      "[valid recall]total: 0.9778, grapheme: 0.9701, vowel: 0.9884, consonant: 0.9827\n",
      "================================================================================\n",
      "[EPOCH 00046]train_loss: 0.7386; val_loss: 0.1122; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1266, vowel: 0.1138, consonant: 0.0820\n",
      "[valid recall]total: 0.9777, grapheme: 0.9704, vowel: 0.9882, consonant: 0.9817\n",
      "================================================================================\n",
      "[EPOCH 00047]train_loss: 0.7283; val_loss: 0.0958; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1125, vowel: 0.0886, consonant: 0.0695\n",
      "[valid recall]total: 0.9795, grapheme: 0.9726, vowel: 0.9884, consonant: 0.9844\n",
      "================================================================================\n",
      "[EPOCH 00048]train_loss: 0.7123; val_loss: 0.0761; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0965, vowel: 0.0579, consonant: 0.0533\n",
      "[valid recall]total: 0.9799, grapheme: 0.9721, vowel: 0.9889, consonant: 0.9864\n",
      "================================================================================\n",
      "[EPOCH 00049]train_loss: 0.7407; val_loss: 0.0907; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1073, vowel: 0.0820, consonant: 0.0662\n",
      "[valid recall]total: 0.9800, grapheme: 0.9731, vowel: 0.9888, consonant: 0.9849\n",
      "================================================================================\n",
      "[EPOCH 00050]train_loss: 0.7237; val_loss: 0.0851; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1043, vowel: 0.0716, consonant: 0.0601\n",
      "[valid recall]total: 0.9791, grapheme: 0.9722, vowel: 0.9886, consonant: 0.9834\n",
      "================================================================================\n",
      "[EPOCH 00051]train_loss: 0.7205; val_loss: 0.0830; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1015, vowel: 0.0704, consonant: 0.0587\n",
      "[valid recall]total: 0.9800, grapheme: 0.9733, vowel: 0.9888, consonant: 0.9848\n",
      "================================================================================\n",
      "[EPOCH 00052]train_loss: 0.7142; val_loss: 0.0839; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1018, vowel: 0.0717, consonant: 0.0604\n",
      "[valid recall]total: 0.9799, grapheme: 0.9728, vowel: 0.9893, consonant: 0.9848\n",
      "================================================================================\n",
      "[EPOCH 00053]train_loss: 0.7187; val_loss: 0.0943; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1126, vowel: 0.0845, consonant: 0.0674\n",
      "[valid recall]total: 0.9788, grapheme: 0.9716, vowel: 0.9889, consonant: 0.9832\n",
      "================================================================================\n",
      "[EPOCH 00054]train_loss: 0.7418; val_loss: 0.0901; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1047, vowel: 0.0852, consonant: 0.0657\n",
      "[valid recall]total: 0.9794, grapheme: 0.9722, vowel: 0.9892, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00055]train_loss: 0.7073; val_loss: 0.0952; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1138, vowel: 0.0837, consonant: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid recall]total: 0.9792, grapheme: 0.9721, vowel: 0.9892, consonant: 0.9835\n",
      "================================================================================\n",
      "[EPOCH 00056]train_loss: 0.7408; val_loss: 0.0871; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1041, vowel: 0.0762, consonant: 0.0641\n",
      "[valid recall]total: 0.9795, grapheme: 0.9730, vowel: 0.9886, consonant: 0.9836\n",
      "================================================================================\n",
      "[EPOCH 00057]train_loss: 0.7289; val_loss: 0.0894; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1073, vowel: 0.0760, consonant: 0.0671\n",
      "[valid recall]total: 0.9794, grapheme: 0.9726, vowel: 0.9889, consonant: 0.9836\n",
      "================================================================================\n",
      "[EPOCH 00058]train_loss: 0.7278; val_loss: 0.0972; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1119, vowel: 0.0931, consonant: 0.0720\n",
      "[valid recall]total: 0.9792, grapheme: 0.9726, vowel: 0.9887, consonant: 0.9826\n",
      "================================================================================\n",
      "[EPOCH 00059]train_loss: 0.7172; val_loss: 0.0927; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1105, vowel: 0.0854, consonant: 0.0644\n",
      "[valid recall]total: 0.9797, grapheme: 0.9735, vowel: 0.9887, consonant: 0.9832\n",
      "================================================================================\n",
      "[EPOCH 00060]train_loss: 0.7112; val_loss: 0.1022; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1151, vowel: 0.1022, consonant: 0.0762\n",
      "[valid recall]total: 0.9790, grapheme: 0.9721, vowel: 0.9891, consonant: 0.9829\n",
      "================================================================================\n",
      "[EPOCH 00061]train_loss: 0.7243; val_loss: 0.1111; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.1238, vowel: 0.1148, consonant: 0.0821\n",
      "[valid recall]total: 0.9792, grapheme: 0.9722, vowel: 0.9887, consonant: 0.9836\n",
      "================================================================================\n",
      "[EPOCH 00062]train_loss: 0.7155; val_loss: 0.0836; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.1010, vowel: 0.0713, consonant: 0.0612\n",
      "[valid recall]total: 0.9802, grapheme: 0.9738, vowel: 0.9894, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00063]train_loss: 0.7188; val_loss: 0.0848; time elapsed: 9.7 min\n",
      "[valid loss]grapheme: 0.1036, vowel: 0.0726, consonant: 0.0592\n",
      "[valid recall]total: 0.9799, grapheme: 0.9731, vowel: 0.9895, consonant: 0.9838\n",
      "================================================================================\n",
      "[EPOCH 00064]train_loss: 0.6973; val_loss: 0.0805; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.0979, vowel: 0.0687, consonant: 0.0577\n",
      "[valid recall]total: 0.9801, grapheme: 0.9737, vowel: 0.9888, consonant: 0.9842\n",
      "================================================================================\n",
      "[EPOCH 00065]train_loss: 0.6895; val_loss: 0.0893; time elapsed: 9.5 min\n",
      "[valid loss]grapheme: 0.1059, vowel: 0.0796, consonant: 0.0657\n",
      "[valid recall]total: 0.9796, grapheme: 0.9725, vowel: 0.9893, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00066]train_loss: 0.7007; val_loss: 0.0795; time elapsed: 9.6 min\n",
      "[valid loss]grapheme: 0.0976, vowel: 0.0652, consonant: 0.0577\n",
      "[valid recall]total: 0.9802, grapheme: 0.9733, vowel: 0.9897, consonant: 0.9843\n",
      "================================================================================\n",
      "[EPOCH 00067]train_loss: 0.7095; val_loss: 0.0853; time elapsed: 9.3 min\n",
      "[valid loss]grapheme: 0.1014, vowel: 0.0745, consonant: 0.0640\n",
      "[valid recall]total: 0.9801, grapheme: 0.9735, vowel: 0.9893, consonant: 0.9839\n",
      "================================================================================\n",
      "[EPOCH 00068]train_loss: 0.7225; val_loss: 0.0827; time elapsed: 9.4 min\n",
      "[valid loss]grapheme: 0.0979, vowel: 0.0728, consonant: 0.0623\n",
      "[valid recall]total: 0.9800, grapheme: 0.9734, vowel: 0.9893, consonant: 0.9840\n",
      "================================================================================\n",
      "Early Stopping: val_metric does not increase 20 rounds\n"
     ]
    }
   ],
   "source": [
    "#### training for 5 folds here ####\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "    if fold in [1,2,3,4]:#train 1 fold for testing ideas\n",
    "        print('========training fold %d========'%fold)\n",
    "        print(train_idx)\n",
    "        print(valid_idx)\n",
    "        \n",
    "        checkpoint_path = '../checkpoint/v2-fold'+str(fold)\n",
    "        print('checkpoint_path: ', checkpoint_path)\n",
    "        \n",
    "        #1.1 data\n",
    "        train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "        train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "        #1.2 Dataset, DataLoader\n",
    "        train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "        val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "        \n",
    "        #2. model\n",
    "        #net = se_resnext50_32x4d(num_classes=num_classes, pretrained=None).cuda(device=device)\n",
    "        net = se_resnext50_32x4d(num_classes=num_classes, pretrained='imagenet').cuda(device=device)\n",
    "\n",
    "        #3. train session\n",
    "        train_and_valid(net, train_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold0: .982 ~70 epochs, LB=.9748\n",
    "#fold1: .9807 ~90 epochs, LB=.9745\n",
    "#fold2: .9840 ~90 epochs, LB=.9755\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 0\n",
    "# [     0      1      2 ... 200835 200837 200839]\n",
    "# [     4      6     12 ... 200832 200836 200838]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check dataset/network/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "#     if fold in [0]:#train 1 fold for testing ideas\n",
    "#         print('========training fold %d========'%fold)\n",
    "#         print(train_idx)\n",
    "#         print(valid_idx)\n",
    "        \n",
    "#         #1.1 data\n",
    "#         train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "#         train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "#         #1.2 Dataset, DataLoader\n",
    "#         train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "#         val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "\n",
    "# ####\n",
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if np.random.rand()<1.0:\n",
    "#         print('cutmix')\n",
    "#         inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "#     else:\n",
    "#         print('mixup')\n",
    "#         inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "#     if batch_id==1:\n",
    "#         break\n",
    "\n",
    "# #print(inputs.shape, truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_inputs = inputs.cpu().numpy()[np.random.choice(BATCH_SIZE, 20), :, :, :]\n",
    "# fig,axes = plt.subplots(5,4, figsize=(10,8))\n",
    "# for i in range(20):\n",
    "#     axes[i//4, i%4].imshow(show_inputs[i, 0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import senet_v2\n",
    "# importlib.reload(senet_v2)\n",
    "\n",
    "# import torch\n",
    "\n",
    "# from senet_v2 import se_resnext50_32x4d\n",
    "\n",
    "# net = se_resnext50_32x4d(num_classes=186, pretrained='imagenet', debug=True).cuda(device='cuda:2')\n",
    "\n",
    "# inputs = torch.rand((128, 1, 137, 236), dtype=torch.float).cuda(device='cuda:2')\n",
    "# print(inputs.size())\n",
    "\n",
    "# logit = net(inputs)\n",
    "# print(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
