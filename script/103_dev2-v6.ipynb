{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define environment\n",
    "ON_KAGGLE = False\n",
    "TRAIN_PREDICT = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.3.1+cu100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if ON_KAGGLE:\n",
    "    sys.path.append('../input/bengali-util/script/')\n",
    "    sys.path.append('../input/bengali-util/')\n",
    "    from script.utils import seed_everything, set_n_get_device\n",
    "else:\n",
    "    from utils import seed_everything, set_n_get_device\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "print('torch', torch.__version__)\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    #load utility scripts\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "debug = False\n",
    "SEED = 42\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 256\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    NUM_WORKERS = 2\n",
    "else:\n",
    "    NUM_WORKERS = 16\n",
    "\n",
    "device = set_n_get_device(\"2,3\", data_device_id=\"cuda:0\")#IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0,1]\n",
    "\n",
    "if debug:\n",
    "    LOG_PATH = '../logging/v6-debug.log'\n",
    "else:\n",
    "    LOG_PATH = '../logging/v6.log'\n",
    "\n",
    "checkpoint_path = '../checkpoint/v6'\n",
    "warm_start, last_checkpoint_path = False, '../checkpoint/v2/last.pth.tar'\n",
    "\n",
    "NUM_EPOCHS = 120\n",
    "early_stopping_round = 9999\n",
    "#LearningRate = 5e-3\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "n_grapheme=168\n",
    "n_vowel=11\n",
    "n_consonant=7\n",
    "#n_combo = 1295\n",
    "\n",
    "#num_classes = n_grapheme+n_vowel+n_consonant+n_combo\n",
    "num_classes = n_grapheme+n_vowel+n_consonant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "1. pytorch Dataset, data augmentation, DataLoader, train-test-split/KFold, \n",
    "2. network\n",
    "3. training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200840, 137, 236), (200840, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ON_KAGGLE:\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    train_df_list = [pd.read_feather('../data/processed/train_image_data_%d.feather'%i) for i in range(4)]\n",
    "    train_images_arr = np.concatenate([df.iloc[:, 1:].values.reshape(-1, IMG_HEIGHT, IMG_WIDTH) \n",
    "                                       for df in train_df_list], axis=0)\n",
    "    train_label_df = pd.read_csv('../data/raw/train.csv')\n",
    "    train_label_arr = train_label_df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "\n",
    "train_images_arr.shape, train_label_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import augmentation\n",
    "# importlib.reload(augmentation)\n",
    "# from augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##experiment a lot of augmentations\n",
    "# imgs = train_images_arr[np.random.choice(200840, 4), :]\n",
    "# imgs = np.clip((255-imgs)/255, 0, 1)\n",
    "\n",
    "# fig,axes = plt.subplots(4,2, figsize=(10,8))\n",
    "# for i in range(4):\n",
    "#     image = imgs[i]\n",
    "#     img_aug = do_random_shift_scale_crop_pad2(image, limit=0.2)\n",
    "#     axes[i, 0].imshow(image, cmap='binary')\n",
    "#     axes[i, 1].imshow(img_aug, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 1. encode grapheme characters to index 2. use it as sampler\n",
    "# unique_char = train_label_df['grapheme'].unique()\n",
    "# char2ind = dict([(char,i) for i,char in enumerate(unique_char)])\n",
    "# grapheme_ind = [char2ind[char] for char in train_label_df['grapheme']]\n",
    "# cls_w_dict = pd.value_counts(grapheme_ind)\n",
    "# cls_w_dict /= 100\n",
    "# cls_w_dict = cls_w_dict.to_dict()\n",
    "# cls_w = [cls_w_dict[i] for i in grapheme_ind]\n",
    "\n",
    "\n",
    "##check onehot correct?\n",
    "#train_label_df.loc[train_label_arr[:,3]==1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation --cutmix, mixup\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    #cut_rat = np.sqrt(1. - lam)\n",
    "    cut_rat = lam\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform, ignore edge area\n",
    "    cx = np.random.randint(W//4, W*3//4)\n",
    "    cy = np.random.randint(H//4, H*3//4)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    #print(bbx1, bby1, bbx2, bby2)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(data, target, alpha=1.0):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    #lam = np.random.beta(alpha, alpha)\n",
    "    lam = np.sqrt(np.random.rand()/4)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    #data[:, :, bbx1:bbx2, bby1:bby2] += data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    #data = torch.clamp(data, 0, 1)\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, \n",
    "               targets3, shuffled_targets3, lam]\n",
    "    return data, targets\n",
    "\n",
    "def mixup(data, target, alpha=0.4):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, \n",
    "               targets3, shuffled_targets3, lam]\n",
    "\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "#     if fold in [0]:#train 1 fold for testing ideas\n",
    "#         print('========training fold %d========'%fold)\n",
    "#         print(train_idx)\n",
    "#         print(valid_idx)\n",
    "        \n",
    "#         #1.1 data\n",
    "#         train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "#         train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "#         #1.2 Dataset, DataLoader\n",
    "#         train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "#         val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "\n",
    "# ####\n",
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if np.random.rand()<-10:\n",
    "#         inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "#     else:\n",
    "#         inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "#     if batch_id==1:\n",
    "#         break\n",
    "\n",
    "# #print(inputs.shape, truth.shape)\n",
    "\n",
    "# show_inputs = inputs.cpu().numpy()[np.random.choice(BATCH_SIZE, 20, replace=False), :, :, :]\n",
    "# fig,axes = plt.subplots(5,4, figsize=(10,8))\n",
    "# for i in range(20):\n",
    "#     axes[i//4, i%4].imshow(show_inputs[i, 0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##crop to 128x128\n",
    "# def bbox(img):\n",
    "#     rows = np.any(img, axis=1)\n",
    "#     cols = np.any(img, axis=0)\n",
    "#     rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "#     cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "#     return rmin, rmax, cmin, cmax\n",
    "\n",
    "# def crop_resize(img0, size=128, pad=16):\n",
    "#     #crop a box around pixels large than the threshold \n",
    "#     #some images contain line at the sides\n",
    "#     ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "#     #cropping may cut too much, so we need to add it back\n",
    "#     xmin = xmin - 13 if (xmin > 13) else 0\n",
    "#     ymin = ymin - 10 if (ymin > 10) else 0\n",
    "#     xmax = xmax + 13 if (xmax < IMG_WIDTH - 13) else IMG_WIDTH\n",
    "#     ymax = ymax + 10 if (ymax < IMG_HEIGHT - 10) else IMG_HEIGHT\n",
    "#     img = img0[ymin:ymax,xmin:xmax]\n",
    "#     #remove lo intensity pixels as noise\n",
    "#     img[img < 28] = 0\n",
    "#     lx, ly = xmax-xmin,ymax-ymin\n",
    "#     l = max(lx,ly) + pad\n",
    "#     #make sure that the aspect ratio is kept in rescaling\n",
    "#     img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "#     return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img0 = train_images_arr[0]\n",
    "#img0 = 255 - img0\n",
    "#img0 = (img0*(255.0/img0.max())).astype(np.uint8)\n",
    "#plt.imshow(crop_resize(rotate(img0, angle=20, reshape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### make up a weighted/balanced data sampler --for mixup/cutmix ####\n",
    "# #weights for 168 classes--graphene_root\n",
    "# import torch.utils.data\n",
    "# _weights = [6.8,6.9,3,3.1,3,5.7,3.2,6.5,6.4,2.3,6.6,6.6,6.8,0.2,1.3,0.9,1.1,1.3,0.6,3.6,3,1.1,0.3,0.2,3,0.9,5.8,3.3,1.3,0.4,2.3,1.3,0.9,7.4,3.6,2.1,1,3.5,0.3,1.6,1.3,3.3,0.5,0.3,0.9,6.9,1.7,2.2,0.7,3.1,1.4,3.1,1.1,0.3,1.7,0.6,0.4,1.6,0.8,0.4,2.3,1.7,1.2,6.7,0.2,0.7,1.3,2.1,1.6,1.3,1,0.3,0.2,7.7,0.7,0.9,0.5,1,3.4,0.3,2.2,0.3,3.4,0.7,2.2,0.7,0.5,6,1.3,0.4,1.6,0.6,0.9,1.6,1,1.4,0.2,2.1,1.6,2.2,2.2,0.9,7.1,0.3,6.2,6.6,1.3,0.2,6.3,1.1,2.9,1.3,1.1,0.2,6.7,0.2,2.3,0.7,0.9,0.7,0.8,2.2,0.4,0.5,0.5,1.2,6.3,1.1,1.1,1,6.9,2.3,1,0.2,1.6,1.6,1,1.8,1.1,0.4,1.1,0.6,0.9,1.6,1.6,3.2,3.3,0.2,0.6,0.4,0.4,0.8,1.6,0.6,1.4,1.1,1.3,3.1,7,0.3,2.1,3.2,2.2,6.1,6.1,0.9,3.3,0.6]\n",
    "# weights_dict = dict(zip(range(len(_weights)), _weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import set_logger, save_checkpoint, load_checkpoint\n",
    "import logging\n",
    "#import gc\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import cv2\n",
    "from augmentation import *\n",
    "\n",
    "\n",
    "def prepare_dataset(img_arr, label_arr, mode='train', debug=False):\n",
    "    \"\"\"\n",
    "    mode: 'train', 'valid', 'test'\n",
    "    \"\"\"\n",
    "    if debug:#for debug, sample 1/10 data\n",
    "        n = img_arr.shape[0]\n",
    "        sid = np.random.choice(n, size=n//5, replace=False)\n",
    "        img_arr = img_arr[sid]\n",
    "        label_arr = label_arr[sid]\n",
    "\n",
    "    if mode=='train':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "\n",
    "#     if mode=='train':\n",
    "#         ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "#         weights = [weights_dict[c] for c in label_arr[:,0]]\n",
    "#         sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=len(ds), replacement=True)\n",
    "#         dl = DataLoader(ds,\n",
    "#                         batch_size=BATCH_SIZE,\n",
    "#                         shuffle=False,\n",
    "#                         sampler=sampler,\n",
    "#                         num_workers=NUM_WORKERS,\n",
    "#                         drop_last=True\n",
    "#                        )\n",
    "#         return dl\n",
    "\n",
    "    elif mode=='valid':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "    elif mode=='test':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='test', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=False\n",
    "                       ) \n",
    "    return dl\n",
    "\n",
    "class DatasetV1(Dataset):\n",
    "    \"\"\"plain\"\"\"\n",
    "    def __init__(self, inputs, outputs, mode='train', augmentation=False):\n",
    "        \"\"\"\n",
    "        inputs: images, (N, H, W)\n",
    "        outputs: label, (N, 3)\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.mode = mode \n",
    "        self.augmentation = augmentation\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: augmentation, preprocessing\n",
    "        inputs, outputs = self.inputs[idx], self.outputs[idx]\n",
    "        inputs = np.clip((255-inputs)/255.0, 0, 1)\n",
    "\n",
    "#         inputs = cv2.resize(inputs, (224,224))\n",
    "#         inputs = np.clip(inputs, 0, 1)\n",
    "\n",
    "        #crop\n",
    "#         inputs = 255-inputs\n",
    "#         inputs = crop_resize(inputs)\n",
    "#         inputs = np.clip(inputs/255.0, 0, 1)\n",
    "\n",
    "        if self.augmentation:\n",
    "            inputs = self.do_augmentation(inputs)\n",
    "        \n",
    "        inputs = np.expand_dims(inputs, 0)#(224,224)-->(1,224,224)\n",
    "        inputs = inputs.astype(np.float32)\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "    \n",
    "    def do_augmentation(self, image):\n",
    "        #rotate\n",
    "        #if np.random.rand() < 0.5:\n",
    "        #angle = np.random.randint(0, 40) - 20\n",
    "        #inputs = rotate(inputs, angle, reshape=False)\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_projective(image, 0.4),#0.4\n",
    "            lambda image : do_random_perspective(image, 0.4),#0.4\n",
    "            lambda image : do_random_scale(image, 0.4),#0.4\n",
    "            lambda image : do_random_rotate(image, 0.4),#0.4\n",
    "            lambda image : do_random_shear_x(image, 0.5),#0.5\n",
    "            lambda image : do_random_shear_y(image, 0.4),#0.4\n",
    "            lambda image : do_random_stretch_x(image, 0.5),#0.5\n",
    "            lambda image : do_random_stretch_y(image, 0.5),#0.5\n",
    "            lambda image : do_random_grid_distortion(image, 0.4),#0.4\n",
    "            lambda image : do_random_custom_distortion1(image, 0.5),#0.5\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_erode(image, 0.4),#0.4\n",
    "            lambda image : do_random_dilate(image, 0.4),#0.4\n",
    "            lambda image : do_random_sprinkle(image, 0.5),#0.5\n",
    "            #lambda image : do_random_line(image, 0.2),\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "\n",
    "        for op in np.random.choice([\n",
    "            lambda image : do_identity(image),\n",
    "            lambda image : do_random_contast(image, 0.5),#0.5\n",
    "            lambda image : do_random_block_fade(image, 0.5),#0.5\n",
    "        ],1):\n",
    "            image = op(image)\n",
    "        \n",
    "#         if np.random.rand()<1.1:\n",
    "#             image = do_random_shift_scale_crop_pad2(image, limit=0.1)\n",
    "#         else:\n",
    "#             image = do_shift_scale_rotate2(image, angle=np.random.uniform(0, 10))\n",
    "        return image\n",
    "\n",
    "def train_and_valid(net, train_dl, val_dl=None):\n",
    "    \"\"\"train one fold\n",
    "    \n",
    "    [settings]...\n",
    "    \n",
    "    [Epoch i]\n",
    "        [Trainset]\n",
    "            [Batch j]\n",
    "        [Validset]\n",
    "            [Batch k]\n",
    "        [Logging/Checkpoint]\n",
    "    \"\"\"\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #1. optim\n",
    "    train_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "#     optimizer = torch.optim.Adam(train_params, lr=LearningRate)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "#                                                           factor=0.5, patience=5, \n",
    "#                                                           verbose=False, threshold=0.0001, \n",
    "#                                                           threshold_mode='rel', cooldown=0, \n",
    "#                                                           min_lr=0, eps=1e-08)\n",
    "    optimizer = torch.optim.Adam(train_params)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-3, \n",
    "                                                    steps_per_epoch=len(train_dl),#1255 \n",
    "                                                    epochs=NUM_EPOCHS)\n",
    "\n",
    "    #1.1 warm-start\n",
    "    if warm_start:\n",
    "        logging.info('warm_start: '+last_checkpoint_path)\n",
    "        net, _ = load_checkpoint(last_checkpoint_path, net)\n",
    "    \n",
    "    #2. using multi GPU\n",
    "    if multi_gpu is not None:\n",
    "        net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "    #3. train\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i_epoch in range(NUM_EPOCHS):\n",
    "        t0 = time.time()\n",
    "        print('lr: ', scheduler.get_lr())\n",
    "        ## trainset -------------------------------------------------------------\n",
    "        net.train()\n",
    "        loss_logger = LossLogger()\n",
    "        for batch_id, (images, labels) in enumerate(train_dl):\n",
    "            inputs = images.to(device=device, dtype=torch.float)\n",
    "            truth = labels.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            #do cutmix/mixup\n",
    "            if i_epoch<-1:#5\n",
    "                mode = 0\n",
    "                do_nothing = True\n",
    "            else:\n",
    "                mode = 1\n",
    "                if np.random.rand()<0.5:\n",
    "                    inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "                else:\n",
    "                    inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "            \n",
    "            logit = net(inputs)\n",
    "            logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "            train_loss = loss_logger.update(logits, truth, mode=mode)\n",
    "            #grandient accumulation step=2\n",
    "            acc_step = 1\n",
    "            if acc_step>1:\n",
    "                train_loss = train_loss / acc_step\n",
    "            train_loss.backward()\n",
    "            if (batch_id+1)%acc_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            ##lr scheduler\n",
    "            scheduler.step()\n",
    "        ##aggregate loss\n",
    "        train_loss_total, _, _, _ = loss_logger.aggregate()\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i_epoch,\n",
    "            'state_dict': net.module.state_dict() if multi_gpu is not None else net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            'metrics': {'train_loss': train_loss_total}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=False, checkpoint=checkpoint_path)\n",
    "        \n",
    "        #logging loss/metric\n",
    "        logging.info('[EPOCH %05d]train_loss: %0.4f; time elapsed: %0.1f min'%(i_epoch, \n",
    "                    train_loss_total, (time.time()-t0)/60))\n",
    "        logging.info('='*80)\n",
    "\n",
    "def predict(test_dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# print(torch.__version__)\n",
    "\n",
    "# NUM_EPOCHS=120\n",
    "\n",
    "# model = torchvision.models.resnet18(pretrained=False)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-3, \n",
    "#                                                 steps_per_epoch=1255, epochs=NUM_EPOCHS)#steps_per_epoch=len(dl)\n",
    "\n",
    "# l = []\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     for i,batch in enumerate(range(1255)):\n",
    "#         l.append(scheduler.get_lr())\n",
    "#         #train_batch(...)\n",
    "#         scheduler.step()\n",
    "\n",
    "# l[0::1255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class LossLogger(object):\n",
    "    \"\"\"loss for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        loss_logger = LossLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            loss = loss_logger.update(logits, truth)\n",
    "            loss.backward()\n",
    "        \n",
    "        loss, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss_grapheme = []\n",
    "        self.loss_vowel = []\n",
    "        self.loss_consonant = []\n",
    "\n",
    "    def update(self, logits, truth, mode=0):\n",
    "        \"\"\"\n",
    "        logits: logit splitted to [logit_grapheme, logit_vowel, logit_consonant]\n",
    "        truth: shape (N, 3)\n",
    "        \"\"\"\n",
    "        if mode==0:\n",
    "            #loss\n",
    "            loss_grapheme = F.cross_entropy(logits[0], truth[:,0].long())\n",
    "            loss_vowel = F.cross_entropy(logits[1], truth[:,1].long())\n",
    "            loss_consonant = F.cross_entropy(logits[2], truth[:,2].long())\n",
    "            loss = 0.5*loss_grapheme + 0.25*loss_vowel + 0.25*loss_consonant\n",
    "            #\n",
    "            self.loss_grapheme.append(loss_grapheme.item())\n",
    "            self.loss_vowel.append(loss_vowel.item())\n",
    "            self.loss_consonant.append(loss_consonant.item())\n",
    "            return loss\n",
    "        elif mode==1:#cutmix/mixup loss\n",
    "            truth1, truth2, truth3, truth4, truth5, truth6, lam = \\\n",
    "                    truth[0], truth[1], truth[2], truth[3], truth[4], truth[5], truth[6]\n",
    "            criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "            loss_grapheme = lam * criterion(logits[0], truth1.long()) + \\\n",
    "                (1 - lam) * criterion(logits[0], truth2.long())\n",
    "            loss_vowel = lam * criterion(logits[1], truth3.long()) + \\\n",
    "                (1 - lam) * criterion(logits[1], truth4.long())\n",
    "            loss_consonant = lam * criterion(logits[2], truth5.long()) + \\\n",
    "                (1 - lam) * criterion(logits[2], truth6.long())\n",
    "            loss = 0.5*loss_grapheme + 0.25*loss_vowel + 0.25*loss_consonant\n",
    "            #\n",
    "            self.loss_grapheme.append(loss_grapheme.item())\n",
    "            self.loss_vowel.append(loss_vowel.item())\n",
    "            self.loss_consonant.append(loss_consonant.item())\n",
    "            return loss\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\"\n",
    "        for print logging\n",
    "        \"\"\"\n",
    "        loss_grapheme = np.mean(self.loss_grapheme)\n",
    "        loss_vowel = np.mean(self.loss_vowel)\n",
    "        loss_consonant = np.mean(self.loss_consonant)\n",
    "        loss_total = np.mean(\n",
    "            0.5*np.array(self.loss_grapheme) + \\\n",
    "            0.25*np.array(self.loss_vowel) + \\\n",
    "            0.25*np.array(self.loss_consonant)\n",
    "        )\n",
    "        return loss_total, loss_grapheme, loss_vowel, loss_consonant\n",
    "\n",
    "class MetricLogger(object):\n",
    "    \"\"\"recall, precision for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        metric_logger = MetricLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            metric_logger.update(logits, truth)\n",
    "        \n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pred_grapheme = torch.tensor([], dtype=torch.long).cuda(device)\n",
    "        self.pred_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.pred_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        \n",
    "        self.truth_grapheme = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "\n",
    "    def update(self, logits, truth):\n",
    "        pred = torch.argmax(logits[0], dim=1)\n",
    "        self.pred_grapheme = torch.cat([self.pred_grapheme, pred])\n",
    "        self.truth_grapheme = torch.cat([self.truth_grapheme, truth[:, 0].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[1], dim=1)\n",
    "        self.pred_vowel = torch.cat([self.pred_vowel, pred])\n",
    "        self.truth_vowel = torch.cat([self.truth_vowel, truth[:, 1].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[2], dim=1)\n",
    "        self.pred_consonant = torch.cat([self.pred_consonant, pred])\n",
    "        self.truth_consonant = torch.cat([self.truth_consonant, truth[:, 2].long()])\n",
    "\n",
    "    def aggregate(self):\n",
    "        rec_grapheme = recall_score(self.truth_grapheme.cpu().numpy(), \n",
    "                                    self.pred_grapheme.cpu().numpy(), \n",
    "                                    average='macro')\n",
    "        rec_vowel = recall_score(self.truth_vowel.cpu().numpy(), \n",
    "                                 self.pred_vowel.cpu().numpy(), \n",
    "                                 average='macro')\n",
    "        rec_consonant = recall_score(self.truth_consonant.cpu().numpy(), \n",
    "                                     self.pred_consonant.cpu().numpy(), \n",
    "                                     average='macro')\n",
    "        #rec = (2*rec_grapheme + 1*rec_vowel + 1*rec_consonant) / 4\n",
    "        rec = np.average([rec_grapheme, rec_vowel, rec_consonant], weights=[2,1,1])\n",
    "        return rec, rec_grapheme, rec_vowel, rec_consonant\n",
    "\n",
    "# #debug MetricLogger\n",
    "# #Epoch 0\n",
    "# loss_logger = LossLogger()\n",
    "# metric_logger = MetricLogger()\n",
    "# for batch_id, (images, labels) in enumerate(val_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if batch_id==10:\n",
    "#         break\n",
    "#     logit = net(inputs)\n",
    "#     logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "#     loss = loss_logger.update(logits, truth)\n",
    "#     metric_logger.update(logits, truth)\n",
    "# rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "# loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "# print(rec, rec_grapheme, rec_vowel, rec_consonant)\n",
    "# print(loss_total, loss_grapheme, loss_vowel, loss_consonant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from senet import se_resnext50_32x4d\n",
    "# from senet_v2 import se_resnext50_32x4d\n",
    "from efficientnet import EffiNet\n",
    "# from densenet import DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00019999999999999966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00000]train_loss: 2.5384; time elapsed: 11.8 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00020913304775700085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00001]train_loss: 1.6836; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00023646268056022861]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00002]train_loss: 1.4261; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0002817808960417041]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00003]train_loss: 1.3214; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00034474278301288314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00004]train_loss: 1.2286; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00042486914653994904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00005]train_loss: 1.1486; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.000521550155035664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00006]train_loss: 1.1264; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0006340499816102048]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00007]train_loss: 1.0875; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0007615124043562705]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00008]train_loss: 1.0669; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0009029673229453946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00009]train_loss: 1.0486; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0010573381419384607]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00010]train_loss: 1.0243; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0012234499646170114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00012]train_loss: 0.9905; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0015857598598014123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00013]train_loss: 1.0065; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0017792004376609694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00014]train_loss: 0.9858; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001978888016855332]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00015]train_loss: 0.9836; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00218330280055345]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00016]train_loss: 0.9751; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0023908890137705305]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00017]train_loss: 0.9679; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002600066744174066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00018]train_loss: 0.9560; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002809243966596161]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00019]train_loss: 0.9482; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003016828659735101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00020]train_loss: 0.9382; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0032212409228275004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00021]train_loss: 0.9437; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0034209250000725774]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00022]train_loss: 0.9303; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0036143611212921716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00023]train_loss: 0.9388; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0038000770687087607]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00024]train_loss: 0.9203; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003976659381808183]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00025]train_loss: 0.9251; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004142764115008292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00026]train_loss: 0.9016; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0042971270662582675]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00027]train_loss: 0.8867; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004438573398720047]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00028]train_loss: 0.9126; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004566026582302441]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00029]train_loss: 0.8978; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004678516586995082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00030]train_loss: 0.8873; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004775187265643769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00031]train_loss: 0.8926; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004855302869977835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00032]train_loss: 0.8905; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0049182536502968945]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00033]train_loss: 0.8694; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004963560496198449]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00034]train_loss: 0.8807; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004990878583026386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00035]train_loss: 0.8519; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004999999999289763]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00036]train_loss: 0.8708; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00499824954004866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00037]train_loss: 0.8915; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004993005066911978]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00038]train_loss: 0.8659; time elapsed: 12.6 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004984273914749621]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00039]train_loss: 0.8427; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004972068294867387]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00040]train_loss: 0.8439; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004956405277928351]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00041]train_loss: 0.8309; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004937306770078005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00042]train_loss: 0.8298; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004914799482306524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00043]train_loss: 0.8094; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004888914893091039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00044]train_loss: 0.8197; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004859689204370133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00045]train_loss: 0.7946; time elapsed: 12.6 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004827163290912164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00046]train_loss: 0.8175; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004791382643148201]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00047]train_loss: 0.8216; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004752397303549541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00048]train_loss: 0.8099; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0047102617966387934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00049]train_loss: 0.7915; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0046650350527324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00050]train_loss: 0.7863; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004616780325521259]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00051]train_loss: 0.7771; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004565565103604726]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00052]train_loss: 0.7613; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0045114610161016925]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00053]train_loss: 0.7526; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004454543732470798]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00054]train_loss: 0.7727; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004394892856679843]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00055]train_loss: 0.7720; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004332591815872443]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00056]train_loss: 0.7665; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004267727743687629]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00057]train_loss: 0.7492; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004200391358395567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00058]train_loss: 0.7430; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004130676836019861]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00059]train_loss: 0.7570; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.004058681678623863]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00060]train_loss: 0.7515; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0039845065779452234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00061]train_loss: 0.7198; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003908255274569393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00062]train_loss: 0.7268; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003830034412839028]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00063]train_loss: 0.7231; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0037499533917022413]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00064]train_loss: 0.7272; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0036681242117082738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00065]train_loss: 0.6982; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003584661318364603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00066]train_loss: 0.7044; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0034996814420745546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00067]train_loss: 0.7095; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00341330343487927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00068]train_loss: 0.6946; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0033256481042323906]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00069]train_loss: 0.6851; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0032368380440398995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00070]train_loss: 0.6763; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0031469974632014662]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00071]train_loss: 0.6792; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.003056252011893068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00072]train_loss: 0.6910; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002964728605833853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00073]train_loss: 0.6694; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0028725552487830347]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00074]train_loss: 0.6782; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0027798608535150576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00075]train_loss: 0.6720; time elapsed: 12.1 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00268677506152343]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00076]train_loss: 0.6621; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0025934280617053674]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00077]train_loss: 0.6567; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0024999504082808483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00078]train_loss: 0.6626; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002406472838200738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00079]train_loss: 0.6376; time elapsed: 12.6 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0023131260882993327]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00080]train_loss: 0.6410; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0022200407124470835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00081]train_loss: 0.6617; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0021273468989591957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00082]train_loss: 0.6460; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.002035174288515506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00083]train_loss: 0.6483; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0019436517928462613]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00084]train_loss: 0.6409; time elapsed: 12.4 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001852907414437411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00085]train_loss: 0.6345; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0017630680675075588]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00086]train_loss: 0.6273; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001674259400506947]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00087]train_loss: 0.6337; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0015866056203867405]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00088]train_loss: 0.6225; time elapsed: 12.6 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0015002293188843727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00089]train_loss: 0.6176; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.001415251301067916]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00090]train_loss: 0.6281; time elapsed: 12.5 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0013317904163792729]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00091]train_loss: 0.6074; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0012499633924124788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00092]train_loss: 0.6089; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0011698846716596137]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00093]train_loss: 0.6229; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0010916662514526263]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00094]train_loss: 0.6045; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0010154175273249329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00095]train_loss: 0.6191; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0009412451400118835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00096]train_loss: 0.6092; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.000869252826304039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00097]train_loss: 0.6061; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0007995412739618939]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00098]train_loss: 0.5966; time elapsed: 12.1 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0007322079808949421]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00099]train_loss: 0.5917; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0006673471188020302]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00100]train_loss: 0.6076; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0006050494014637203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00101]train_loss: 0.5982; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0005454019578708701]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00102]train_loss: 0.6080; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.000488488210366857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00103]train_loss: 0.5983; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0004343877579738894]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00104]train_loss: 0.5953; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0003831762650665738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00105]train_loss: 0.5988; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.000334925355548449]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00106]train_loss: 0.5824; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0002897025126794784]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00107]train_loss: 0.5982; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0002475709846946072]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00108]train_loss: 0.5702; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00020858969634539068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00109]train_loss: 0.5811; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0001728131664883987]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00110]train_loss: 0.5920; time elapsed: 12.1 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.0001402914318356637]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00111]train_loss: 0.6010; time elapsed: 12.1 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [0.00011106997697381788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00112]train_loss: 0.5857; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [8.518967074978217e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00113]train_loss: 0.5801; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [6.268670911199134e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00114]train_loss: 0.5805; time elapsed: 12.3 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [4.359256448708619e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00115]train_loss: 0.5780; time elapsed: 12.0 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [2.7933941762877692e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00116]train_loss: 0.5942; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [1.5732740939149334e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00117]train_loss: 0.5832; time elapsed: 12.1 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [7.006026498523869e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00118]train_loss: 0.5912; time elapsed: 12.1 min\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  [1.766003540244315e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EPOCH 00119]train_loss: 0.5819; time elapsed: 12.2 min\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#### training full data ####\n",
    "#1.1 data\n",
    "train_inputs, train_outputs = train_images_arr, train_label_arr\n",
    "\n",
    "#1.2 Dataset, DataLoader\n",
    "train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "\n",
    "#2. model\n",
    "#net = se_resnext50_32x4d(num_classes=num_classes, pretrained=None).cuda(device=device)\n",
    "#net = se_resnext50_32x4d(num_classes=num_classes, pretrained='imagenet').cuda(device=device)\n",
    "net = EffiNet(model='b4').cuda(device=device)\n",
    "#net = DenseNet().cuda(device=device)\n",
    "\n",
    "#3. train session\n",
    "train_and_valid(net, train_dl, val_dl=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold0 - val_loss: 0.0733; CV: 0.9824, LB=0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 0\n",
    "# [     0      1      2 ... 200835 200837 200839]\n",
    "# [     4      6     12 ... 200832 200836 200838]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check dataset/network/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "#     if fold in [0]:#train 1 fold for testing ideas\n",
    "#         print('========training fold %d========'%fold)\n",
    "#         print(train_idx)\n",
    "#         print(valid_idx)\n",
    "        \n",
    "#         #1.1 data\n",
    "#         train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "#         train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "#         #1.2 Dataset, DataLoader\n",
    "#         train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "#         val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "\n",
    "# ####\n",
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if np.random.rand()<1.0:\n",
    "#         print('cutmix')\n",
    "#         inputs, truth = cutmix(inputs, truth, alpha=None)\n",
    "#     else:\n",
    "#         print('mixup')\n",
    "#         inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "#     if batch_id==1:\n",
    "#         break\n",
    "\n",
    "# #print(inputs.shape, truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_inputs = inputs.cpu().numpy()[np.random.choice(BATCH_SIZE, 20), :, :, :]\n",
    "# fig,axes = plt.subplots(5,4, figsize=(10,8))\n",
    "# for i in range(20):\n",
    "#     axes[i//4, i%4].imshow(show_inputs[i, 0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import efficientnet\n",
    "# importlib.reload(efficientnet)\n",
    "\n",
    "# import torch\n",
    "\n",
    "# #from senet_v2 import se_resnext50_32x4d\n",
    "# from efficientnet import EffiNet\n",
    "\n",
    "# #net = se_resnext50_32x4d(num_classes=186, pretrained='imagenet', debug=True).cuda(device='cuda:2')\n",
    "# net = EffiNet(model='b3', debug=True).cuda(device='cuda:3')\n",
    "\n",
    "# inputs = torch.rand((128, 1, 137, 236), dtype=torch.float).cuda(device='cuda:3')\n",
    "# print(inputs.size())\n",
    "\n",
    "# logit = net(inputs)\n",
    "# print(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
