{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define environment\n",
    "ON_KAGGLE = False\n",
    "TRAIN_PREDICT = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# if not ON_KAGGLE:\n",
    "#     sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "print('torch', torch.__version__)\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from utils import seed_everything, set_n_get_device\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_KAGGLE:\n",
    "    #load utility scripts\n",
    "    pass\n",
    "\n",
    "else:#offline\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "debug = False\n",
    "SEED = 42\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "\n",
    "if TRAIN_PREDICT=='train':\n",
    "    BATCH_SIZE = 128\n",
    "else:\n",
    "    BATCH_SIZE = 256\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    NUM_WORKERS = 2\n",
    "else:\n",
    "    NUM_WORKERS = 16\n",
    "\n",
    "device = set_n_get_device(\"2,3\", data_device_id=\"cuda:0\")#IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0,1]\n",
    "\n",
    "checkpoint_path = '../checkpoint/v1'\n",
    "LOG_PATH = '../logging/v1.log'\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "early_stopping_round = 10\n",
    "LearningRate = 0.005#0.01\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "n_grapheme=168\n",
    "n_vowel=11\n",
    "n_consonant=7\n",
    "\n",
    "num_classes = n_grapheme+n_vowel+n_consonant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "1. pytorch Dataset, data augmentation, DataLoader, train-test-split/KFold, \n",
    "2. network\n",
    "3. training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200840, 137, 236), (200840, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ON_KAGGLE:\n",
    "    pass\n",
    "else:#offline\n",
    "    train_df_list = [pd.read_feather('../data/processed/train_image_data_%d.feather'%i) for i in range(4)]\n",
    "    train_images_arr = np.concatenate([df.iloc[:, 1:].values.reshape(-1, IMG_HEIGHT, IMG_WIDTH) \n",
    "                                       for df in train_df_list], axis=0)\n",
    "    train_label_df = pd.read_csv('../data/raw/train.csv')\n",
    "    train_label_arr = train_label_df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "\n",
    "train_images_arr.shape, train_label_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data augmentation --cutmix, mixup\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(data, target, alpha=1.0):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
    "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
    "\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
    "    return data, targets\n",
    "\n",
    "def mixup(data, target, alpha=0.4):\n",
    "    targets1, targets2, targets3 = target[:,0], target[:,1], target[:,2]\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets1 = targets1[indices]\n",
    "    shuffled_targets2 = targets2[indices]\n",
    "    shuffled_targets3 = targets3[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    data = data * lam + shuffled_data * (1 - lam)\n",
    "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
    "\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### make up a weighted/balanced data sampler --for mixup/cutmix ####\n",
    "#weights for 168 classes--graphene_root\n",
    "import torch.utils.data\n",
    "_weights = [6.8,6.9,3,3.1,3,5.7,3.2,6.5,6.4,2.3,6.6,6.6,6.8,0.2,1.3,0.9,1.1,1.3,0.6,3.6,3,1.1,0.3,0.2,3,0.9,5.8,3.3,1.3,0.4,2.3,1.3,0.9,7.4,3.6,2.1,1,3.5,0.3,1.6,1.3,3.3,0.5,0.3,0.9,6.9,1.7,2.2,0.7,3.1,1.4,3.1,1.1,0.3,1.7,0.6,0.4,1.6,0.8,0.4,2.3,1.7,1.2,6.7,0.2,0.7,1.3,2.1,1.6,1.3,1,0.3,0.2,7.7,0.7,0.9,0.5,1,3.4,0.3,2.2,0.3,3.4,0.7,2.2,0.7,0.5,6,1.3,0.4,1.6,0.6,0.9,1.6,1,1.4,0.2,2.1,1.6,2.2,2.2,0.9,7.1,0.3,6.2,6.6,1.3,0.2,6.3,1.1,2.9,1.3,1.1,0.2,6.7,0.2,2.3,0.7,0.9,0.7,0.8,2.2,0.4,0.5,0.5,1.2,6.3,1.1,1.1,1,6.9,2.3,1,0.2,1.6,1.6,1,1.8,1.1,0.4,1.1,0.6,0.9,1.6,1.6,3.2,3.3,0.2,0.6,0.4,0.4,0.8,1.6,0.6,1.4,1.1,1.3,3.1,7,0.3,2.1,3.2,2.2,6.1,6.1,0.9,3.3,0.6]\n",
    "weights_dict = dict(zip(range(len(_weights)), _weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import set_logger, save_checkpoint, load_checkpoint\n",
    "import logging\n",
    "#import gc\n",
    "\n",
    "def prepare_dataset(img_arr, label_arr, mode='train', debug=False):\n",
    "    \"\"\"\n",
    "    mode: 'train', 'valid', 'test'\n",
    "    \"\"\"\n",
    "    if debug:#for debug, sample 1/10 data\n",
    "        n = img_arr.shape[0]\n",
    "        sid = np.random.choice(n, size=n//5, replace=False)\n",
    "        img_arr = img_arr[sid]\n",
    "        label_arr = label_arr[sid]\n",
    "\n",
    "#     if mode=='train':\n",
    "#         ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "#         dl = DataLoader(ds,\n",
    "#                         batch_size=BATCH_SIZE,\n",
    "#                         shuffle=True,\n",
    "#                         #sampler=sampler,\n",
    "#                         num_workers=NUM_WORKERS,\n",
    "#                         drop_last=True\n",
    "#                        )\n",
    "\n",
    "    if mode=='train':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=True)\n",
    "        weights = [weights_dict[c] for c in label_arr[:,0]]\n",
    "        sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=len(ds), replacement=True)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "        return dl\n",
    "\n",
    "    elif mode=='valid':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='train', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=True\n",
    "                       )\n",
    "    elif mode=='test':\n",
    "        ds = DatasetV1(img_arr, label_arr, mode='test', augmentation=False)\n",
    "        dl = DataLoader(ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        #sampler=sampler,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        drop_last=False\n",
    "                       ) \n",
    "    return dl\n",
    "\n",
    "class DatasetV1(Dataset):\n",
    "    \"\"\"plain\"\"\"\n",
    "    def __init__(self, inputs, outputs, mode='train', augmentation=False):\n",
    "        \"\"\"\n",
    "        inputs: images, (N, H, W)\n",
    "        outputs: label, (N, 3)\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.mode = mode \n",
    "        self.augmentation = augmentation\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: augmentation, preprocessing\n",
    "        inputs, outputs = self.inputs[idx], self.outputs[idx]\n",
    "        inputs = np.expand_dims(inputs, 0)#(224,224)-->(1,224,224)\n",
    "        return inputs, outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "\n",
    "def train_and_valid(net, train_dl, val_dl):\n",
    "    \"\"\"train one fold\n",
    "    \n",
    "    [settings]...\n",
    "    \n",
    "    [Epoch i]\n",
    "        [Trainset]\n",
    "            [Batch j]\n",
    "        [Validset]\n",
    "            [Batch k]\n",
    "        [Logging/Checkpoint]\n",
    "    \"\"\"\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #1. optim\n",
    "    train_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    optimizer = torch.optim.Adam(train_params, lr=LearningRate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                          factor=0.5, patience=6, \n",
    "                                                          verbose=False, threshold=0.0001, \n",
    "                                                          threshold_mode='rel', cooldown=0, \n",
    "                                                          min_lr=0, eps=1e-08)\n",
    "    #2. using multi GPU\n",
    "    if multi_gpu is not None:\n",
    "        net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "    #3. train\n",
    "    diff = 0\n",
    "    best_val_metric = -0.1\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i_epoch in range(NUM_EPOCHS):\n",
    "        t0 = time.time()\n",
    "        ## trainset -------------------------------------------------------------\n",
    "        net.train()\n",
    "        loss_logger = LossLogger()\n",
    "        for batch_id, (images, labels) in enumerate(train_dl):\n",
    "            inputs = images.to(device=device, dtype=torch.float)\n",
    "            truth = labels.to(device=device, dtype=torch.float)\n",
    "            \n",
    "            #do cutmix/mixup\n",
    "            if i_epoch<-1:#5\n",
    "                mode = 0\n",
    "                do_nothing = True\n",
    "            else:\n",
    "                mode = 1\n",
    "                if np.random.rand()<0.5:\n",
    "                    inputs, truth = cutmix(inputs, truth, alpha=1.0)\n",
    "                else:\n",
    "                    inputs, truth = mixup(inputs, truth, alpha=0.4)\n",
    "            \n",
    "            logit = net(inputs)\n",
    "            logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "            train_loss = loss_logger.update(logits, truth, mode=mode)\n",
    "            #grandient accumulation step=2\n",
    "            acc_step = 1\n",
    "            if acc_step>1:\n",
    "                train_loss = train_loss / acc_step\n",
    "            train_loss.backward()\n",
    "            if (batch_id+1)%acc_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        train_loss_total, _, _, _ = loss_logger.aggregate()\n",
    "        \n",
    "#         ##check for memory leakage\n",
    "#         for obj in gc.get_objects():\n",
    "#             try:\n",
    "#                 if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#                     print(type(obj), obj.size())\n",
    "#             except:\n",
    "#                 pass\n",
    "        ## validset -------------------------------------------------------------\n",
    "        net.eval()\n",
    "        loss_logger = LossLogger()\n",
    "        metric_logger = MetricLogger()\n",
    "        with torch.no_grad():\n",
    "            for batch_id, (images, labels) in enumerate(val_dl):\n",
    "                inputs = images.to(device=device, dtype=torch.float)\n",
    "                truth = labels.to(device=device, dtype=torch.float)\n",
    "                logit = net(inputs)\n",
    "                logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "                _ = loss_logger.update(logits, truth, mode=0)\n",
    "                metric_logger.update(logits, truth)\n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "        loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "        \n",
    "        ## callbacks -------------------------------------------------------------\n",
    "        val_metric = rec\n",
    "        scheduler.step(val_metric)\n",
    "        \n",
    "        #sometimes too early stop, force to at least train N epochs\n",
    "        if i_epoch>=-1:#50\n",
    "            if val_metric > best_val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                is_best = True\n",
    "                diff = 0\n",
    "            else:\n",
    "                is_best = False\n",
    "                diff += 1\n",
    "                if diff > early_stopping_round:\n",
    "                    logging.info('Early Stopping: val_metric does not increase %d rounds'%early_stopping_round)\n",
    "                    break\n",
    "        else:\n",
    "            is_best = False\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i_epoch,\n",
    "            'state_dict': net.module.state_dict() if multi_gpu is not None else net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            'metrics': {'train_loss': train_loss_total, 'val_loss': loss_total, \n",
    "                        'val_metric': val_metric}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=is_best, checkpoint=checkpoint_path)\n",
    "        \n",
    "        #logging loss/metric\n",
    "        logging.info('[EPOCH %05d]train_loss: %0.4f; val_loss: %0.4f; time elapsed: %0.1f min'%(i_epoch, \n",
    "                    train_loss_total, loss_total, (time.time()-t0)/60))\n",
    "        logging.info('[valid loss]grapheme: %0.4f, vowel: %0.4f, consonant: %0.4f'%(loss_grapheme, \n",
    "                                                                                    loss_vowel, loss_consonant))\n",
    "        logging.info('[valid recall]total: %0.4f, grapheme: %0.4f, vowel: %0.4f, consonant: %0.4f'%(rec, \n",
    "                    rec_grapheme, rec_vowel, rec_consonant))\n",
    "        logging.info('='*80)\n",
    "\n",
    "def predict(test_dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class LossLogger(object):\n",
    "    \"\"\"loss for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        loss_logger = LossLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            loss = loss_logger.update(logits, truth)\n",
    "            loss.backward()\n",
    "        \n",
    "        loss, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss_grapheme = []\n",
    "        self.loss_vowel = []\n",
    "        self.loss_consonant = []\n",
    "\n",
    "    def update(self, logits, truth, mode=0):\n",
    "        \"\"\"\n",
    "        logits: logit splitted to [logit_grapheme, logit_vowel, logit_consonant]\n",
    "        truth: shape (N, 3)\n",
    "        \"\"\"\n",
    "        if mode==0:\n",
    "            #loss\n",
    "            loss_grapheme = F.cross_entropy(logits[0], truth[:,0].long())\n",
    "            loss_vowel = F.cross_entropy(logits[1], truth[:,1].long())\n",
    "            loss_consonant = F.cross_entropy(logits[2], truth[:,2].long())\n",
    "            loss = (loss_grapheme + loss_vowel + loss_consonant)/3\n",
    "            #\n",
    "            self.loss_grapheme.append(loss_grapheme.item())\n",
    "            self.loss_vowel.append(loss_vowel.item())\n",
    "            self.loss_consonant.append(loss_consonant.item())\n",
    "            return loss\n",
    "        elif mode==1:#cutmix/mixup loss\n",
    "            truth1, truth2, truth3, truth4, truth5, truth6, lam = \\\n",
    "                    truth[0], truth[1], truth[2], truth[3], truth[4], truth[5], truth[6]\n",
    "            criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "            loss_grapheme = lam * criterion(logits[0], truth1.long()) + \\\n",
    "                (1 - lam) * criterion(logits[0], truth2.long())\n",
    "            loss_vowel = lam * criterion(logits[1], truth3.long()) + \\\n",
    "                (1 - lam) * criterion(logits[1], truth4.long())\n",
    "            loss_consonant = lam * criterion(logits[2], truth5.long()) + \\\n",
    "                (1 - lam) * criterion(logits[2], truth6.long())\n",
    "            loss = (loss_grapheme + loss_vowel + loss_consonant)/3\n",
    "            #\n",
    "            self.loss_grapheme.append(loss_grapheme.item())\n",
    "            self.loss_vowel.append(loss_vowel.item())\n",
    "            self.loss_consonant.append(loss_consonant.item())\n",
    "            return loss\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\"\n",
    "        for print logging\n",
    "        \"\"\"\n",
    "        loss_grapheme = np.mean(self.loss_grapheme)\n",
    "        loss_vowel = np.mean(self.loss_vowel)\n",
    "        loss_consonant = np.mean(self.loss_consonant)\n",
    "        loss_total = np.mean([loss_grapheme, loss_vowel, loss_consonant])\n",
    "        return loss_total, loss_grapheme, loss_vowel, loss_consonant\n",
    "\n",
    "class MetricLogger(object):\n",
    "    \"\"\"recall, precision for an epoch\n",
    "    \n",
    "    [Epoch i]:\n",
    "        metric_logger = MetricLogger()\n",
    "        \n",
    "        [Batch j]:\n",
    "            metric_logger.update(logits, truth)\n",
    "        \n",
    "        rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pred_grapheme = torch.tensor([], dtype=torch.long).cuda(device)\n",
    "        self.pred_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.pred_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        \n",
    "        self.truth_grapheme = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_vowel = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "        self.truth_consonant = torch.tensor([], dtype=torch.long).cuda(device=device)\n",
    "\n",
    "    def update(self, logits, truth):\n",
    "        pred = torch.argmax(logits[0], dim=1)\n",
    "        self.pred_grapheme = torch.cat([self.pred_grapheme, pred])\n",
    "        self.truth_grapheme = torch.cat([self.truth_grapheme, truth[:, 0].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[1], dim=1)\n",
    "        self.pred_vowel = torch.cat([self.pred_vowel, pred])\n",
    "        self.truth_vowel = torch.cat([self.truth_vowel, truth[:, 1].long()])\n",
    "        #\n",
    "        pred = torch.argmax(logits[2], dim=1)\n",
    "        self.pred_consonant = torch.cat([self.pred_consonant, pred])\n",
    "        self.truth_consonant = torch.cat([self.truth_consonant, truth[:, 2].long()])\n",
    "\n",
    "    def aggregate(self):\n",
    "        rec_grapheme = recall_score(self.truth_grapheme.cpu().numpy(), \n",
    "                                    self.pred_grapheme.cpu().numpy(), \n",
    "                                    average='macro')\n",
    "        rec_vowel = recall_score(self.truth_vowel.cpu().numpy(), \n",
    "                                 self.pred_vowel.cpu().numpy(), \n",
    "                                 average='macro')\n",
    "        rec_consonant = recall_score(self.truth_consonant.cpu().numpy(), \n",
    "                                     self.pred_consonant.cpu().numpy(), \n",
    "                                     average='macro')\n",
    "        #rec = (2*rec_grapheme + 1*rec_vowel + 1*rec_consonant) / 4\n",
    "        rec = np.average([rec_grapheme, rec_vowel, rec_consonant], weights=[2,1,1])\n",
    "        return rec, rec_grapheme, rec_vowel, rec_consonant\n",
    "\n",
    "# #debug MetricLogger\n",
    "# #Epoch 0\n",
    "# loss_logger = LossLogger()\n",
    "# metric_logger = MetricLogger()\n",
    "# for batch_id, (images, labels) in enumerate(val_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if batch_id==10:\n",
    "#         break\n",
    "#     logit = net(inputs)\n",
    "#     logits = torch.split(logit, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "#     loss = loss_logger.update(logits, truth)\n",
    "#     metric_logger.update(logits, truth)\n",
    "# rec, rec_grapheme, rec_vowel, rec_consonant = metric_logger.aggregate()\n",
    "# loss_total, loss_grapheme, loss_vowel, loss_consonant = loss_logger.aggregate()\n",
    "# print(rec, rec_grapheme, rec_vowel, rec_consonant)\n",
    "# print(loss_total, loss_grapheme, loss_vowel, loss_consonant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senet import se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 0========\n",
      "[     0      1      2 ... 200835 200837 200839]\n",
      "[     4      6     12 ... 200832 200836 200838]\n",
      "model state_dict loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[EPOCH 00000]train_loss: 1.7333; val_loss: 0.4934; time elapsed: 19.6 min\n",
      "[valid loss]grapheme: 0.7596, vowel: 0.3932, consonant: 0.3273\n",
      "[valid recall]total: 0.8170, grapheme: 0.8806, vowel: 0.8667, consonant: 0.6398\n",
      "================================================================================\n",
      "[EPOCH 00001]train_loss: 1.2111; val_loss: 0.3267; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.4986, vowel: 0.2755, consonant: 0.2061\n",
      "[valid recall]total: 0.8885, grapheme: 0.9207, vowel: 0.9320, consonant: 0.7805\n",
      "================================================================================\n",
      "[EPOCH 00002]train_loss: 1.1135; val_loss: 0.3313; time elapsed: 19.9 min\n",
      "[valid loss]grapheme: 0.4556, vowel: 0.3180, consonant: 0.2203\n",
      "[valid recall]total: 0.8924, grapheme: 0.9309, vowel: 0.9369, consonant: 0.7711\n",
      "================================================================================\n",
      "[EPOCH 00003]train_loss: 1.0344; val_loss: 0.2618; time elapsed: 19.3 min\n",
      "[valid loss]grapheme: 0.3803, vowel: 0.2265, consonant: 0.1785\n",
      "[valid recall]total: 0.9305, grapheme: 0.9385, vowel: 0.9476, consonant: 0.8972\n",
      "================================================================================\n",
      "[EPOCH 00004]train_loss: 0.9940; val_loss: 0.2343; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.3079, vowel: 0.2298, consonant: 0.1651\n",
      "[valid recall]total: 0.9391, grapheme: 0.9411, vowel: 0.9522, consonant: 0.9222\n",
      "================================================================================\n",
      "[EPOCH 00005]train_loss: 0.9291; val_loss: 0.2059; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.3054, vowel: 0.1838, consonant: 0.1286\n",
      "[valid recall]total: 0.9491, grapheme: 0.9467, vowel: 0.9657, consonant: 0.9372\n",
      "================================================================================\n",
      "[EPOCH 00006]train_loss: 0.9292; val_loss: 0.2118; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.2789, vowel: 0.1986, consonant: 0.1577\n",
      "[valid recall]total: 0.9452, grapheme: 0.9480, vowel: 0.9591, consonant: 0.9256\n",
      "================================================================================\n",
      "[EPOCH 00007]train_loss: 0.8773; val_loss: 0.2128; time elapsed: 19.6 min\n",
      "[valid loss]grapheme: 0.2764, vowel: 0.2276, consonant: 0.1344\n",
      "[valid recall]total: 0.9551, grapheme: 0.9481, vowel: 0.9663, consonant: 0.9580\n",
      "================================================================================\n",
      "[EPOCH 00008]train_loss: 0.8708; val_loss: 0.2129; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.2902, vowel: 0.2046, consonant: 0.1437\n",
      "[valid recall]total: 0.9538, grapheme: 0.9496, vowel: 0.9689, consonant: 0.9471\n",
      "================================================================================\n",
      "[EPOCH 00009]train_loss: 0.8415; val_loss: 0.2166; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.2929, vowel: 0.2086, consonant: 0.1482\n",
      "[valid recall]total: 0.9488, grapheme: 0.9495, vowel: 0.9656, consonant: 0.9304\n",
      "================================================================================\n",
      "[EPOCH 00010]train_loss: 0.8229; val_loss: 0.1958; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.2623, vowel: 0.2125, consonant: 0.1128\n",
      "[valid recall]total: 0.9601, grapheme: 0.9542, vowel: 0.9670, consonant: 0.9651\n",
      "================================================================================\n",
      "[EPOCH 00011]train_loss: 0.8152; val_loss: 0.2086; time elapsed: 19.6 min\n",
      "[valid loss]grapheme: 0.2739, vowel: 0.2036, consonant: 0.1484\n",
      "[valid recall]total: 0.9528, grapheme: 0.9544, vowel: 0.9693, consonant: 0.9332\n",
      "================================================================================\n",
      "[EPOCH 00012]train_loss: 0.8172; val_loss: 0.1810; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.2376, vowel: 0.1784, consonant: 0.1271\n",
      "[valid recall]total: 0.9593, grapheme: 0.9541, vowel: 0.9740, consonant: 0.9552\n",
      "================================================================================\n",
      "[EPOCH 00013]train_loss: 0.7997; val_loss: 0.1537; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.2125, vowel: 0.1480, consonant: 0.1006\n",
      "[valid recall]total: 0.9650, grapheme: 0.9564, vowel: 0.9750, consonant: 0.9724\n",
      "================================================================================\n",
      "[EPOCH 00014]train_loss: 0.7961; val_loss: 0.1671; time elapsed: 19.3 min\n",
      "[valid loss]grapheme: 0.2193, vowel: 0.1741, consonant: 0.1080\n",
      "[valid recall]total: 0.9657, grapheme: 0.9557, vowel: 0.9761, consonant: 0.9753\n",
      "================================================================================\n",
      "[EPOCH 00015]train_loss: 0.8017; val_loss: 0.1894; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.2432, vowel: 0.1973, consonant: 0.1278\n",
      "[valid recall]total: 0.9623, grapheme: 0.9577, vowel: 0.9764, consonant: 0.9574\n",
      "================================================================================\n",
      "[EPOCH 00016]train_loss: 0.7870; val_loss: 0.1735; time elapsed: 19.1 min\n",
      "[valid loss]grapheme: 0.2335, vowel: 0.1667, consonant: 0.1203\n",
      "[valid recall]total: 0.9671, grapheme: 0.9583, vowel: 0.9768, consonant: 0.9748\n",
      "================================================================================\n",
      "[EPOCH 00017]train_loss: 0.7843; val_loss: 0.1472; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.2016, vowel: 0.1389, consonant: 0.1009\n",
      "[valid recall]total: 0.9644, grapheme: 0.9582, vowel: 0.9787, consonant: 0.9623\n",
      "================================================================================\n",
      "[EPOCH 00018]train_loss: 0.7617; val_loss: 0.1427; time elapsed: 19.1 min\n",
      "[valid loss]grapheme: 0.2043, vowel: 0.1306, consonant: 0.0933\n",
      "[valid recall]total: 0.9641, grapheme: 0.9551, vowel: 0.9785, consonant: 0.9678\n",
      "================================================================================\n",
      "[EPOCH 00019]train_loss: 0.7431; val_loss: 0.1309; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.1840, vowel: 0.1202, consonant: 0.0885\n",
      "[valid recall]total: 0.9680, grapheme: 0.9600, vowel: 0.9797, consonant: 0.9721\n",
      "================================================================================\n",
      "[EPOCH 00020]train_loss: 0.7660; val_loss: 0.1799; time elapsed: 19.1 min\n",
      "[valid loss]grapheme: 0.2325, vowel: 0.1855, consonant: 0.1216\n",
      "[valid recall]total: 0.9666, grapheme: 0.9594, vowel: 0.9774, consonant: 0.9700\n",
      "================================================================================\n",
      "[EPOCH 00021]train_loss: 0.7409; val_loss: 0.1943; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.2427, vowel: 0.2117, consonant: 0.1285\n",
      "[valid recall]total: 0.9654, grapheme: 0.9585, vowel: 0.9786, consonant: 0.9661\n",
      "================================================================================\n",
      "[EPOCH 00022]train_loss: 0.7589; val_loss: 0.1494; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.1998, vowel: 0.1418, consonant: 0.1065\n",
      "[valid recall]total: 0.9636, grapheme: 0.9589, vowel: 0.9774, consonant: 0.9590\n",
      "================================================================================\n",
      "[EPOCH 00023]train_loss: 0.7441; val_loss: 0.1699; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.2104, vowel: 0.1782, consonant: 0.1210\n",
      "[valid recall]total: 0.9653, grapheme: 0.9561, vowel: 0.9809, consonant: 0.9681\n",
      "================================================================================\n",
      "[EPOCH 00024]train_loss: 0.7365; val_loss: 0.1641; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.2261, vowel: 0.1607, consonant: 0.1057\n",
      "[valid recall]total: 0.9641, grapheme: 0.9573, vowel: 0.9771, consonant: 0.9646\n",
      "================================================================================\n",
      "[EPOCH 00025]train_loss: 0.7315; val_loss: 0.2062; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.2442, vowel: 0.2280, consonant: 0.1463\n",
      "[valid recall]total: 0.9654, grapheme: 0.9583, vowel: 0.9761, consonant: 0.9689\n",
      "================================================================================\n",
      "[EPOCH 00026]train_loss: 0.7071; val_loss: 0.1791; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.2363, vowel: 0.1827, consonant: 0.1184\n",
      "[valid recall]total: 0.9665, grapheme: 0.9604, vowel: 0.9794, consonant: 0.9657\n",
      "================================================================================\n",
      "[EPOCH 00027]train_loss: 0.7062; val_loss: 0.1096; time elapsed: 19.2 min\n",
      "[valid loss]grapheme: 0.1558, vowel: 0.0997, consonant: 0.0733\n",
      "[valid recall]total: 0.9722, grapheme: 0.9622, vowel: 0.9839, consonant: 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[EPOCH 00028]train_loss: 0.7034; val_loss: 0.1793; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.2073, vowel: 0.2132, consonant: 0.1173\n",
      "[valid recall]total: 0.9722, grapheme: 0.9631, vowel: 0.9826, consonant: 0.9802\n",
      "================================================================================\n",
      "[EPOCH 00029]train_loss: 0.6833; val_loss: 0.1357; time elapsed: 19.1 min\n",
      "[valid loss]grapheme: 0.1768, vowel: 0.1353, consonant: 0.0949\n",
      "[valid recall]total: 0.9710, grapheme: 0.9638, vowel: 0.9827, consonant: 0.9738\n",
      "================================================================================\n",
      "[EPOCH 00030]train_loss: 0.6698; val_loss: 0.1404; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.1792, vowel: 0.1431, consonant: 0.0989\n",
      "[valid recall]total: 0.9688, grapheme: 0.9589, vowel: 0.9843, consonant: 0.9731\n",
      "================================================================================\n",
      "[EPOCH 00031]train_loss: 0.6831; val_loss: 0.1812; time elapsed: 19.1 min\n",
      "[valid loss]grapheme: 0.2413, vowel: 0.1772, consonant: 0.1251\n",
      "[valid recall]total: 0.9696, grapheme: 0.9614, vowel: 0.9845, consonant: 0.9710\n",
      "================================================================================\n",
      "[EPOCH 00032]train_loss: 0.6842; val_loss: 0.1360; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.1750, vowel: 0.1348, consonant: 0.0982\n",
      "[valid recall]total: 0.9715, grapheme: 0.9625, vowel: 0.9840, consonant: 0.9769\n",
      "================================================================================\n",
      "[EPOCH 00033]train_loss: 0.6720; val_loss: 0.1486; time elapsed: 19.0 min\n",
      "[valid loss]grapheme: 0.1788, vowel: 0.1589, consonant: 0.1080\n",
      "[valid recall]total: 0.9696, grapheme: 0.9608, vowel: 0.9813, consonant: 0.9756\n",
      "================================================================================\n",
      "[EPOCH 00034]train_loss: 0.6988; val_loss: 0.1334; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.1710, vowel: 0.1292, consonant: 0.0999\n",
      "[valid recall]total: 0.9713, grapheme: 0.9630, vowel: 0.9810, consonant: 0.9783\n",
      "================================================================================\n",
      "[EPOCH 00035]train_loss: 0.6685; val_loss: 0.1362; time elapsed: 19.3 min\n",
      "[valid loss]grapheme: 0.1727, vowel: 0.1361, consonant: 0.0996\n",
      "[valid recall]total: 0.9738, grapheme: 0.9644, vowel: 0.9848, consonant: 0.9815\n",
      "================================================================================\n",
      "[EPOCH 00036]train_loss: 0.6713; val_loss: 0.1327; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.1715, vowel: 0.1309, consonant: 0.0956\n",
      "[valid recall]total: 0.9734, grapheme: 0.9640, vowel: 0.9847, consonant: 0.9811\n",
      "================================================================================\n",
      "[EPOCH 00037]train_loss: 0.6636; val_loss: 0.1455; time elapsed: 19.5 min\n",
      "[valid loss]grapheme: 0.1813, vowel: 0.1513, consonant: 0.1040\n",
      "[valid recall]total: 0.9732, grapheme: 0.9642, vowel: 0.9850, consonant: 0.9793\n",
      "================================================================================\n",
      "[EPOCH 00038]train_loss: 0.6644; val_loss: 0.1250; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.1632, vowel: 0.1246, consonant: 0.0871\n",
      "[valid recall]total: 0.9732, grapheme: 0.9637, vowel: 0.9853, consonant: 0.9802\n",
      "================================================================================\n",
      "[EPOCH 00039]train_loss: 0.6623; val_loss: 0.1493; time elapsed: 19.7 min\n",
      "[valid loss]grapheme: 0.1801, vowel: 0.1593, consonant: 0.1086\n",
      "[valid recall]total: 0.9728, grapheme: 0.9636, vowel: 0.9847, consonant: 0.9793\n",
      "================================================================================\n",
      "[EPOCH 00040]train_loss: 0.6665; val_loss: 0.1653; time elapsed: 19.4 min\n",
      "[valid loss]grapheme: 0.1975, vowel: 0.1760, consonant: 0.1223\n",
      "[valid recall]total: 0.9719, grapheme: 0.9631, vowel: 0.9850, consonant: 0.9763\n",
      "================================================================================\n",
      "[EPOCH 00041]train_loss: 0.6566; val_loss: 0.1511; time elapsed: 19.8 min\n",
      "[valid loss]grapheme: 0.1891, vowel: 0.1678, consonant: 0.0962\n",
      "[valid recall]total: 0.9725, grapheme: 0.9628, vowel: 0.9846, consonant: 0.9797\n",
      "================================================================================\n",
      "[EPOCH 00042]train_loss: 0.6642; val_loss: 0.1243; time elapsed: 19.1 min\n",
      "[valid loss]grapheme: 0.1594, vowel: 0.1264, consonant: 0.0872\n",
      "[valid recall]total: 0.9737, grapheme: 0.9640, vowel: 0.9859, consonant: 0.9809\n",
      "================================================================================\n",
      "[EPOCH 00043]train_loss: 0.6635; val_loss: 0.1638; time elapsed: 19.9 min\n",
      "[valid loss]grapheme: 0.1845, vowel: 0.1852, consonant: 0.1216\n",
      "[valid recall]total: 0.9734, grapheme: 0.9649, vowel: 0.9846, consonant: 0.9791\n",
      "================================================================================\n",
      "[EPOCH 00044]train_loss: 0.6487; val_loss: 0.1392; time elapsed: 18.5 min\n",
      "[valid loss]grapheme: 0.1649, vowel: 0.1490, consonant: 0.1036\n",
      "[valid recall]total: 0.9737, grapheme: 0.9645, vowel: 0.9856, consonant: 0.9804\n",
      "================================================================================\n",
      "[EPOCH 00045]train_loss: 0.6557; val_loss: 0.1115; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1582, vowel: 0.1038, consonant: 0.0725\n",
      "[valid recall]total: 0.9743, grapheme: 0.9643, vowel: 0.9863, consonant: 0.9821\n",
      "================================================================================\n",
      "[EPOCH 00046]train_loss: 0.6303; val_loss: 0.1383; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1628, vowel: 0.1482, consonant: 0.1037\n",
      "[valid recall]total: 0.9739, grapheme: 0.9645, vowel: 0.9856, consonant: 0.9810\n",
      "================================================================================\n",
      "[EPOCH 00047]train_loss: 0.6315; val_loss: 0.1399; time elapsed: 18.2 min\n",
      "[valid loss]grapheme: 0.1710, vowel: 0.1413, consonant: 0.1072\n",
      "[valid recall]total: 0.9736, grapheme: 0.9639, vowel: 0.9852, consonant: 0.9813\n",
      "================================================================================\n",
      "[EPOCH 00048]train_loss: 0.6546; val_loss: 0.1430; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1650, vowel: 0.1526, consonant: 0.1114\n",
      "[valid recall]total: 0.9743, grapheme: 0.9654, vowel: 0.9860, consonant: 0.9804\n",
      "================================================================================\n",
      "[EPOCH 00049]train_loss: 0.6329; val_loss: 0.1355; time elapsed: 18.1 min\n",
      "[valid loss]grapheme: 0.1716, vowel: 0.1405, consonant: 0.0945\n",
      "[valid recall]total: 0.9734, grapheme: 0.9641, vowel: 0.9849, consonant: 0.9804\n",
      "================================================================================\n",
      "[EPOCH 00050]train_loss: 0.6459; val_loss: 0.1517; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1799, vowel: 0.1631, consonant: 0.1120\n",
      "[valid recall]total: 0.9737, grapheme: 0.9646, vowel: 0.9850, consonant: 0.9807\n",
      "================================================================================\n",
      "[EPOCH 00051]train_loss: 0.6394; val_loss: 0.1404; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1601, vowel: 0.1511, consonant: 0.1102\n",
      "[valid recall]total: 0.9741, grapheme: 0.9653, vowel: 0.9854, consonant: 0.9802\n",
      "================================================================================\n",
      "[EPOCH 00052]train_loss: 0.6330; val_loss: 0.1589; time elapsed: 18.2 min\n",
      "[valid loss]grapheme: 0.2027, vowel: 0.1631, consonant: 0.1109\n",
      "[valid recall]total: 0.9734, grapheme: 0.9639, vowel: 0.9853, consonant: 0.9807\n",
      "================================================================================\n",
      "[EPOCH 00053]train_loss: 0.6342; val_loss: 0.1132; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1509, vowel: 0.1066, consonant: 0.0821\n",
      "[valid recall]total: 0.9748, grapheme: 0.9651, vowel: 0.9862, consonant: 0.9826\n",
      "================================================================================\n",
      "[EPOCH 00054]train_loss: 0.6426; val_loss: 0.1177; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1529, vowel: 0.1196, consonant: 0.0807\n",
      "[valid recall]total: 0.9747, grapheme: 0.9648, vowel: 0.9865, consonant: 0.9826\n",
      "================================================================================\n",
      "[EPOCH 00055]train_loss: 0.6537; val_loss: 0.1175; time elapsed: 18.4 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[valid loss]grapheme: 0.1545, vowel: 0.1109, consonant: 0.0871\n",
      "[valid recall]total: 0.9745, grapheme: 0.9641, vowel: 0.9862, consonant: 0.9836\n",
      "================================================================================\n",
      "[EPOCH 00056]train_loss: 0.6165; val_loss: 0.1184; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1562, vowel: 0.1133, consonant: 0.0858\n",
      "[valid recall]total: 0.9742, grapheme: 0.9642, vowel: 0.9858, consonant: 0.9826\n",
      "================================================================================\n",
      "[EPOCH 00057]train_loss: 0.6390; val_loss: 0.1460; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1753, vowel: 0.1514, consonant: 0.1113\n",
      "[valid recall]total: 0.9742, grapheme: 0.9649, vowel: 0.9863, consonant: 0.9805\n",
      "================================================================================\n",
      "[EPOCH 00058]train_loss: 0.6433; val_loss: 0.1082; time elapsed: 18.5 min\n",
      "[valid loss]grapheme: 0.1482, vowel: 0.0959, consonant: 0.0804\n",
      "[valid recall]total: 0.9742, grapheme: 0.9637, vowel: 0.9863, consonant: 0.9834\n",
      "================================================================================\n",
      "[EPOCH 00059]train_loss: 0.6344; val_loss: 0.1170; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1524, vowel: 0.1103, consonant: 0.0882\n",
      "[valid recall]total: 0.9742, grapheme: 0.9635, vowel: 0.9862, consonant: 0.9834\n",
      "================================================================================\n",
      "[EPOCH 00060]train_loss: 0.5978; val_loss: 0.1249; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1568, vowel: 0.1235, consonant: 0.0945\n",
      "[valid recall]total: 0.9742, grapheme: 0.9641, vowel: 0.9858, consonant: 0.9825\n",
      "================================================================================\n",
      "[EPOCH 00061]train_loss: 0.6270; val_loss: 0.1343; time elapsed: 18.5 min\n",
      "[valid loss]grapheme: 0.1637, vowel: 0.1420, consonant: 0.0972\n",
      "[valid recall]total: 0.9748, grapheme: 0.9653, vowel: 0.9862, consonant: 0.9823\n",
      "================================================================================\n",
      "[EPOCH 00062]train_loss: 0.6421; val_loss: 0.1161; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1524, vowel: 0.1131, consonant: 0.0829\n",
      "[valid recall]total: 0.9734, grapheme: 0.9628, vowel: 0.9860, consonant: 0.9820\n",
      "================================================================================\n",
      "[EPOCH 00063]train_loss: 0.6382; val_loss: 0.1300; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1621, vowel: 0.1339, consonant: 0.0940\n",
      "[valid recall]total: 0.9737, grapheme: 0.9633, vowel: 0.9856, consonant: 0.9827\n",
      "================================================================================\n",
      "[EPOCH 00064]train_loss: 0.6413; val_loss: 0.1191; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1592, vowel: 0.1161, consonant: 0.0820\n",
      "[valid recall]total: 0.9744, grapheme: 0.9641, vowel: 0.9860, consonant: 0.9835\n",
      "================================================================================\n",
      "[EPOCH 00065]train_loss: 0.6373; val_loss: 0.1139; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1541, vowel: 0.1044, consonant: 0.0830\n",
      "[valid recall]total: 0.9740, grapheme: 0.9639, vowel: 0.9857, consonant: 0.9822\n",
      "================================================================================\n",
      "[EPOCH 00066]train_loss: 0.6361; val_loss: 0.1215; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1551, vowel: 0.1220, consonant: 0.0874\n",
      "[valid recall]total: 0.9737, grapheme: 0.9635, vowel: 0.9861, consonant: 0.9820\n",
      "================================================================================\n",
      "[EPOCH 00067]train_loss: 0.6253; val_loss: 0.1394; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1656, vowel: 0.1477, consonant: 0.1050\n",
      "[valid recall]total: 0.9748, grapheme: 0.9654, vowel: 0.9862, consonant: 0.9823\n",
      "================================================================================\n",
      "[EPOCH 00068]train_loss: 0.6076; val_loss: 0.1273; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1621, vowel: 0.1267, consonant: 0.0932\n",
      "[valid recall]total: 0.9748, grapheme: 0.9649, vowel: 0.9866, consonant: 0.9828\n",
      "================================================================================\n",
      "[EPOCH 00069]train_loss: 0.6375; val_loss: 0.1165; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1524, vowel: 0.1107, consonant: 0.0865\n",
      "[valid recall]total: 0.9744, grapheme: 0.9643, vowel: 0.9866, consonant: 0.9823\n",
      "================================================================================\n",
      "[EPOCH 00070]train_loss: 0.6375; val_loss: 0.1486; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1888, vowel: 0.1465, consonant: 0.1105\n",
      "[valid recall]total: 0.9743, grapheme: 0.9645, vowel: 0.9865, consonant: 0.9816\n",
      "================================================================================\n",
      "[EPOCH 00071]train_loss: 0.6229; val_loss: 0.1306; time elapsed: 18.5 min\n",
      "[valid loss]grapheme: 0.1574, vowel: 0.1309, consonant: 0.1034\n",
      "[valid recall]total: 0.9741, grapheme: 0.9641, vowel: 0.9862, consonant: 0.9822\n",
      "================================================================================\n",
      "[EPOCH 00072]train_loss: 0.6409; val_loss: 0.1131; time elapsed: 18.3 min\n",
      "[valid loss]grapheme: 0.1570, vowel: 0.1038, consonant: 0.0785\n",
      "[valid recall]total: 0.9738, grapheme: 0.9634, vowel: 0.9859, consonant: 0.9827\n",
      "================================================================================\n",
      "[EPOCH 00073]train_loss: 0.6367; val_loss: 0.1045; time elapsed: 18.5 min\n",
      "[valid loss]grapheme: 0.1500, vowel: 0.0912, consonant: 0.0724\n",
      "[valid recall]total: 0.9735, grapheme: 0.9627, vowel: 0.9860, consonant: 0.9826\n",
      "================================================================================\n",
      "[EPOCH 00074]train_loss: 0.6334; val_loss: 0.1243; time elapsed: 18.4 min\n",
      "[valid loss]grapheme: 0.1544, vowel: 0.1244, consonant: 0.0943\n",
      "[valid recall]total: 0.9741, grapheme: 0.9638, vowel: 0.9864, consonant: 0.9825\n",
      "================================================================================\n",
      "[EPOCH 00075]train_loss: 0.6179; val_loss: 0.1405; time elapsed: 18.8 min\n",
      "[valid loss]grapheme: 0.1756, vowel: 0.1424, consonant: 0.1037\n",
      "[valid recall]total: 0.9742, grapheme: 0.9643, vowel: 0.9856, consonant: 0.9827\n",
      "================================================================================\n",
      "[EPOCH 00076]train_loss: 0.6270; val_loss: 0.1222; time elapsed: 19.0 min\n",
      "[valid loss]grapheme: 0.1517, vowel: 0.1171, consonant: 0.0977\n",
      "[valid recall]total: 0.9740, grapheme: 0.9638, vowel: 0.9862, consonant: 0.9821\n",
      "================================================================================\n",
      "[EPOCH 00077]train_loss: 0.6209; val_loss: 0.1283; time elapsed: 18.8 min\n",
      "[valid loss]grapheme: 0.1581, vowel: 0.1339, consonant: 0.0929\n",
      "[valid recall]total: 0.9743, grapheme: 0.9643, vowel: 0.9859, consonant: 0.9827\n",
      "================================================================================\n",
      "Early Stopping: val_metric does not increase 10 rounds\n"
     ]
    }
   ],
   "source": [
    "#### training for 5 folds here ####\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED).split(X=train_images_arr, y=train_label_arr)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf):\n",
    "    \n",
    "    if fold in [0]:#train 1 fold for testing ideas\n",
    "        print('========training fold %d========'%fold)\n",
    "        print(train_idx)\n",
    "        print(valid_idx)\n",
    "        \n",
    "        #1.1 data\n",
    "        train_inputs, valid_inputs = train_images_arr[train_idx], train_images_arr[valid_idx]\n",
    "        train_outputs, valid_outputs = train_label_arr[train_idx], train_label_arr[valid_idx]\n",
    "        #1.2 Dataset, DataLoader\n",
    "        train_dl = prepare_dataset(train_inputs, train_outputs, mode='train', debug=debug)\n",
    "        val_dl = prepare_dataset(valid_inputs, valid_outputs, mode='valid', debug=debug)\n",
    "        \n",
    "        #2. model\n",
    "        #net = se_resnext50_32x4d(num_classes=num_classes, pretrained=None).cuda(device=device)\n",
    "        net = se_resnext50_32x4d(num_classes=num_classes, pretrained='imagenet').cuda(device=device)\n",
    "\n",
    "        #3. train session\n",
    "        train_and_valid(net, train_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 0\n",
    "# [     0      1      2 ... 200835 200837 200839]\n",
    "# [     4      6     12 ... 200832 200836 200838]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check dataset/network/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_id, (images, labels) in enumerate(train_dl):\n",
    "#     inputs = images.to(device=device, dtype=torch.float)\n",
    "#     truth = labels.to(device=device, dtype=torch.float)\n",
    "#     if batch_id==0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs.shape, truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils import model_zoo\n",
    "#pretrained_dict = model_zoo.load_url('http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth')\n",
    "#list(pretrained_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import senet\n",
    "# importlib.reload(senet)\n",
    "\n",
    "# from senet import se_resnext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = se_resnext50_32x4d(num_classes=num_classes, pretrained='imagenet').cuda(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logit = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
